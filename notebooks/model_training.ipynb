{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-20 14:47:38.835816: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-08-20 14:47:38.935589: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2024-08-20 14:47:38.935607: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2024-08-20 14:47:39.434533: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2024-08-20 14:47:39.434590: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2024-08-20 14:47:39.434597: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARN: Unable to import optimizer(s) from expr_templates.py: No module named 'sympy'\n",
      "WARNING: Failed to import handlers from convolution.py: No module named 'torch'.\n",
      "WARNING: Failed to import handlers from core.py: No module named 'torch'.\n",
      "WARNING: Failed to import handlers from merge.py: No module named 'torch'.\n",
      "WARNING: Failed to import handlers from pooling.py: No module named 'torch'.\n",
      "WARNING: Failed to import handlers from reshape.py: No module named 'torch'.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jcampos/miniforge3/envs/ml4qick-env/lib/python3.8/site-packages/hls4ml/converters/__init__.py:27: UserWarning: WARNING: Pytorch converter is not enabled!\n",
      "  warnings.warn(\"WARNING: Pytorch converter is not enabled!\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "import sys \n",
    "sys.path.append(\"../training\")\n",
    "import pickle\n",
    "\n",
    "import hashlib\n",
    "import hls4ml \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation, BatchNormalization, Dropout, Softmax\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, ModelCheckpoint\n",
    "from tensorflow.keras.losses import CategoricalCrossentropy\n",
    "\n",
    "from tensorflow_model_optimization.python.core.sparsity.keras import prune, pruning_callbacks, pruning_schedule\n",
    "from tensorflow_model_optimization.sparsity.keras import strip_pruning\n",
    "import tensorflow_model_optimization as tfmot\n",
    "\n",
    "from qkeras.qlayers import QDense, QActivation\n",
    "from qkeras import QBatchNormalization\n",
    "from qkeras.quantizers import quantized_bits, quantized_relu\n",
    "from qkeras.utils import _add_supported_quantized_objects\n",
    "from tensorflow.keras.models import load_model\n",
    "from qkeras.utils import _add_supported_quantized_objects"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data\n",
    "\n",
    "#### Impoartant! \n",
    "Download the dataset locally from [OneDrive here](https://purdue0-my.sharepoint.com/personal/du245_purdue_edu/_layouts/15/onedrive.aspx?id=%2Fpersonal%2Fdu245%5Fpurdue%5Fedu%2FDocuments%2FShared%2FQSC%20ML%20for%20readout%2FFinal%5Fraw%5Fdata%5Ffor%5Fpaper%2Fdata%5F0528%5Fnpy). We are using QICK data with timestamp **0528**. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encode(data):\n",
    "    y_encoded = np.zeros([data.shape[0],2], dtype=np.int32)\n",
    "    for idx, x in enumerate(data):\n",
    "        if x == 1:\n",
    "            y_encoded[idx][1] = 1\n",
    "        else:\n",
    "            y_encoded[idx][0] = 1\n",
    "    return y_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Data Set:\n",
      "\tX Path        : ../data/malab_05282024/npz/0528_X_train_0_770.npy\n",
      "\ty Path        : ../data/malab_05282024/npz/0528_y_train_0_770.npy\n",
      "\tSize          : 900000\n",
      "\tSample Shape  : (1540,)\n",
      "\tMean          : 57.37779754545455\n",
      "\tStd. Dev.     : 844.0956096913322\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Loadning training split\"\"\"\n",
    "start_window = 0\n",
    "end_window = 770\n",
    "data_dir = \"../data/malab_05282024/npz/\"\n",
    "assert os.path.exists(f\"{data_dir}/0528_X_train_{start_window}_{end_window}.npy\"), \"File does not exist \"\n",
    "\n",
    "x_train_path = os.path.join(data_dir, f'0528_X_train_{start_window}_{end_window}.npy')\n",
    "y_train_path = os.path.join(data_dir, f'0528_y_train_{start_window}_{end_window}.npy')\n",
    "\n",
    "X_train_val = np.load(x_train_path)\n",
    "y_train_val = np.load(y_train_path)\n",
    "\n",
    "# Insure same dataset is loaded \n",
    "assert hashlib.md5(X_train_val).hexdigest() == 'b61226c86b7dee0201a9158455e08ffb',  \"Checksum failed. Wrong file was loaded or file may be corrupted.\"\n",
    "assert hashlib.md5(y_train_val).hexdigest() == 'c59ce37dc7c73d2d546e7ea180fa8d31',  \"Checksum failed. Wrong file was loaded or file may be corrupted.\"\n",
    "\n",
    "y_train_val = one_hot_encode(y_train_val)\n",
    "\n",
    "print(\"Train Data Set:\")\n",
    "print(\"\\tX Path        :\", x_train_path)\n",
    "print(\"\\ty Path        :\", y_train_path)\n",
    "print(\"\\tSize          :\", len(X_train_val))\n",
    "print(\"\\tSample Shape  :\", X_train_val[0].shape)\n",
    "print(\"\\tMean          :\", X_train_val.mean())\n",
    "print(\"\\tStd. Dev.     :\", X_train_val.std())\n",
    "\n",
    "assert len(X_train_val[0]) == (end_window-start_window)*2, \"ERROR: Specified window does not match loaded dataset shape\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Data Set:\n",
      "\tX Path        : ../data/malab_05282024/npz/0528_X_test_0_770.npy\n",
      "\ty Path        : ../data/malab_05282024/npz/0528_y_test_0_770.npy\n",
      "\tSize         : 100000\n",
      "\tSample Shape : (1540,)\n",
      "\tSample Shape : 57.57549828571429\n",
      "\tStd. Dev.    : 845.6158899866076\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Loading testing split\"\"\"\n",
    "start_window = 0\n",
    "end_window = 770\n",
    "data_dir = \"../data/malab_05282024/npz/\"\n",
    "assert os.path.exists(f\"{data_dir}/X_test_{start_window}_{end_window}.npy\"), \"File does not exist \"\n",
    "\n",
    "x_test_path = os.path.join(data_dir, f'0528_X_test_{start_window}_{end_window}.npy')\n",
    "y_test_path = os.path.join(data_dir, f'0528_y_test_{start_window}_{end_window}.npy')\n",
    "\n",
    "X_test = np.load(x_test_path)\n",
    "y_test = np.load(y_test_path)\n",
    "\n",
    "# Insure same dataset is loaded \n",
    "assert hashlib.md5(X_test).hexdigest() == 'b7d85f42522a0a57e877422bc5947cde', \"Checksum failed. Wrong file was loaded or file may be corrupted.\"\n",
    "assert hashlib.md5(y_test).hexdigest() == '8c9cce1821372380371ade5f0ccfd4a2', \"Checksum failed. Wrong file was loaded or file may be corrupted.\"\n",
    "\n",
    "y_test = one_hot_encode(y_test)\n",
    "\n",
    "print(\"Test Data Set:\")\n",
    "print(\"\\tX Path        :\", x_test_path)\n",
    "print(\"\\ty Path        :\", y_test_path)\n",
    "print(\"\\tSize         :\", len(X_test))\n",
    "print(\"\\tSample Shape :\", X_test[0].shape)\n",
    "print(\"\\tSample Shape :\", X_test.mean())\n",
    "print(\"\\tStd. Dev.    :\", X_test.std())\n",
    "\n",
    "assert len(X_test[0]) == (end_window-start_window)*2, \"ERROR: Specified window does not match loaded dataset shape\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi-layer Model \n",
    "Or the initial \"big\" model \n",
    "\n",
    "<!-- ![Multi-layer model](../images/multi_layer_model.png) -->\n",
    "<img src=\"../images/multi_layer_model.png\" alt=\"alt text\" width=\"75%\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"hyperparameters\"\"\"\n",
    "init_learning_rate = 1e-4\n",
    "validation_split = 0\n",
    "batch_size = 8192\n",
    "epochs = 50\n",
    "checkpoint_filename = \"multi-layer.h5\"\n",
    "input_shape = (len(X_train_val[0]),)\n",
    "start_window = 0\n",
    "end_window = 770\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 385)               593285    \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 385)              1540      \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 2)                 772       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 595,597\n",
      "Trainable params: 594,827\n",
      "Non-trainable params: 770\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-20 14:48:03.952618: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2024-08-20 14:48:03.952736: W tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:265] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2024-08-20 14:48:03.952777: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (correlator4.fnal.gov): /proc/driver/nvidia/version does not exist\n",
      "2024-08-20 14:48:03.953182: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "sr = int((end_window-start_window)*2)\n",
    "hn = sr * 2\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(int(hn/8), activation='relu', input_shape=(sr,)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(2, activation='relu'))\n",
    "\n",
    "print(model.summary())\n",
    "assert model.count_params() == 595597, 'Error. Total parameters has changed.'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [\n",
    "        ModelCheckpoint(\n",
    "        checkpoint_filename,\n",
    "        monitor=\"val_loss\",\n",
    "        verbose=0,\n",
    "        save_best_only=True,\n",
    "        save_weights_only=False,\n",
    "        save_freq=\"epoch\",\n",
    "    ),\n",
    "    ReduceLROnPlateau(patience=75, min_delta=1**-6),\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-20 14:48:05.339412: W tensorflow/tsl/framework/cpu_allocator_impl.cc:82] Allocation of 5266800000 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "105/105 [==============================] - 4s 34ms/step - loss: 0.2369 - accuracy: 0.9280 - val_loss: 0.1933 - val_accuracy: 0.9519 - lr: 1.0000e-04\n",
      "Epoch 2/10\n",
      "105/105 [==============================] - 3s 31ms/step - loss: 0.1742 - accuracy: 0.9569 - val_loss: 0.1756 - val_accuracy: 0.9555 - lr: 1.0000e-04\n",
      "Epoch 3/10\n",
      "105/105 [==============================] - 3s 32ms/step - loss: 0.1636 - accuracy: 0.9597 - val_loss: 0.1683 - val_accuracy: 0.9579 - lr: 1.0000e-04\n",
      "Epoch 4/10\n",
      "105/105 [==============================] - 3s 31ms/step - loss: 0.1567 - accuracy: 0.9611 - val_loss: 0.1635 - val_accuracy: 0.9589 - lr: 1.0000e-04\n",
      "Epoch 5/10\n",
      "105/105 [==============================] - 3s 31ms/step - loss: 0.1517 - accuracy: 0.9617 - val_loss: 0.1606 - val_accuracy: 0.9596 - lr: 1.0000e-04\n",
      "Epoch 6/10\n",
      "105/105 [==============================] - 3s 31ms/step - loss: 0.1479 - accuracy: 0.9621 - val_loss: 0.1589 - val_accuracy: 0.9597 - lr: 1.0000e-04\n",
      "Epoch 7/10\n",
      "105/105 [==============================] - 3s 32ms/step - loss: 0.1448 - accuracy: 0.9624 - val_loss: 0.1580 - val_accuracy: 0.9599 - lr: 1.0000e-04\n",
      "Epoch 8/10\n",
      "105/105 [==============================] - 3s 31ms/step - loss: 0.1420 - accuracy: 0.9628 - val_loss: 0.1575 - val_accuracy: 0.9600 - lr: 1.0000e-04\n",
      "Epoch 9/10\n",
      "105/105 [==============================] - 3s 31ms/step - loss: 0.1395 - accuracy: 0.9631 - val_loss: 0.1568 - val_accuracy: 0.9598 - lr: 1.0000e-04\n",
      "Epoch 10/10\n",
      "105/105 [==============================] - 3s 31ms/step - loss: 0.1371 - accuracy: 0.9634 - val_loss: 0.1565 - val_accuracy: 0.9600 - lr: 1.0000e-04\n"
     ]
    }
   ],
   "source": [
    "opt = Adam(learning_rate=init_learning_rate)\n",
    "model.compile(\n",
    "    optimizer=opt, \n",
    "    loss=CategoricalCrossentropy(from_logits=True), \n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "history = model.fit(\n",
    "    X_train_val, \n",
    "    y_train_val, \n",
    "    batch_size=batch_size,\n",
    "    epochs=epochs, \n",
    "    validation_split=0.05, \n",
    "    shuffle=True, \n",
    "    callbacks=callbacks,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3125/3125 [==============================] - 8s 2ms/step\n",
      "Keras  Accuracy: 0.96093\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "print(\"Keras  Accuracy: {}\".format(accuracy_score(np.argmax(y_test, axis=1), np.argmax(y_pred, axis=1))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get ground and excited indices \n",
    "e_indices = np.where(np.argmax(y_test, axis=1) == 1)[0]\n",
    "g_indices = np.where(np.argmax(y_test, axis=1) == 0)[0]\n",
    "\n",
    "# separate ground and excited samples \n",
    "Xe_test = X_test[e_indices]\n",
    "ye_test = np.argmax(y_test, axis=1)[e_indices]\n",
    "\n",
    "Xg_test = X_test[g_indices]\n",
    "yg_test = np.argmax(y_test, axis=1)[g_indices]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1563/1563 [==============================] - 4s 2ms/step\n",
      "Total correct: 47376\n",
      "Total incorrect: 2624\n",
      "Total samples: 50000\n",
      "Keras Excited Accuracy: 0.94752\n",
      "1563/1563 [==============================] - 4s 2ms/step\n",
      "Total correct: 48717\n",
      "Total incorrect: 1283\n",
      "Total samples: 50000\n",
      "Keras Ground Accuracy: 0.97434\n",
      "\n",
      "===================================\n",
      "Fidelity 0.9609300000000001\n",
      "===================================\n"
     ]
    }
   ],
   "source": [
    "# compute total correct for excited state \n",
    "ye_pred = model.predict(Xe_test)\n",
    "e_accuracy = accuracy_score(ye_test, np.argmax(ye_pred, axis=1))\n",
    "\n",
    "total_correct = (ye_test==np.argmax(ye_pred, axis=1)).astype(np.int8).sum()\n",
    "total_incorrect = (ye_test!=np.argmax(ye_pred, axis=1)).astype(np.int8).sum()\n",
    "\n",
    "print(\"Total correct:\", total_correct)\n",
    "print(\"Total incorrect:\", total_incorrect)\n",
    "print(\"Total samples:\", len(Xe_test) )\n",
    "print(\"Keras Excited Accuracy: {}\".format(e_accuracy))\n",
    "\n",
    "# compute total correct for ground state \n",
    "yg_pred = model.predict(Xg_test)\n",
    "g_accuracy = accuracy_score(yg_test, np.argmax(yg_pred, axis=1))\n",
    "\n",
    "total_correct = (yg_test==np.argmax(yg_pred, axis=1)).astype(np.int8).sum()\n",
    "total_incorrect = (yg_test!=np.argmax(yg_pred, axis=1)).astype(np.int8).sum()\n",
    "\n",
    "print(\"Total correct:\", total_correct)\n",
    "print(\"Total incorrect:\", total_incorrect)\n",
    "print(\"Total samples:\", len(Xg_test) )\n",
    "print(\"Keras Ground Accuracy: {}\".format(g_accuracy))\n",
    "\n",
    "# compute fidelity \n",
    "fidelity = 0.5*(e_accuracy + g_accuracy)\n",
    "print('\\n===================================')\n",
    "print('Fidelity', fidelity)\n",
    "print('===================================')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Single-layer Model \n",
    "Or the \"small\" model \n",
    "\n",
    "<img src=\"../images/single_layer_model.png\" alt=\"alt text\" width=\"50%\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"hyperparameters\"\"\"\n",
    "init_learning_rate = 1e-3\n",
    "validation_split = 0\n",
    "batch_size = 8192\n",
    "epochs = 10\n",
    "checkpoint_filename = \"single-layer.h5\"\n",
    "input_shape = (len(X_train_val[0]),)\n",
    "start_window = 0\n",
    "end_window = 770\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_4 (Dense)             (None, 2)                 3082      \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 2)                8         \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,090\n",
      "Trainable params: 3,086\n",
      "Non-trainable params: 4\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(2, activation='relu', input_shape=(sr,)))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "print(model.summary())\n",
    "assert model.count_params() == 3090, 'Error. Total parameters has changed.'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [\n",
    "        ModelCheckpoint(\n",
    "        checkpoint_filename,\n",
    "        monitor=\"val_loss\",\n",
    "        verbose=0,\n",
    "        save_best_only=True,\n",
    "        save_weights_only=False,\n",
    "        save_freq=\"epoch\",\n",
    "    ),\n",
    "    ReduceLROnPlateau(patience=75, min_delta=1**-6),\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-20 14:48:59.480139: W tensorflow/tsl/framework/cpu_allocator_impl.cc:82] Allocation of 5266800000 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "105/105 [==============================] - 2s 16ms/step - loss: 0.6709 - accuracy: 0.6663 - val_loss: 0.4361 - val_accuracy: 0.8201 - lr: 1.0000e-04\n",
      "Epoch 2/10\n",
      "105/105 [==============================] - 1s 14ms/step - loss: 0.3863 - accuracy: 0.8774 - val_loss: 0.3127 - val_accuracy: 0.9084 - lr: 1.0000e-04\n",
      "Epoch 3/10\n",
      "105/105 [==============================] - 1s 14ms/step - loss: 0.3145 - accuracy: 0.9260 - val_loss: 0.2742 - val_accuracy: 0.9338 - lr: 1.0000e-04\n",
      "Epoch 4/10\n",
      "105/105 [==============================] - 1s 14ms/step - loss: 0.2816 - accuracy: 0.9419 - val_loss: 0.2558 - val_accuracy: 0.9433 - lr: 1.0000e-04\n",
      "Epoch 5/10\n",
      "105/105 [==============================] - 1s 14ms/step - loss: 0.2630 - accuracy: 0.9481 - val_loss: 0.2449 - val_accuracy: 0.9481 - lr: 1.0000e-04\n",
      "Epoch 6/10\n",
      "105/105 [==============================] - 1s 14ms/step - loss: 0.2509 - accuracy: 0.9510 - val_loss: 0.2373 - val_accuracy: 0.9505 - lr: 1.0000e-04\n",
      "Epoch 7/10\n",
      "105/105 [==============================] - 1s 14ms/step - loss: 0.2422 - accuracy: 0.9532 - val_loss: 0.2315 - val_accuracy: 0.9524 - lr: 1.0000e-04\n",
      "Epoch 8/10\n",
      "105/105 [==============================] - 1s 14ms/step - loss: 0.2355 - accuracy: 0.9546 - val_loss: 0.2268 - val_accuracy: 0.9532 - lr: 1.0000e-04\n",
      "Epoch 9/10\n",
      "105/105 [==============================] - 1s 14ms/step - loss: 0.2301 - accuracy: 0.9555 - val_loss: 0.2229 - val_accuracy: 0.9541 - lr: 1.0000e-04\n",
      "Epoch 10/10\n",
      "105/105 [==============================] - 1s 14ms/step - loss: 0.2255 - accuracy: 0.9562 - val_loss: 0.2194 - val_accuracy: 0.9546 - lr: 1.0000e-04\n"
     ]
    }
   ],
   "source": [
    "opt = Adam(learning_rate=init_learning_rate)\n",
    "model.compile(\n",
    "    optimizer=opt, \n",
    "    loss=CategoricalCrossentropy(from_logits=True), \n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "history = model.fit(\n",
    "    X_train_val, \n",
    "    y_train_val, \n",
    "    batch_size=batch_size,\n",
    "    epochs=epochs, \n",
    "    validation_split=0.05, \n",
    "    shuffle=True, \n",
    "    callbacks=callbacks,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3125/3125 [==============================] - 4s 1ms/step\n",
      "Keras  Accuracy: 0.95588\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "print(\"Keras  Accuracy: {}\".format(accuracy_score(np.argmax(y_test, axis=1), np.argmax(y_pred, axis=1))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get ground and excited indices \n",
    "e_indices = np.where(np.argmax(y_test, axis=1) == 1)[0]\n",
    "g_indices = np.where(np.argmax(y_test, axis=1) == 0)[0]\n",
    "\n",
    "# separate ground and excited samples \n",
    "Xe_test = X_test[e_indices]\n",
    "ye_test = np.argmax(y_test, axis=1)[e_indices]\n",
    "\n",
    "Xg_test = X_test[g_indices]\n",
    "yg_test = np.argmax(y_test, axis=1)[g_indices]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1563/1563 [==============================] - 3s 2ms/step\n",
      "Total correct: 46819\n",
      "Total incorrect: 3181\n",
      "Total samples: 50000\n",
      "Keras Excited Accuracy: 0.93638\n",
      "1563/1563 [==============================] - 3s 2ms/step\n",
      "Total correct: 48769\n",
      "Total incorrect: 1231\n",
      "Total samples: 50000\n",
      "Keras Ground Accuracy: 0.97538\n",
      "\n",
      "===================================\n",
      "Fidelity 0.9558800000000001\n",
      "===================================\n"
     ]
    }
   ],
   "source": [
    "# compute total correct for excited state \n",
    "ye_pred = model.predict(Xe_test)\n",
    "e_accuracy = accuracy_score(ye_test, np.argmax(ye_pred, axis=1))\n",
    "\n",
    "total_correct = (ye_test==np.argmax(ye_pred, axis=1)).astype(np.int8).sum()\n",
    "total_incorrect = (ye_test!=np.argmax(ye_pred, axis=1)).astype(np.int8).sum()\n",
    "\n",
    "print(\"Total correct:\", total_correct)\n",
    "print(\"Total incorrect:\", total_incorrect)\n",
    "print(\"Total samples:\", len(Xe_test) )\n",
    "print(\"Keras Excited Accuracy: {}\".format(e_accuracy))\n",
    "\n",
    "# compute total correct for ground state \n",
    "yg_pred = model.predict(Xg_test)\n",
    "g_accuracy = accuracy_score(yg_test, np.argmax(yg_pred, axis=1))\n",
    "\n",
    "total_correct = (yg_test==np.argmax(yg_pred, axis=1)).astype(np.int8).sum()\n",
    "total_incorrect = (yg_test!=np.argmax(yg_pred, axis=1)).astype(np.int8).sum()\n",
    "\n",
    "print(\"Total correct:\", total_correct)\n",
    "print(\"Total incorrect:\", total_incorrect)\n",
    "print(\"Total samples:\", len(Xg_test) )\n",
    "print(\"Keras Ground Accuracy: {}\".format(g_accuracy))\n",
    "\n",
    "# compute fidelity \n",
    "fidelity = 0.5*(e_accuracy + g_accuracy)\n",
    "print('\\n===================================')\n",
    "print('Fidelity', fidelity)\n",
    "print('===================================')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Readout Window Start Location\n",
    "Results are with smaller readout window (400) and the start location of the readout window (0, 50, 100, ..., 350)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "window_start_locations = list(range(0, 350+1, 50))\n",
    "window_size = 400"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scan_readout_window(model, window_start_locations, window_size):\n",
    "    all_fidelity = list()\n",
    "    all_accuracy = list()\n",
    "    all_e_accuracy = list()\n",
    "    all_g_accuracy = list()\n",
    "\n",
    "    for start_window in window_start_locations:\n",
    "        end_window = start_window + window_size\n",
    "\n",
    "        #########################\n",
    "        # 1. get readout window \n",
    "        #########################\n",
    "        X_train_window = X_train_val[:,start_window*2:end_window*2]\n",
    "        X_test_window = X_test[:,start_window*2:end_window*2]\n",
    "\n",
    "        #########################\n",
    "        # 2. start training \n",
    "        #########################\n",
    "        opt = Adam(learning_rate=init_learning_rate)\n",
    "        model.compile(\n",
    "            optimizer=opt, \n",
    "            loss=CategoricalCrossentropy(from_logits=True), \n",
    "            metrics=['accuracy']\n",
    "        )\n",
    "\n",
    "        history = model.fit(\n",
    "            X_train_window, \n",
    "            y_train_val, \n",
    "            batch_size=batch_size,\n",
    "            epochs=50, \n",
    "            validation_split=0.05, \n",
    "            shuffle=True, \n",
    "            callbacks=callbacks,\n",
    "        )\n",
    "\n",
    "        #########################\n",
    "        # 3. load checkpoint \n",
    "        #########################\n",
    "        co = {}\n",
    "        _add_supported_quantized_objects(co)\n",
    "        model = load_model(checkpoint_filename, custom_objects=co, compile=False)\n",
    "\n",
    "        #########################\n",
    "        # 4. compute fidelity \n",
    "        #########################\n",
    "        y_pred = model.predict(X_test_window)\n",
    "        test_acc = accuracy_score(np.argmax(y_test, axis=1), np.argmax(y_pred, axis=1))\n",
    "        print(\"Keras  Accuracy: {}\".format(test_acc))\n",
    "        all_accuracy.append(test_acc)\n",
    "        \n",
    "        # get ground and excited indices \n",
    "        e_indices = np.where(np.argmax(y_test, axis=1) == 1)[0]\n",
    "        g_indices = np.where(np.argmax(y_test, axis=1) == 0)[0]\n",
    "\n",
    "        # separate ground and excited samples \n",
    "        Xe_test = X_test_window[e_indices]\n",
    "        ye_test = np.argmax(y_test, axis=1)[e_indices]\n",
    "\n",
    "        Xg_test = X_test_window[g_indices]\n",
    "        yg_test = np.argmax(y_test, axis=1)[g_indices]\n",
    "\n",
    "        # compute total correct for excited state \n",
    "        ye_pred = model.predict(Xe_test)\n",
    "        e_accuracy = accuracy_score(ye_test, np.argmax(ye_pred, axis=1))\n",
    "\n",
    "        total_correct = (ye_test==np.argmax(ye_pred, axis=1)).astype(np.int8).sum()\n",
    "        total_incorrect = (ye_test!=np.argmax(ye_pred, axis=1)).astype(np.int8).sum()\n",
    "\n",
    "        print(\"Total correct:\", total_correct)\n",
    "        print(\"Total incorrect:\", total_incorrect)\n",
    "        print(\"Total samples:\", len(Xe_test) )\n",
    "        print(\"Keras Excited Accuracy: {}\".format(e_accuracy))\n",
    "\n",
    "        # compute total correct for ground state \n",
    "        yg_pred = model.predict(Xg_test)\n",
    "        g_accuracy = accuracy_score(yg_test, np.argmax(yg_pred, axis=1))\n",
    "\n",
    "        total_correct = (yg_test==np.argmax(yg_pred, axis=1)).astype(np.int8).sum()\n",
    "        total_incorrect = (yg_test!=np.argmax(yg_pred, axis=1)).astype(np.int8).sum()\n",
    "\n",
    "        print(\"Total correct:\", total_correct)\n",
    "        print(\"Total incorrect:\", total_incorrect)\n",
    "        print(\"Total samples:\", len(Xg_test) )\n",
    "        print(\"Keras Ground Accuracy: {}\".format(g_accuracy))\n",
    "\n",
    "        all_e_accuracy.append(e_accuracy)\n",
    "        all_g_accuracy.append(g_accuracy)\n",
    "\n",
    "        # compute fidelity \n",
    "        fidelity = 0.5*(e_accuracy + g_accuracy)\n",
    "        all_fidelity.append(fidelity)\n",
    "        print('\\n===================================')\n",
    "        print('Fidelity', fidelity)\n",
    "        print('===================================')\n",
    "\n",
    "    return all_accuracy, all_e_accuracy, all_g_accuracy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multi-Layer Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "105/105 [==============================] - 8s 70ms/step - loss: 0.1963 - accuracy: 0.9474 - val_loss: 0.1907 - val_accuracy: 0.9533 - lr: 0.0010\n",
      "Epoch 2/50\n",
      "105/105 [==============================] - 9s 88ms/step - loss: 0.1573 - accuracy: 0.9579 - val_loss: 0.1675 - val_accuracy: 0.9548 - lr: 0.0010\n",
      "Epoch 3/50\n",
      "105/105 [==============================] - 8s 79ms/step - loss: 0.1509 - accuracy: 0.9589 - val_loss: 0.1662 - val_accuracy: 0.9552 - lr: 0.0010\n",
      "Epoch 4/50\n",
      "105/105 [==============================] - 6s 53ms/step - loss: 0.1451 - accuracy: 0.9597 - val_loss: 0.1664 - val_accuracy: 0.9551 - lr: 0.0010\n",
      "Epoch 5/50\n",
      "105/105 [==============================] - 4s 38ms/step - loss: 0.1385 - accuracy: 0.9606 - val_loss: 0.1699 - val_accuracy: 0.9545 - lr: 0.0010\n",
      "Epoch 6/50\n",
      "105/105 [==============================] - 4s 34ms/step - loss: 0.1306 - accuracy: 0.9618 - val_loss: 0.1767 - val_accuracy: 0.9540 - lr: 0.0010\n",
      "Epoch 7/50\n",
      "105/105 [==============================] - 3s 29ms/step - loss: 0.1217 - accuracy: 0.9629 - val_loss: 0.1836 - val_accuracy: 0.9530 - lr: 0.0010\n",
      "Epoch 8/50\n",
      "105/105 [==============================] - 3s 28ms/step - loss: 0.1127 - accuracy: 0.9641 - val_loss: 0.1912 - val_accuracy: 0.9524 - lr: 0.0010\n",
      "Epoch 9/50\n",
      "105/105 [==============================] - 3s 26ms/step - loss: 0.1041 - accuracy: 0.9652 - val_loss: 0.1983 - val_accuracy: 0.9520 - lr: 0.0010\n",
      "Epoch 10/50\n",
      "105/105 [==============================] - 3s 27ms/step - loss: 0.0958 - accuracy: 0.9662 - val_loss: 0.2116 - val_accuracy: 0.9510 - lr: 0.0010\n",
      "Epoch 11/50\n",
      "105/105 [==============================] - 3s 26ms/step - loss: 0.0875 - accuracy: 0.9674 - val_loss: 0.2210 - val_accuracy: 0.9499 - lr: 0.0010\n",
      "Epoch 12/50\n",
      "105/105 [==============================] - 3s 25ms/step - loss: 0.0683 - accuracy: 0.9709 - val_loss: 0.2149 - val_accuracy: 0.9512 - lr: 1.0000e-04\n",
      "Epoch 13/50\n",
      "105/105 [==============================] - 2s 24ms/step - loss: 0.0650 - accuracy: 0.9714 - val_loss: 0.2160 - val_accuracy: 0.9508 - lr: 1.0000e-04\n",
      "Epoch 14/50\n",
      "105/105 [==============================] - 2s 23ms/step - loss: 0.0634 - accuracy: 0.9716 - val_loss: 0.2183 - val_accuracy: 0.9504 - lr: 1.0000e-04\n",
      "Epoch 15/50\n",
      "105/105 [==============================] - 2s 24ms/step - loss: 0.0620 - accuracy: 0.9718 - val_loss: 0.2203 - val_accuracy: 0.9505 - lr: 1.0000e-04\n",
      "Epoch 16/50\n",
      "105/105 [==============================] - 2s 23ms/step - loss: 0.0607 - accuracy: 0.9720 - val_loss: 0.2224 - val_accuracy: 0.9505 - lr: 1.0000e-04\n",
      "Epoch 17/50\n",
      "105/105 [==============================] - 2s 23ms/step - loss: 0.0594 - accuracy: 0.9722 - val_loss: 0.2248 - val_accuracy: 0.9504 - lr: 1.0000e-04\n",
      "Epoch 18/50\n",
      "105/105 [==============================] - 2s 23ms/step - loss: 0.0583 - accuracy: 0.9723 - val_loss: 0.2273 - val_accuracy: 0.9502 - lr: 1.0000e-04\n",
      "Epoch 19/50\n",
      "105/105 [==============================] - 2s 24ms/step - loss: 0.0572 - accuracy: 0.9725 - val_loss: 0.2293 - val_accuracy: 0.9499 - lr: 1.0000e-04\n",
      "Epoch 20/50\n",
      "105/105 [==============================] - 3s 29ms/step - loss: 0.0561 - accuracy: 0.9726 - val_loss: 0.2321 - val_accuracy: 0.9500 - lr: 1.0000e-04\n",
      "Epoch 21/50\n",
      "105/105 [==============================] - 4s 37ms/step - loss: 0.0551 - accuracy: 0.9727 - val_loss: 0.2340 - val_accuracy: 0.9498 - lr: 1.0000e-04\n",
      "Epoch 22/50\n",
      "105/105 [==============================] - 4s 40ms/step - loss: 0.0531 - accuracy: 0.9733 - val_loss: 0.2339 - val_accuracy: 0.9497 - lr: 1.0000e-05\n",
      "Epoch 23/50\n",
      "105/105 [==============================] - 3s 32ms/step - loss: 0.0529 - accuracy: 0.9731 - val_loss: 0.2342 - val_accuracy: 0.9498 - lr: 1.0000e-05\n",
      "Epoch 24/50\n",
      "105/105 [==============================] - 6s 60ms/step - loss: 0.0527 - accuracy: 0.9730 - val_loss: 0.2344 - val_accuracy: 0.9497 - lr: 1.0000e-05\n",
      "Epoch 25/50\n",
      "105/105 [==============================] - 11s 105ms/step - loss: 0.0526 - accuracy: 0.9731 - val_loss: 0.2346 - val_accuracy: 0.9497 - lr: 1.0000e-05\n",
      "Epoch 26/50\n",
      "105/105 [==============================] - 4s 34ms/step - loss: 0.0525 - accuracy: 0.9731 - val_loss: 0.2349 - val_accuracy: 0.9497 - lr: 1.0000e-05\n",
      "Epoch 27/50\n",
      "105/105 [==============================] - 7s 66ms/step - loss: 0.0524 - accuracy: 0.9731 - val_loss: 0.2350 - val_accuracy: 0.9497 - lr: 1.0000e-05\n",
      "Epoch 28/50\n",
      "105/105 [==============================] - 3s 25ms/step - loss: 0.0523 - accuracy: 0.9732 - val_loss: 0.2352 - val_accuracy: 0.9498 - lr: 1.0000e-05\n",
      "Epoch 29/50\n",
      "105/105 [==============================] - 3s 31ms/step - loss: 0.0522 - accuracy: 0.9730 - val_loss: 0.2356 - val_accuracy: 0.9496 - lr: 1.0000e-05\n",
      "Epoch 30/50\n",
      "105/105 [==============================] - 3s 24ms/step - loss: 0.0520 - accuracy: 0.9731 - val_loss: 0.2358 - val_accuracy: 0.9496 - lr: 1.0000e-05\n",
      "Epoch 31/50\n",
      "105/105 [==============================] - 3s 24ms/step - loss: 0.0519 - accuracy: 0.9731 - val_loss: 0.2361 - val_accuracy: 0.9497 - lr: 1.0000e-05\n",
      "Epoch 32/50\n",
      "105/105 [==============================] - 2s 24ms/step - loss: 0.0517 - accuracy: 0.9733 - val_loss: 0.2362 - val_accuracy: 0.9497 - lr: 1.0000e-06\n",
      "Epoch 33/50\n",
      "105/105 [==============================] - 2s 23ms/step - loss: 0.0517 - accuracy: 0.9732 - val_loss: 0.2362 - val_accuracy: 0.9497 - lr: 1.0000e-06\n",
      "Epoch 34/50\n",
      "105/105 [==============================] - 2s 24ms/step - loss: 0.0517 - accuracy: 0.9732 - val_loss: 0.2362 - val_accuracy: 0.9497 - lr: 1.0000e-06\n",
      "Epoch 35/50\n",
      "105/105 [==============================] - 2s 23ms/step - loss: 0.0517 - accuracy: 0.9733 - val_loss: 0.2362 - val_accuracy: 0.9496 - lr: 1.0000e-06\n",
      "Epoch 36/50\n",
      "105/105 [==============================] - 2s 23ms/step - loss: 0.0517 - accuracy: 0.9732 - val_loss: 0.2363 - val_accuracy: 0.9497 - lr: 1.0000e-06\n",
      "Epoch 37/50\n",
      "105/105 [==============================] - 2s 23ms/step - loss: 0.0517 - accuracy: 0.9732 - val_loss: 0.2363 - val_accuracy: 0.9497 - lr: 1.0000e-06\n",
      "Epoch 38/50\n",
      "105/105 [==============================] - 2s 23ms/step - loss: 0.0516 - accuracy: 0.9732 - val_loss: 0.2363 - val_accuracy: 0.9496 - lr: 1.0000e-06\n",
      "Epoch 39/50\n",
      "105/105 [==============================] - 2s 23ms/step - loss: 0.0517 - accuracy: 0.9732 - val_loss: 0.2363 - val_accuracy: 0.9496 - lr: 1.0000e-06\n",
      "Epoch 40/50\n",
      "105/105 [==============================] - 3s 24ms/step - loss: 0.0516 - accuracy: 0.9732 - val_loss: 0.2364 - val_accuracy: 0.9496 - lr: 1.0000e-06\n",
      "Epoch 41/50\n",
      "105/105 [==============================] - 3s 25ms/step - loss: 0.0516 - accuracy: 0.9732 - val_loss: 0.2364 - val_accuracy: 0.9497 - lr: 1.0000e-06\n",
      "Epoch 42/50\n",
      "105/105 [==============================] - 3s 24ms/step - loss: 0.0516 - accuracy: 0.9732 - val_loss: 0.2364 - val_accuracy: 0.9497 - lr: 1.0000e-07\n",
      "Epoch 43/50\n",
      "105/105 [==============================] - 3s 29ms/step - loss: 0.0516 - accuracy: 0.9732 - val_loss: 0.2364 - val_accuracy: 0.9497 - lr: 1.0000e-07\n",
      "Epoch 44/50\n",
      "105/105 [==============================] - 3s 25ms/step - loss: 0.0516 - accuracy: 0.9732 - val_loss: 0.2364 - val_accuracy: 0.9497 - lr: 1.0000e-07\n",
      "Epoch 45/50\n",
      "105/105 [==============================] - 3s 24ms/step - loss: 0.0516 - accuracy: 0.9733 - val_loss: 0.2364 - val_accuracy: 0.9497 - lr: 1.0000e-07\n",
      "Epoch 46/50\n",
      "105/105 [==============================] - 3s 29ms/step - loss: 0.0516 - accuracy: 0.9732 - val_loss: 0.2364 - val_accuracy: 0.9497 - lr: 1.0000e-07\n",
      "Epoch 47/50\n",
      "105/105 [==============================] - 3s 25ms/step - loss: 0.0516 - accuracy: 0.9732 - val_loss: 0.2364 - val_accuracy: 0.9496 - lr: 1.0000e-07\n",
      "Epoch 48/50\n",
      "105/105 [==============================] - 2s 23ms/step - loss: 0.0516 - accuracy: 0.9732 - val_loss: 0.2364 - val_accuracy: 0.9496 - lr: 1.0000e-07\n",
      "Epoch 49/50\n",
      "105/105 [==============================] - 2s 23ms/step - loss: 0.0516 - accuracy: 0.9732 - val_loss: 0.2364 - val_accuracy: 0.9497 - lr: 1.0000e-07\n",
      "Epoch 50/50\n",
      "105/105 [==============================] - 2s 23ms/step - loss: 0.0516 - accuracy: 0.9733 - val_loss: 0.2364 - val_accuracy: 0.9496 - lr: 1.0000e-07\n",
      "3125/3125 [==============================] - 6s 2ms/step\n",
      "Keras  Accuracy: 0.95646\n",
      "1563/1563 [==============================] - 2s 2ms/step\n",
      "Total correct: 47219\n",
      "Total incorrect: 2781\n",
      "Total samples: 50000\n",
      "Keras Excited Accuracy: 0.94438\n",
      "1563/1563 [==============================] - 3s 2ms/step\n",
      "Total correct: 48427\n",
      "Total incorrect: 1573\n",
      "Total samples: 50000\n",
      "Keras Ground Accuracy: 0.96854\n",
      "\n",
      "===================================\n",
      "Fidelity 0.95646\n",
      "===================================\n",
      "Epoch 1/50\n",
      "105/105 [==============================] - 4s 33ms/step - loss: 0.1566 - accuracy: 0.9597 - val_loss: 0.1589 - val_accuracy: 0.9579 - lr: 0.0010\n",
      "Epoch 2/50\n",
      "105/105 [==============================] - 4s 35ms/step - loss: 0.1475 - accuracy: 0.9611 - val_loss: 0.1581 - val_accuracy: 0.9576 - lr: 0.0010\n",
      "Epoch 3/50\n",
      "105/105 [==============================] - 3s 26ms/step - loss: 0.1417 - accuracy: 0.9620 - val_loss: 0.1591 - val_accuracy: 0.9572 - lr: 0.0010\n",
      "Epoch 4/50\n",
      "105/105 [==============================] - 3s 24ms/step - loss: 0.1348 - accuracy: 0.9628 - val_loss: 0.1634 - val_accuracy: 0.9571 - lr: 0.0010\n",
      "Epoch 5/50\n",
      "105/105 [==============================] - 3s 24ms/step - loss: 0.1263 - accuracy: 0.9639 - val_loss: 0.1696 - val_accuracy: 0.9564 - lr: 0.0010\n",
      "Epoch 6/50\n",
      "105/105 [==============================] - 3s 24ms/step - loss: 0.1168 - accuracy: 0.9649 - val_loss: 0.1758 - val_accuracy: 0.9558 - lr: 0.0010\n",
      "Epoch 7/50\n",
      "105/105 [==============================] - 3s 24ms/step - loss: 0.1070 - accuracy: 0.9659 - val_loss: 0.1845 - val_accuracy: 0.9556 - lr: 0.0010\n",
      "Epoch 8/50\n",
      "105/105 [==============================] - 3s 26ms/step - loss: 0.0978 - accuracy: 0.9669 - val_loss: 0.1977 - val_accuracy: 0.9541 - lr: 0.0010\n",
      "Epoch 9/50\n",
      "105/105 [==============================] - 3s 25ms/step - loss: 0.0893 - accuracy: 0.9679 - val_loss: 0.2035 - val_accuracy: 0.9537 - lr: 0.0010\n",
      "Epoch 10/50\n",
      "105/105 [==============================] - 3s 30ms/step - loss: 0.0812 - accuracy: 0.9690 - val_loss: 0.2138 - val_accuracy: 0.9535 - lr: 0.0010\n",
      "Epoch 11/50\n",
      "105/105 [==============================] - 3s 27ms/step - loss: 0.0744 - accuracy: 0.9699 - val_loss: 0.2284 - val_accuracy: 0.9527 - lr: 0.0010\n",
      "Epoch 12/50\n",
      "105/105 [==============================] - 3s 26ms/step - loss: 0.0580 - accuracy: 0.9724 - val_loss: 0.2211 - val_accuracy: 0.9537 - lr: 1.0000e-04\n",
      "Epoch 13/50\n",
      "105/105 [==============================] - 3s 26ms/step - loss: 0.0550 - accuracy: 0.9729 - val_loss: 0.2223 - val_accuracy: 0.9534 - lr: 1.0000e-04\n",
      "Epoch 14/50\n",
      "105/105 [==============================] - 3s 27ms/step - loss: 0.0536 - accuracy: 0.9731 - val_loss: 0.2242 - val_accuracy: 0.9533 - lr: 1.0000e-04\n",
      "Epoch 15/50\n",
      "105/105 [==============================] - 3s 26ms/step - loss: 0.0524 - accuracy: 0.9731 - val_loss: 0.2271 - val_accuracy: 0.9532 - lr: 1.0000e-04\n",
      "Epoch 16/50\n",
      "105/105 [==============================] - 3s 25ms/step - loss: 0.0513 - accuracy: 0.9732 - val_loss: 0.2283 - val_accuracy: 0.9530 - lr: 1.0000e-04\n",
      "Epoch 17/50\n",
      "105/105 [==============================] - 3s 25ms/step - loss: 0.0503 - accuracy: 0.9734 - val_loss: 0.2302 - val_accuracy: 0.9532 - lr: 1.0000e-04\n",
      "Epoch 18/50\n",
      "105/105 [==============================] - 3s 25ms/step - loss: 0.0495 - accuracy: 0.9734 - val_loss: 0.2323 - val_accuracy: 0.9532 - lr: 1.0000e-04\n",
      "Epoch 19/50\n",
      "105/105 [==============================] - 3s 25ms/step - loss: 0.0486 - accuracy: 0.9735 - val_loss: 0.2343 - val_accuracy: 0.9529 - lr: 1.0000e-04\n",
      "Epoch 20/50\n",
      "105/105 [==============================] - 3s 25ms/step - loss: 0.0478 - accuracy: 0.9737 - val_loss: 0.2370 - val_accuracy: 0.9532 - lr: 1.0000e-04\n",
      "Epoch 21/50\n",
      "105/105 [==============================] - 3s 26ms/step - loss: 0.0470 - accuracy: 0.9737 - val_loss: 0.2389 - val_accuracy: 0.9529 - lr: 1.0000e-04\n",
      "Epoch 22/50\n",
      "105/105 [==============================] - 3s 26ms/step - loss: 0.0455 - accuracy: 0.9741 - val_loss: 0.2394 - val_accuracy: 0.9529 - lr: 1.0000e-05\n",
      "Epoch 23/50\n",
      "105/105 [==============================] - 3s 26ms/step - loss: 0.0453 - accuracy: 0.9739 - val_loss: 0.2394 - val_accuracy: 0.9530 - lr: 1.0000e-05\n",
      "Epoch 24/50\n",
      "105/105 [==============================] - 6s 60ms/step - loss: 0.0452 - accuracy: 0.9740 - val_loss: 0.2395 - val_accuracy: 0.9530 - lr: 1.0000e-05\n",
      "Epoch 25/50\n",
      "105/105 [==============================] - 8s 72ms/step - loss: 0.0451 - accuracy: 0.9739 - val_loss: 0.2398 - val_accuracy: 0.9530 - lr: 1.0000e-05\n",
      "Epoch 26/50\n",
      "105/105 [==============================] - 8s 73ms/step - loss: 0.0450 - accuracy: 0.9741 - val_loss: 0.2400 - val_accuracy: 0.9530 - lr: 1.0000e-05\n",
      "Epoch 27/50\n",
      "105/105 [==============================] - 8s 76ms/step - loss: 0.0449 - accuracy: 0.9739 - val_loss: 0.2403 - val_accuracy: 0.9530 - lr: 1.0000e-05\n",
      "Epoch 28/50\n",
      "105/105 [==============================] - 9s 88ms/step - loss: 0.0448 - accuracy: 0.9740 - val_loss: 0.2404 - val_accuracy: 0.9530 - lr: 1.0000e-05\n",
      "Epoch 29/50\n",
      "105/105 [==============================] - 10s 92ms/step - loss: 0.0448 - accuracy: 0.9740 - val_loss: 0.2406 - val_accuracy: 0.9530 - lr: 1.0000e-05\n",
      "Epoch 30/50\n",
      "105/105 [==============================] - 9s 85ms/step - loss: 0.0447 - accuracy: 0.9740 - val_loss: 0.2410 - val_accuracy: 0.9530 - lr: 1.0000e-05\n",
      "Epoch 31/50\n",
      "105/105 [==============================] - 9s 84ms/step - loss: 0.0446 - accuracy: 0.9740 - val_loss: 0.2412 - val_accuracy: 0.9530 - lr: 1.0000e-05\n",
      "Epoch 32/50\n",
      "105/105 [==============================] - 10s 93ms/step - loss: 0.0444 - accuracy: 0.9740 - val_loss: 0.2412 - val_accuracy: 0.9530 - lr: 1.0000e-06\n",
      "Epoch 33/50\n",
      "105/105 [==============================] - 8s 79ms/step - loss: 0.0444 - accuracy: 0.9741 - val_loss: 0.2412 - val_accuracy: 0.9530 - lr: 1.0000e-06\n",
      "Epoch 34/50\n",
      "105/105 [==============================] - 8s 75ms/step - loss: 0.0444 - accuracy: 0.9740 - val_loss: 0.2412 - val_accuracy: 0.9530 - lr: 1.0000e-06\n",
      "Epoch 35/50\n",
      "105/105 [==============================] - 8s 75ms/step - loss: 0.0444 - accuracy: 0.9741 - val_loss: 0.2413 - val_accuracy: 0.9530 - lr: 1.0000e-06\n",
      "Epoch 36/50\n",
      "105/105 [==============================] - 8s 75ms/step - loss: 0.0444 - accuracy: 0.9740 - val_loss: 0.2413 - val_accuracy: 0.9530 - lr: 1.0000e-06\n",
      "Epoch 37/50\n",
      "105/105 [==============================] - 3s 28ms/step - loss: 0.0444 - accuracy: 0.9740 - val_loss: 0.2414 - val_accuracy: 0.9531 - lr: 1.0000e-06\n",
      "Epoch 38/50\n",
      "105/105 [==============================] - 3s 26ms/step - loss: 0.0444 - accuracy: 0.9741 - val_loss: 0.2414 - val_accuracy: 0.9530 - lr: 1.0000e-06\n",
      "Epoch 39/50\n",
      "105/105 [==============================] - 3s 25ms/step - loss: 0.0444 - accuracy: 0.9740 - val_loss: 0.2414 - val_accuracy: 0.9530 - lr: 1.0000e-06\n",
      "Epoch 40/50\n",
      "105/105 [==============================] - 3s 25ms/step - loss: 0.0443 - accuracy: 0.9740 - val_loss: 0.2414 - val_accuracy: 0.9530 - lr: 1.0000e-06\n",
      "Epoch 41/50\n",
      "105/105 [==============================] - 3s 25ms/step - loss: 0.0443 - accuracy: 0.9741 - val_loss: 0.2415 - val_accuracy: 0.9530 - lr: 1.0000e-06\n",
      "Epoch 42/50\n",
      "105/105 [==============================] - 3s 25ms/step - loss: 0.0443 - accuracy: 0.9740 - val_loss: 0.2415 - val_accuracy: 0.9530 - lr: 1.0000e-07\n",
      "Epoch 43/50\n",
      "105/105 [==============================] - 3s 24ms/step - loss: 0.0443 - accuracy: 0.9740 - val_loss: 0.2415 - val_accuracy: 0.9530 - lr: 1.0000e-07\n",
      "Epoch 44/50\n",
      "105/105 [==============================] - 3s 31ms/step - loss: 0.0443 - accuracy: 0.9740 - val_loss: 0.2414 - val_accuracy: 0.9530 - lr: 1.0000e-07\n",
      "Epoch 45/50\n",
      "105/105 [==============================] - 3s 26ms/step - loss: 0.0443 - accuracy: 0.9740 - val_loss: 0.2414 - val_accuracy: 0.9530 - lr: 1.0000e-07\n",
      "Epoch 46/50\n",
      "105/105 [==============================] - 3s 31ms/step - loss: 0.0443 - accuracy: 0.9740 - val_loss: 0.2415 - val_accuracy: 0.9530 - lr: 1.0000e-07\n",
      "Epoch 47/50\n",
      "105/105 [==============================] - 3s 31ms/step - loss: 0.0444 - accuracy: 0.9740 - val_loss: 0.2415 - val_accuracy: 0.9531 - lr: 1.0000e-07\n",
      "Epoch 48/50\n",
      "105/105 [==============================] - 3s 29ms/step - loss: 0.0443 - accuracy: 0.9741 - val_loss: 0.2415 - val_accuracy: 0.9530 - lr: 1.0000e-07\n",
      "Epoch 49/50\n",
      "105/105 [==============================] - 8s 78ms/step - loss: 0.0443 - accuracy: 0.9741 - val_loss: 0.2415 - val_accuracy: 0.9530 - lr: 1.0000e-07\n",
      "Epoch 50/50\n",
      "105/105 [==============================] - 3s 31ms/step - loss: 0.0443 - accuracy: 0.9741 - val_loss: 0.2415 - val_accuracy: 0.9530 - lr: 1.0000e-07\n",
      "3125/3125 [==============================] - 5s 2ms/step\n",
      "Keras  Accuracy: 0.95971\n",
      "1563/1563 [==============================] - 2s 1ms/step\n",
      "Total correct: 47332\n",
      "Total incorrect: 2668\n",
      "Total samples: 50000\n",
      "Keras Excited Accuracy: 0.94664\n",
      "1563/1563 [==============================] - 3s 2ms/step\n",
      "Total correct: 48639\n",
      "Total incorrect: 1361\n",
      "Total samples: 50000\n",
      "Keras Ground Accuracy: 0.97278\n",
      "\n",
      "===================================\n",
      "Fidelity 0.9597100000000001\n",
      "===================================\n",
      "Epoch 1/50\n",
      "105/105 [==============================] - 5s 38ms/step - loss: 0.1538 - accuracy: 0.9607 - val_loss: 0.1563 - val_accuracy: 0.9586 - lr: 0.0010\n",
      "Epoch 2/50\n",
      "105/105 [==============================] - 3s 26ms/step - loss: 0.1467 - accuracy: 0.9617 - val_loss: 0.1561 - val_accuracy: 0.9587 - lr: 0.0010\n",
      "Epoch 3/50\n",
      "105/105 [==============================] - 3s 25ms/step - loss: 0.1415 - accuracy: 0.9625 - val_loss: 0.1568 - val_accuracy: 0.9588 - lr: 0.0010\n",
      "Epoch 4/50\n",
      "105/105 [==============================] - 3s 28ms/step - loss: 0.1352 - accuracy: 0.9632 - val_loss: 0.1606 - val_accuracy: 0.9583 - lr: 0.0010\n",
      "Epoch 5/50\n",
      "105/105 [==============================] - 4s 38ms/step - loss: 0.1269 - accuracy: 0.9639 - val_loss: 0.1656 - val_accuracy: 0.9580 - lr: 0.0010\n",
      "Epoch 6/50\n",
      "105/105 [==============================] - 4s 38ms/step - loss: 0.1177 - accuracy: 0.9648 - val_loss: 0.1732 - val_accuracy: 0.9573 - lr: 0.0010\n",
      "Epoch 7/50\n",
      "105/105 [==============================] - 3s 26ms/step - loss: 0.1081 - accuracy: 0.9656 - val_loss: 0.1819 - val_accuracy: 0.9571 - lr: 0.0010\n",
      "Epoch 8/50\n",
      "105/105 [==============================] - 3s 25ms/step - loss: 0.0989 - accuracy: 0.9665 - val_loss: 0.1884 - val_accuracy: 0.9560 - lr: 0.0010\n",
      "Epoch 9/50\n",
      "105/105 [==============================] - 3s 24ms/step - loss: 0.0907 - accuracy: 0.9675 - val_loss: 0.1981 - val_accuracy: 0.9561 - lr: 0.0010\n",
      "Epoch 10/50\n",
      "105/105 [==============================] - 3s 25ms/step - loss: 0.0831 - accuracy: 0.9684 - val_loss: 0.2071 - val_accuracy: 0.9550 - lr: 0.0010\n",
      "Epoch 11/50\n",
      "105/105 [==============================] - 3s 25ms/step - loss: 0.0770 - accuracy: 0.9693 - val_loss: 0.2152 - val_accuracy: 0.9547 - lr: 0.0010\n",
      "Epoch 12/50\n",
      "105/105 [==============================] - 3s 25ms/step - loss: 0.0613 - accuracy: 0.9715 - val_loss: 0.2118 - val_accuracy: 0.9553 - lr: 1.0000e-04\n",
      "Epoch 13/50\n",
      "105/105 [==============================] - 3s 25ms/step - loss: 0.0585 - accuracy: 0.9719 - val_loss: 0.2131 - val_accuracy: 0.9552 - lr: 1.0000e-04\n",
      "Epoch 14/50\n",
      "105/105 [==============================] - 3s 26ms/step - loss: 0.0572 - accuracy: 0.9720 - val_loss: 0.2148 - val_accuracy: 0.9553 - lr: 1.0000e-04\n",
      "Epoch 15/50\n",
      "105/105 [==============================] - 3s 25ms/step - loss: 0.0561 - accuracy: 0.9721 - val_loss: 0.2164 - val_accuracy: 0.9552 - lr: 1.0000e-04\n",
      "Epoch 16/50\n",
      "105/105 [==============================] - 3s 25ms/step - loss: 0.0551 - accuracy: 0.9722 - val_loss: 0.2182 - val_accuracy: 0.9552 - lr: 1.0000e-04\n",
      "Epoch 17/50\n",
      "105/105 [==============================] - 3s 25ms/step - loss: 0.0542 - accuracy: 0.9723 - val_loss: 0.2197 - val_accuracy: 0.9550 - lr: 1.0000e-04\n",
      "Epoch 18/50\n",
      "105/105 [==============================] - 3s 25ms/step - loss: 0.0534 - accuracy: 0.9724 - val_loss: 0.2218 - val_accuracy: 0.9551 - lr: 1.0000e-04\n",
      "Epoch 19/50\n",
      "105/105 [==============================] - 3s 26ms/step - loss: 0.0525 - accuracy: 0.9725 - val_loss: 0.2235 - val_accuracy: 0.9550 - lr: 1.0000e-04\n",
      "Epoch 20/50\n",
      "105/105 [==============================] - 2s 24ms/step - loss: 0.0517 - accuracy: 0.9726 - val_loss: 0.2248 - val_accuracy: 0.9550 - lr: 1.0000e-04\n",
      "Epoch 21/50\n",
      "105/105 [==============================] - 3s 24ms/step - loss: 0.0510 - accuracy: 0.9727 - val_loss: 0.2270 - val_accuracy: 0.9550 - lr: 1.0000e-04\n",
      "Epoch 22/50\n",
      "105/105 [==============================] - 3s 25ms/step - loss: 0.0496 - accuracy: 0.9730 - val_loss: 0.2272 - val_accuracy: 0.9551 - lr: 1.0000e-05\n",
      "Epoch 23/50\n",
      "105/105 [==============================] - 3s 24ms/step - loss: 0.0494 - accuracy: 0.9729 - val_loss: 0.2274 - val_accuracy: 0.9552 - lr: 1.0000e-05\n",
      "Epoch 24/50\n",
      "105/105 [==============================] - 3s 24ms/step - loss: 0.0493 - accuracy: 0.9729 - val_loss: 0.2276 - val_accuracy: 0.9551 - lr: 1.0000e-05\n",
      "Epoch 25/50\n",
      "105/105 [==============================] - 3s 24ms/step - loss: 0.0492 - accuracy: 0.9730 - val_loss: 0.2277 - val_accuracy: 0.9551 - lr: 1.0000e-05\n",
      "Epoch 26/50\n",
      "105/105 [==============================] - 3s 25ms/step - loss: 0.0491 - accuracy: 0.9728 - val_loss: 0.2279 - val_accuracy: 0.9550 - lr: 1.0000e-05\n",
      "Epoch 27/50\n",
      "105/105 [==============================] - 3s 24ms/step - loss: 0.0491 - accuracy: 0.9729 - val_loss: 0.2281 - val_accuracy: 0.9550 - lr: 1.0000e-05\n",
      "Epoch 28/50\n",
      "105/105 [==============================] - 3s 24ms/step - loss: 0.0490 - accuracy: 0.9729 - val_loss: 0.2283 - val_accuracy: 0.9550 - lr: 1.0000e-05\n",
      "Epoch 29/50\n",
      "105/105 [==============================] - 3s 24ms/step - loss: 0.0489 - accuracy: 0.9730 - val_loss: 0.2285 - val_accuracy: 0.9550 - lr: 1.0000e-05\n",
      "Epoch 30/50\n",
      "105/105 [==============================] - 3s 25ms/step - loss: 0.0488 - accuracy: 0.9729 - val_loss: 0.2286 - val_accuracy: 0.9550 - lr: 1.0000e-05\n",
      "Epoch 31/50\n",
      "105/105 [==============================] - 3s 24ms/step - loss: 0.0488 - accuracy: 0.9730 - val_loss: 0.2289 - val_accuracy: 0.9550 - lr: 1.0000e-05\n",
      "Epoch 32/50\n",
      "105/105 [==============================] - 3s 25ms/step - loss: 0.0486 - accuracy: 0.9728 - val_loss: 0.2289 - val_accuracy: 0.9550 - lr: 1.0000e-06\n",
      "Epoch 33/50\n",
      "105/105 [==============================] - 3s 24ms/step - loss: 0.0486 - accuracy: 0.9728 - val_loss: 0.2290 - val_accuracy: 0.9550 - lr: 1.0000e-06\n",
      "Epoch 34/50\n",
      "105/105 [==============================] - 3s 24ms/step - loss: 0.0486 - accuracy: 0.9729 - val_loss: 0.2290 - val_accuracy: 0.9550 - lr: 1.0000e-06\n",
      "Epoch 35/50\n",
      "105/105 [==============================] - 3s 25ms/step - loss: 0.0486 - accuracy: 0.9729 - val_loss: 0.2290 - val_accuracy: 0.9550 - lr: 1.0000e-06\n",
      "Epoch 36/50\n",
      "105/105 [==============================] - 3s 25ms/step - loss: 0.0485 - accuracy: 0.9730 - val_loss: 0.2291 - val_accuracy: 0.9550 - lr: 1.0000e-06\n",
      "Epoch 37/50\n",
      "105/105 [==============================] - 3s 25ms/step - loss: 0.0486 - accuracy: 0.9730 - val_loss: 0.2291 - val_accuracy: 0.9550 - lr: 1.0000e-06\n",
      "Epoch 38/50\n",
      "105/105 [==============================] - 3s 24ms/step - loss: 0.0485 - accuracy: 0.9730 - val_loss: 0.2291 - val_accuracy: 0.9550 - lr: 1.0000e-06\n",
      "Epoch 39/50\n",
      "105/105 [==============================] - 3s 24ms/step - loss: 0.0485 - accuracy: 0.9729 - val_loss: 0.2292 - val_accuracy: 0.9550 - lr: 1.0000e-06\n",
      "Epoch 40/50\n",
      "105/105 [==============================] - 3s 28ms/step - loss: 0.0486 - accuracy: 0.9730 - val_loss: 0.2292 - val_accuracy: 0.9550 - lr: 1.0000e-06\n",
      "Epoch 41/50\n",
      "105/105 [==============================] - 3s 26ms/step - loss: 0.0485 - accuracy: 0.9730 - val_loss: 0.2292 - val_accuracy: 0.9550 - lr: 1.0000e-06\n",
      "Epoch 42/50\n",
      "105/105 [==============================] - 3s 24ms/step - loss: 0.0485 - accuracy: 0.9730 - val_loss: 0.2292 - val_accuracy: 0.9550 - lr: 1.0000e-07\n",
      "Epoch 43/50\n",
      "105/105 [==============================] - 3s 24ms/step - loss: 0.0485 - accuracy: 0.9729 - val_loss: 0.2292 - val_accuracy: 0.9550 - lr: 1.0000e-07\n",
      "Epoch 44/50\n",
      "105/105 [==============================] - 3s 24ms/step - loss: 0.0485 - accuracy: 0.9730 - val_loss: 0.2292 - val_accuracy: 0.9550 - lr: 1.0000e-07\n",
      "Epoch 45/50\n",
      "105/105 [==============================] - 3s 25ms/step - loss: 0.0485 - accuracy: 0.9730 - val_loss: 0.2292 - val_accuracy: 0.9550 - lr: 1.0000e-07\n",
      "Epoch 46/50\n",
      "105/105 [==============================] - 3s 24ms/step - loss: 0.0485 - accuracy: 0.9729 - val_loss: 0.2292 - val_accuracy: 0.9550 - lr: 1.0000e-07\n",
      "Epoch 47/50\n",
      "105/105 [==============================] - 3s 24ms/step - loss: 0.0485 - accuracy: 0.9730 - val_loss: 0.2292 - val_accuracy: 0.9550 - lr: 1.0000e-07\n",
      "Epoch 48/50\n",
      "105/105 [==============================] - 3s 28ms/step - loss: 0.0485 - accuracy: 0.9729 - val_loss: 0.2292 - val_accuracy: 0.9550 - lr: 1.0000e-07\n",
      "Epoch 49/50\n",
      "105/105 [==============================] - 3s 24ms/step - loss: 0.0485 - accuracy: 0.9730 - val_loss: 0.2292 - val_accuracy: 0.9550 - lr: 1.0000e-07\n",
      "Epoch 50/50\n",
      "105/105 [==============================] - 3s 24ms/step - loss: 0.0485 - accuracy: 0.9730 - val_loss: 0.2292 - val_accuracy: 0.9550 - lr: 1.0000e-07\n",
      "3125/3125 [==============================] - 5s 2ms/step\n",
      "Keras  Accuracy: 0.96031\n",
      "1563/1563 [==============================] - 3s 2ms/step\n",
      "Total correct: 47299\n",
      "Total incorrect: 2701\n",
      "Total samples: 50000\n",
      "Keras Excited Accuracy: 0.94598\n",
      "1563/1563 [==============================] - 3s 2ms/step\n",
      "Total correct: 48732\n",
      "Total incorrect: 1268\n",
      "Total samples: 50000\n",
      "Keras Ground Accuracy: 0.97464\n",
      "\n",
      "===================================\n",
      "Fidelity 0.96031\n",
      "===================================\n",
      "Epoch 1/50\n",
      "105/105 [==============================] - 3s 26ms/step - loss: 0.1561 - accuracy: 0.9598 - val_loss: 0.1586 - val_accuracy: 0.9579 - lr: 0.0010\n",
      "Epoch 2/50\n",
      "105/105 [==============================] - 2s 24ms/step - loss: 0.1503 - accuracy: 0.9608 - val_loss: 0.1587 - val_accuracy: 0.9579 - lr: 0.0010\n",
      "Epoch 3/50\n",
      "105/105 [==============================] - 2s 24ms/step - loss: 0.1457 - accuracy: 0.9614 - val_loss: 0.1602 - val_accuracy: 0.9577 - lr: 0.0010\n",
      "Epoch 4/50\n",
      "105/105 [==============================] - 3s 24ms/step - loss: 0.1395 - accuracy: 0.9621 - val_loss: 0.1635 - val_accuracy: 0.9578 - lr: 0.0010\n",
      "Epoch 5/50\n",
      "105/105 [==============================] - 3s 24ms/step - loss: 0.1314 - accuracy: 0.9628 - val_loss: 0.1700 - val_accuracy: 0.9568 - lr: 0.0010\n",
      "Epoch 6/50\n",
      "105/105 [==============================] - 3s 24ms/step - loss: 0.1220 - accuracy: 0.9635 - val_loss: 0.1777 - val_accuracy: 0.9561 - lr: 0.0010\n",
      "Epoch 7/50\n",
      "105/105 [==============================] - 3s 25ms/step - loss: 0.1124 - accuracy: 0.9643 - val_loss: 0.1843 - val_accuracy: 0.9559 - lr: 0.0010\n",
      "Epoch 8/50\n",
      "105/105 [==============================] - 3s 24ms/step - loss: 0.1033 - accuracy: 0.9652 - val_loss: 0.1928 - val_accuracy: 0.9555 - lr: 0.0010\n",
      "Epoch 9/50\n",
      "105/105 [==============================] - 3s 24ms/step - loss: 0.0949 - accuracy: 0.9662 - val_loss: 0.2023 - val_accuracy: 0.9552 - lr: 0.0010\n",
      "Epoch 10/50\n",
      "105/105 [==============================] - 3s 25ms/step - loss: 0.0875 - accuracy: 0.9671 - val_loss: 0.2108 - val_accuracy: 0.9545 - lr: 0.0010\n",
      "Epoch 11/50\n",
      "105/105 [==============================] - 2s 24ms/step - loss: 0.0814 - accuracy: 0.9680 - val_loss: 0.2183 - val_accuracy: 0.9536 - lr: 0.0010\n",
      "Epoch 12/50\n",
      "105/105 [==============================] - 2s 24ms/step - loss: 0.0664 - accuracy: 0.9700 - val_loss: 0.2152 - val_accuracy: 0.9543 - lr: 1.0000e-04\n",
      "Epoch 13/50\n",
      "105/105 [==============================] - 3s 24ms/step - loss: 0.0637 - accuracy: 0.9704 - val_loss: 0.2173 - val_accuracy: 0.9545 - lr: 1.0000e-04\n",
      "Epoch 14/50\n",
      "105/105 [==============================] - 3s 25ms/step - loss: 0.0625 - accuracy: 0.9705 - val_loss: 0.2183 - val_accuracy: 0.9544 - lr: 1.0000e-04\n",
      "Epoch 15/50\n",
      "105/105 [==============================] - 3s 24ms/step - loss: 0.0615 - accuracy: 0.9706 - val_loss: 0.2195 - val_accuracy: 0.9544 - lr: 1.0000e-04\n",
      "Epoch 16/50\n",
      "105/105 [==============================] - 3s 24ms/step - loss: 0.0606 - accuracy: 0.9706 - val_loss: 0.2219 - val_accuracy: 0.9544 - lr: 1.0000e-04\n",
      "Epoch 17/50\n",
      "105/105 [==============================] - 3s 24ms/step - loss: 0.0597 - accuracy: 0.9708 - val_loss: 0.2235 - val_accuracy: 0.9544 - lr: 1.0000e-04\n",
      "Epoch 18/50\n",
      "105/105 [==============================] - 3s 25ms/step - loss: 0.0589 - accuracy: 0.9708 - val_loss: 0.2247 - val_accuracy: 0.9544 - lr: 1.0000e-04\n",
      "Epoch 19/50\n",
      "105/105 [==============================] - 3s 25ms/step - loss: 0.0580 - accuracy: 0.9709 - val_loss: 0.2266 - val_accuracy: 0.9541 - lr: 1.0000e-04\n",
      "Epoch 20/50\n",
      "105/105 [==============================] - 3s 24ms/step - loss: 0.0573 - accuracy: 0.9711 - val_loss: 0.2281 - val_accuracy: 0.9543 - lr: 1.0000e-04\n",
      "Epoch 21/50\n",
      "105/105 [==============================] - 3s 25ms/step - loss: 0.0566 - accuracy: 0.9711 - val_loss: 0.2297 - val_accuracy: 0.9542 - lr: 1.0000e-04\n",
      "Epoch 22/50\n",
      "105/105 [==============================] - 3s 24ms/step - loss: 0.0552 - accuracy: 0.9715 - val_loss: 0.2300 - val_accuracy: 0.9542 - lr: 1.0000e-05\n",
      "Epoch 23/50\n",
      "105/105 [==============================] - 3s 25ms/step - loss: 0.0551 - accuracy: 0.9712 - val_loss: 0.2302 - val_accuracy: 0.9542 - lr: 1.0000e-05\n",
      "Epoch 24/50\n",
      "105/105 [==============================] - 3s 24ms/step - loss: 0.0549 - accuracy: 0.9713 - val_loss: 0.2303 - val_accuracy: 0.9542 - lr: 1.0000e-05\n",
      "Epoch 25/50\n",
      "105/105 [==============================] - 3s 25ms/step - loss: 0.0549 - accuracy: 0.9713 - val_loss: 0.2306 - val_accuracy: 0.9542 - lr: 1.0000e-05\n",
      "Epoch 26/50\n",
      "105/105 [==============================] - 3s 25ms/step - loss: 0.0548 - accuracy: 0.9713 - val_loss: 0.2308 - val_accuracy: 0.9542 - lr: 1.0000e-05\n",
      "Epoch 27/50\n",
      "105/105 [==============================] - 3s 25ms/step - loss: 0.0547 - accuracy: 0.9714 - val_loss: 0.2310 - val_accuracy: 0.9543 - lr: 1.0000e-05\n",
      "Epoch 28/50\n",
      "105/105 [==============================] - 3s 24ms/step - loss: 0.0546 - accuracy: 0.9714 - val_loss: 0.2310 - val_accuracy: 0.9543 - lr: 1.0000e-05\n",
      "Epoch 29/50\n",
      "105/105 [==============================] - 3s 24ms/step - loss: 0.0545 - accuracy: 0.9713 - val_loss: 0.2312 - val_accuracy: 0.9543 - lr: 1.0000e-05\n",
      "Epoch 30/50\n",
      "105/105 [==============================] - 3s 24ms/step - loss: 0.0545 - accuracy: 0.9713 - val_loss: 0.2314 - val_accuracy: 0.9542 - lr: 1.0000e-05\n",
      "Epoch 31/50\n",
      "105/105 [==============================] - 2s 24ms/step - loss: 0.0544 - accuracy: 0.9714 - val_loss: 0.2315 - val_accuracy: 0.9542 - lr: 1.0000e-05\n",
      "Epoch 32/50\n",
      "105/105 [==============================] - 3s 24ms/step - loss: 0.0543 - accuracy: 0.9715 - val_loss: 0.2316 - val_accuracy: 0.9542 - lr: 1.0000e-06\n",
      "Epoch 33/50\n",
      "105/105 [==============================] - 3s 24ms/step - loss: 0.0542 - accuracy: 0.9715 - val_loss: 0.2316 - val_accuracy: 0.9542 - lr: 1.0000e-06\n",
      "Epoch 34/50\n",
      "105/105 [==============================] - 3s 24ms/step - loss: 0.0542 - accuracy: 0.9715 - val_loss: 0.2316 - val_accuracy: 0.9542 - lr: 1.0000e-06\n",
      "Epoch 35/50\n",
      "105/105 [==============================] - 2s 24ms/step - loss: 0.0542 - accuracy: 0.9714 - val_loss: 0.2316 - val_accuracy: 0.9542 - lr: 1.0000e-06\n",
      "Epoch 36/50\n",
      "105/105 [==============================] - 3s 24ms/step - loss: 0.0542 - accuracy: 0.9714 - val_loss: 0.2317 - val_accuracy: 0.9542 - lr: 1.0000e-06\n",
      "Epoch 37/50\n",
      "105/105 [==============================] - 2s 24ms/step - loss: 0.0542 - accuracy: 0.9715 - val_loss: 0.2317 - val_accuracy: 0.9542 - lr: 1.0000e-06\n",
      "Epoch 38/50\n",
      "105/105 [==============================] - 3s 24ms/step - loss: 0.0542 - accuracy: 0.9714 - val_loss: 0.2317 - val_accuracy: 0.9542 - lr: 1.0000e-06\n",
      "Epoch 39/50\n",
      "105/105 [==============================] - 3s 24ms/step - loss: 0.0542 - accuracy: 0.9714 - val_loss: 0.2317 - val_accuracy: 0.9542 - lr: 1.0000e-06\n",
      "Epoch 40/50\n",
      "105/105 [==============================] - 3s 25ms/step - loss: 0.0542 - accuracy: 0.9714 - val_loss: 0.2318 - val_accuracy: 0.9542 - lr: 1.0000e-06\n",
      "Epoch 41/50\n",
      "105/105 [==============================] - 3s 25ms/step - loss: 0.0542 - accuracy: 0.9714 - val_loss: 0.2318 - val_accuracy: 0.9542 - lr: 1.0000e-06\n",
      "Epoch 42/50\n",
      "105/105 [==============================] - 3s 24ms/step - loss: 0.0542 - accuracy: 0.9715 - val_loss: 0.2318 - val_accuracy: 0.9542 - lr: 1.0000e-07\n",
      "Epoch 43/50\n",
      "105/105 [==============================] - 3s 24ms/step - loss: 0.0542 - accuracy: 0.9713 - val_loss: 0.2317 - val_accuracy: 0.9542 - lr: 1.0000e-07\n",
      "Epoch 44/50\n",
      "105/105 [==============================] - 3s 24ms/step - loss: 0.0542 - accuracy: 0.9713 - val_loss: 0.2318 - val_accuracy: 0.9542 - lr: 1.0000e-07\n",
      "Epoch 45/50\n",
      "105/105 [==============================] - 3s 24ms/step - loss: 0.0542 - accuracy: 0.9714 - val_loss: 0.2318 - val_accuracy: 0.9542 - lr: 1.0000e-07\n",
      "Epoch 46/50\n",
      "105/105 [==============================] - 3s 24ms/step - loss: 0.0542 - accuracy: 0.9714 - val_loss: 0.2318 - val_accuracy: 0.9542 - lr: 1.0000e-07\n",
      "Epoch 47/50\n",
      "105/105 [==============================] - 3s 24ms/step - loss: 0.0542 - accuracy: 0.9714 - val_loss: 0.2318 - val_accuracy: 0.9542 - lr: 1.0000e-07\n",
      "Epoch 48/50\n",
      "105/105 [==============================] - 3s 24ms/step - loss: 0.0542 - accuracy: 0.9713 - val_loss: 0.2318 - val_accuracy: 0.9542 - lr: 1.0000e-07\n",
      "Epoch 49/50\n",
      "105/105 [==============================] - 3s 25ms/step - loss: 0.0542 - accuracy: 0.9714 - val_loss: 0.2318 - val_accuracy: 0.9542 - lr: 1.0000e-07\n",
      "Epoch 50/50\n",
      "105/105 [==============================] - 2s 24ms/step - loss: 0.0542 - accuracy: 0.9715 - val_loss: 0.2318 - val_accuracy: 0.9542 - lr: 1.0000e-07\n",
      "3125/3125 [==============================] - 5s 2ms/step\n",
      "Keras  Accuracy: 0.95946\n",
      "1563/1563 [==============================] - 3s 2ms/step\n",
      "Total correct: 47164\n",
      "Total incorrect: 2836\n",
      "Total samples: 50000\n",
      "Keras Excited Accuracy: 0.94328\n",
      "1563/1563 [==============================] - 3s 2ms/step\n",
      "Total correct: 48782\n",
      "Total incorrect: 1218\n",
      "Total samples: 50000\n",
      "Keras Ground Accuracy: 0.97564\n",
      "\n",
      "===================================\n",
      "Fidelity 0.95946\n",
      "===================================\n",
      "Epoch 1/50\n",
      "105/105 [==============================] - 3s 25ms/step - loss: 0.1623 - accuracy: 0.9579 - val_loss: 0.1645 - val_accuracy: 0.9562 - lr: 0.0010\n",
      "Epoch 2/50\n",
      "105/105 [==============================] - 2s 23ms/step - loss: 0.1564 - accuracy: 0.9588 - val_loss: 0.1650 - val_accuracy: 0.9559 - lr: 0.0010\n",
      "Epoch 3/50\n",
      "105/105 [==============================] - 2s 23ms/step - loss: 0.1518 - accuracy: 0.9594 - val_loss: 0.1673 - val_accuracy: 0.9557 - lr: 0.0010\n",
      "Epoch 4/50\n",
      "105/105 [==============================] - 2s 23ms/step - loss: 0.1454 - accuracy: 0.9601 - val_loss: 0.1709 - val_accuracy: 0.9556 - lr: 0.0010\n",
      "Epoch 5/50\n",
      "105/105 [==============================] - 2s 23ms/step - loss: 0.1372 - accuracy: 0.9607 - val_loss: 0.1760 - val_accuracy: 0.9553 - lr: 0.0010\n",
      "Epoch 6/50\n",
      "105/105 [==============================] - 2s 23ms/step - loss: 0.1276 - accuracy: 0.9613 - val_loss: 0.1854 - val_accuracy: 0.9551 - lr: 0.0010\n",
      "Epoch 7/50\n",
      "105/105 [==============================] - 2s 23ms/step - loss: 0.1179 - accuracy: 0.9621 - val_loss: 0.1913 - val_accuracy: 0.9542 - lr: 0.0010\n",
      "Epoch 8/50\n",
      "105/105 [==============================] - 2s 23ms/step - loss: 0.1091 - accuracy: 0.9630 - val_loss: 0.2001 - val_accuracy: 0.9536 - lr: 0.0010\n",
      "Epoch 9/50\n",
      "105/105 [==============================] - 2s 23ms/step - loss: 0.1008 - accuracy: 0.9639 - val_loss: 0.2082 - val_accuracy: 0.9529 - lr: 0.0010\n",
      "Epoch 10/50\n",
      "105/105 [==============================] - 2s 23ms/step - loss: 0.0939 - accuracy: 0.9648 - val_loss: 0.2167 - val_accuracy: 0.9530 - lr: 0.0010\n",
      "Epoch 11/50\n",
      "105/105 [==============================] - 2s 23ms/step - loss: 0.0872 - accuracy: 0.9656 - val_loss: 0.2247 - val_accuracy: 0.9520 - lr: 0.0010\n",
      "Epoch 12/50\n",
      "105/105 [==============================] - 2s 23ms/step - loss: 0.0721 - accuracy: 0.9677 - val_loss: 0.2217 - val_accuracy: 0.9534 - lr: 1.0000e-04\n",
      "Epoch 13/50\n",
      "105/105 [==============================] - 2s 23ms/step - loss: 0.0694 - accuracy: 0.9680 - val_loss: 0.2231 - val_accuracy: 0.9533 - lr: 1.0000e-04\n",
      "Epoch 14/50\n",
      "105/105 [==============================] - 2s 23ms/step - loss: 0.0682 - accuracy: 0.9682 - val_loss: 0.2245 - val_accuracy: 0.9533 - lr: 1.0000e-04\n",
      "Epoch 15/50\n",
      "105/105 [==============================] - 2s 23ms/step - loss: 0.0671 - accuracy: 0.9681 - val_loss: 0.2263 - val_accuracy: 0.9532 - lr: 1.0000e-04\n",
      "Epoch 16/50\n",
      "105/105 [==============================] - 2s 23ms/step - loss: 0.0661 - accuracy: 0.9683 - val_loss: 0.2280 - val_accuracy: 0.9534 - lr: 1.0000e-04\n",
      "Epoch 17/50\n",
      "105/105 [==============================] - 2s 23ms/step - loss: 0.0652 - accuracy: 0.9684 - val_loss: 0.2297 - val_accuracy: 0.9534 - lr: 1.0000e-04\n",
      "Epoch 18/50\n",
      "105/105 [==============================] - 2s 23ms/step - loss: 0.0644 - accuracy: 0.9685 - val_loss: 0.2315 - val_accuracy: 0.9532 - lr: 1.0000e-04\n",
      "Epoch 19/50\n",
      "105/105 [==============================] - 2s 23ms/step - loss: 0.0636 - accuracy: 0.9686 - val_loss: 0.2326 - val_accuracy: 0.9528 - lr: 1.0000e-04\n",
      "Epoch 20/50\n",
      "105/105 [==============================] - 2s 24ms/step - loss: 0.0628 - accuracy: 0.9686 - val_loss: 0.2342 - val_accuracy: 0.9531 - lr: 1.0000e-04\n",
      "Epoch 21/50\n",
      "105/105 [==============================] - 2s 23ms/step - loss: 0.0621 - accuracy: 0.9687 - val_loss: 0.2362 - val_accuracy: 0.9528 - lr: 1.0000e-04\n",
      "Epoch 22/50\n",
      "105/105 [==============================] - 2s 23ms/step - loss: 0.0607 - accuracy: 0.9692 - val_loss: 0.2363 - val_accuracy: 0.9530 - lr: 1.0000e-05\n",
      "Epoch 23/50\n",
      "105/105 [==============================] - 2s 24ms/step - loss: 0.0604 - accuracy: 0.9690 - val_loss: 0.2364 - val_accuracy: 0.9531 - lr: 1.0000e-05\n",
      "Epoch 24/50\n",
      "105/105 [==============================] - 2s 23ms/step - loss: 0.0603 - accuracy: 0.9688 - val_loss: 0.2365 - val_accuracy: 0.9529 - lr: 1.0000e-05\n",
      "Epoch 25/50\n",
      "105/105 [==============================] - 2s 24ms/step - loss: 0.0602 - accuracy: 0.9690 - val_loss: 0.2367 - val_accuracy: 0.9530 - lr: 1.0000e-05\n",
      "Epoch 26/50\n",
      "105/105 [==============================] - 2s 23ms/step - loss: 0.0602 - accuracy: 0.9690 - val_loss: 0.2369 - val_accuracy: 0.9530 - lr: 1.0000e-05\n",
      "Epoch 27/50\n",
      "105/105 [==============================] - 3s 24ms/step - loss: 0.0601 - accuracy: 0.9689 - val_loss: 0.2371 - val_accuracy: 0.9530 - lr: 1.0000e-05\n",
      "Epoch 28/50\n",
      "105/105 [==============================] - 3s 24ms/step - loss: 0.0600 - accuracy: 0.9689 - val_loss: 0.2373 - val_accuracy: 0.9530 - lr: 1.0000e-05\n",
      "Epoch 29/50\n",
      "105/105 [==============================] - 3s 25ms/step - loss: 0.0599 - accuracy: 0.9690 - val_loss: 0.2374 - val_accuracy: 0.9529 - lr: 1.0000e-05\n",
      "Epoch 30/50\n",
      "105/105 [==============================] - 3s 24ms/step - loss: 0.0599 - accuracy: 0.9690 - val_loss: 0.2375 - val_accuracy: 0.9530 - lr: 1.0000e-05\n",
      "Epoch 31/50\n",
      "105/105 [==============================] - 3s 24ms/step - loss: 0.0598 - accuracy: 0.9690 - val_loss: 0.2378 - val_accuracy: 0.9530 - lr: 1.0000e-05\n",
      "Epoch 32/50\n",
      "105/105 [==============================] - 3s 24ms/step - loss: 0.0597 - accuracy: 0.9689 - val_loss: 0.2378 - val_accuracy: 0.9530 - lr: 1.0000e-06\n",
      "Epoch 33/50\n",
      "105/105 [==============================] - 3s 25ms/step - loss: 0.0596 - accuracy: 0.9690 - val_loss: 0.2378 - val_accuracy: 0.9530 - lr: 1.0000e-06\n",
      "Epoch 34/50\n",
      "105/105 [==============================] - 3s 24ms/step - loss: 0.0596 - accuracy: 0.9691 - val_loss: 0.2378 - val_accuracy: 0.9530 - lr: 1.0000e-06\n",
      "Epoch 35/50\n",
      "105/105 [==============================] - 3s 27ms/step - loss: 0.0596 - accuracy: 0.9690 - val_loss: 0.2378 - val_accuracy: 0.9530 - lr: 1.0000e-06\n",
      "Epoch 36/50\n",
      "105/105 [==============================] - 5s 48ms/step - loss: 0.0596 - accuracy: 0.9690 - val_loss: 0.2379 - val_accuracy: 0.9530 - lr: 1.0000e-06\n",
      "Epoch 37/50\n",
      "105/105 [==============================] - 3s 26ms/step - loss: 0.0596 - accuracy: 0.9690 - val_loss: 0.2379 - val_accuracy: 0.9530 - lr: 1.0000e-06\n",
      "Epoch 38/50\n",
      "105/105 [==============================] - 3s 25ms/step - loss: 0.0596 - accuracy: 0.9690 - val_loss: 0.2379 - val_accuracy: 0.9530 - lr: 1.0000e-06\n",
      "Epoch 39/50\n",
      "105/105 [==============================] - 3s 24ms/step - loss: 0.0596 - accuracy: 0.9690 - val_loss: 0.2379 - val_accuracy: 0.9530 - lr: 1.0000e-06\n",
      "Epoch 40/50\n",
      "105/105 [==============================] - 3s 24ms/step - loss: 0.0596 - accuracy: 0.9689 - val_loss: 0.2379 - val_accuracy: 0.9530 - lr: 1.0000e-06\n",
      "Epoch 41/50\n",
      "105/105 [==============================] - 3s 24ms/step - loss: 0.0596 - accuracy: 0.9690 - val_loss: 0.2380 - val_accuracy: 0.9530 - lr: 1.0000e-06\n",
      "Epoch 42/50\n",
      "105/105 [==============================] - 3s 24ms/step - loss: 0.0596 - accuracy: 0.9690 - val_loss: 0.2380 - val_accuracy: 0.9530 - lr: 1.0000e-07\n",
      "Epoch 43/50\n",
      "105/105 [==============================] - 3s 24ms/step - loss: 0.0595 - accuracy: 0.9691 - val_loss: 0.2380 - val_accuracy: 0.9530 - lr: 1.0000e-07\n",
      "Epoch 44/50\n",
      "105/105 [==============================] - 3s 24ms/step - loss: 0.0596 - accuracy: 0.9690 - val_loss: 0.2380 - val_accuracy: 0.9530 - lr: 1.0000e-07\n",
      "Epoch 45/50\n",
      "105/105 [==============================] - 3s 24ms/step - loss: 0.0595 - accuracy: 0.9690 - val_loss: 0.2380 - val_accuracy: 0.9530 - lr: 1.0000e-07\n",
      "Epoch 46/50\n",
      "105/105 [==============================] - 4s 39ms/step - loss: 0.0596 - accuracy: 0.9691 - val_loss: 0.2380 - val_accuracy: 0.9530 - lr: 1.0000e-07\n",
      "Epoch 47/50\n",
      "105/105 [==============================] - 3s 30ms/step - loss: 0.0596 - accuracy: 0.9691 - val_loss: 0.2380 - val_accuracy: 0.9530 - lr: 1.0000e-07\n",
      "Epoch 48/50\n",
      "105/105 [==============================] - 2s 23ms/step - loss: 0.0595 - accuracy: 0.9690 - val_loss: 0.2380 - val_accuracy: 0.9530 - lr: 1.0000e-07\n",
      "Epoch 49/50\n",
      "105/105 [==============================] - 2s 23ms/step - loss: 0.0595 - accuracy: 0.9691 - val_loss: 0.2380 - val_accuracy: 0.9530 - lr: 1.0000e-07\n",
      "Epoch 50/50\n",
      "105/105 [==============================] - 2s 23ms/step - loss: 0.0595 - accuracy: 0.9691 - val_loss: 0.2380 - val_accuracy: 0.9530 - lr: 1.0000e-07\n",
      "3125/3125 [==============================] - 6s 2ms/step\n",
      "Keras  Accuracy: 0.9571\n",
      "1563/1563 [==============================] - 3s 2ms/step\n",
      "Total correct: 46924\n",
      "Total incorrect: 3076\n",
      "Total samples: 50000\n",
      "Keras Excited Accuracy: 0.93848\n",
      "1563/1563 [==============================] - 3s 2ms/step\n",
      "Total correct: 48786\n",
      "Total incorrect: 1214\n",
      "Total samples: 50000\n",
      "Keras Ground Accuracy: 0.97572\n",
      "\n",
      "===================================\n",
      "Fidelity 0.9571000000000001\n",
      "===================================\n",
      "Epoch 1/50\n",
      "105/105 [==============================] - 3s 25ms/step - loss: 0.1700 - accuracy: 0.9554 - val_loss: 0.1706 - val_accuracy: 0.9532 - lr: 0.0010\n",
      "Epoch 2/50\n",
      "105/105 [==============================] - 3s 25ms/step - loss: 0.1640 - accuracy: 0.9563 - val_loss: 0.1711 - val_accuracy: 0.9531 - lr: 0.0010\n",
      "Epoch 3/50\n",
      "105/105 [==============================] - 3s 24ms/step - loss: 0.1593 - accuracy: 0.9569 - val_loss: 0.1733 - val_accuracy: 0.9528 - lr: 0.0010\n",
      "Epoch 4/50\n",
      "105/105 [==============================] - 2s 23ms/step - loss: 0.1531 - accuracy: 0.9575 - val_loss: 0.1766 - val_accuracy: 0.9527 - lr: 0.0010\n",
      "Epoch 5/50\n",
      "105/105 [==============================] - 2s 24ms/step - loss: 0.1448 - accuracy: 0.9581 - val_loss: 0.1816 - val_accuracy: 0.9522 - lr: 0.0010\n",
      "Epoch 6/50\n",
      "105/105 [==============================] - 3s 24ms/step - loss: 0.1355 - accuracy: 0.9588 - val_loss: 0.1880 - val_accuracy: 0.9521 - lr: 0.0010\n",
      "Epoch 7/50\n",
      "105/105 [==============================] - 2s 23ms/step - loss: 0.1256 - accuracy: 0.9594 - val_loss: 0.1965 - val_accuracy: 0.9522 - lr: 0.0010\n",
      "Epoch 8/50\n",
      "105/105 [==============================] - 2s 23ms/step - loss: 0.1168 - accuracy: 0.9603 - val_loss: 0.2039 - val_accuracy: 0.9516 - lr: 0.0010\n",
      "Epoch 9/50\n",
      "105/105 [==============================] - 3s 24ms/step - loss: 0.1082 - accuracy: 0.9611 - val_loss: 0.2127 - val_accuracy: 0.9508 - lr: 0.0010\n",
      "Epoch 10/50\n",
      "105/105 [==============================] - 2s 24ms/step - loss: 0.1007 - accuracy: 0.9620 - val_loss: 0.2209 - val_accuracy: 0.9505 - lr: 0.0010\n",
      "Epoch 11/50\n",
      "105/105 [==============================] - 2s 23ms/step - loss: 0.0942 - accuracy: 0.9629 - val_loss: 0.2261 - val_accuracy: 0.9504 - lr: 0.0010\n",
      "Epoch 12/50\n",
      "105/105 [==============================] - 2s 24ms/step - loss: 0.0783 - accuracy: 0.9649 - val_loss: 0.2245 - val_accuracy: 0.9512 - lr: 1.0000e-04\n",
      "Epoch 13/50\n",
      "105/105 [==============================] - 2s 23ms/step - loss: 0.0755 - accuracy: 0.9653 - val_loss: 0.2258 - val_accuracy: 0.9513 - lr: 1.0000e-04\n",
      "Epoch 14/50\n",
      "105/105 [==============================] - 2s 23ms/step - loss: 0.0742 - accuracy: 0.9654 - val_loss: 0.2279 - val_accuracy: 0.9510 - lr: 1.0000e-04\n",
      "Epoch 15/50\n",
      "105/105 [==============================] - 3s 24ms/step - loss: 0.0731 - accuracy: 0.9655 - val_loss: 0.2289 - val_accuracy: 0.9510 - lr: 1.0000e-04\n",
      "Epoch 16/50\n",
      "105/105 [==============================] - 3s 24ms/step - loss: 0.0721 - accuracy: 0.9657 - val_loss: 0.2307 - val_accuracy: 0.9511 - lr: 1.0000e-04\n",
      "Epoch 17/50\n",
      "105/105 [==============================] - 3s 24ms/step - loss: 0.0712 - accuracy: 0.9657 - val_loss: 0.2322 - val_accuracy: 0.9511 - lr: 1.0000e-04\n",
      "Epoch 18/50\n",
      "105/105 [==============================] - 3s 24ms/step - loss: 0.0703 - accuracy: 0.9658 - val_loss: 0.2342 - val_accuracy: 0.9508 - lr: 1.0000e-04\n",
      "Epoch 19/50\n",
      "105/105 [==============================] - 3s 24ms/step - loss: 0.0695 - accuracy: 0.9660 - val_loss: 0.2360 - val_accuracy: 0.9510 - lr: 1.0000e-04\n",
      "Epoch 20/50\n",
      "105/105 [==============================] - 2s 24ms/step - loss: 0.0687 - accuracy: 0.9659 - val_loss: 0.2376 - val_accuracy: 0.9510 - lr: 1.0000e-04\n",
      "Epoch 21/50\n",
      "105/105 [==============================] - 2s 24ms/step - loss: 0.0679 - accuracy: 0.9661 - val_loss: 0.2390 - val_accuracy: 0.9506 - lr: 1.0000e-04\n",
      "Epoch 22/50\n",
      "105/105 [==============================] - 2s 24ms/step - loss: 0.0664 - accuracy: 0.9665 - val_loss: 0.2394 - val_accuracy: 0.9509 - lr: 1.0000e-05\n",
      "Epoch 23/50\n",
      "105/105 [==============================] - 2s 23ms/step - loss: 0.0662 - accuracy: 0.9664 - val_loss: 0.2395 - val_accuracy: 0.9509 - lr: 1.0000e-05\n",
      "Epoch 24/50\n",
      "105/105 [==============================] - 2s 24ms/step - loss: 0.0661 - accuracy: 0.9663 - val_loss: 0.2399 - val_accuracy: 0.9509 - lr: 1.0000e-05\n",
      "Epoch 25/50\n",
      "105/105 [==============================] - 3s 24ms/step - loss: 0.0660 - accuracy: 0.9663 - val_loss: 0.2398 - val_accuracy: 0.9509 - lr: 1.0000e-05\n",
      "Epoch 26/50\n",
      "105/105 [==============================] - 3s 24ms/step - loss: 0.0659 - accuracy: 0.9664 - val_loss: 0.2400 - val_accuracy: 0.9509 - lr: 1.0000e-05\n",
      "Epoch 27/50\n",
      "105/105 [==============================] - 3s 25ms/step - loss: 0.0658 - accuracy: 0.9662 - val_loss: 0.2403 - val_accuracy: 0.9509 - lr: 1.0000e-05\n",
      "Epoch 28/50\n",
      "105/105 [==============================] - 3s 25ms/step - loss: 0.0658 - accuracy: 0.9663 - val_loss: 0.2404 - val_accuracy: 0.9510 - lr: 1.0000e-05\n",
      "Epoch 29/50\n",
      "105/105 [==============================] - 2s 24ms/step - loss: 0.0657 - accuracy: 0.9663 - val_loss: 0.2405 - val_accuracy: 0.9509 - lr: 1.0000e-05\n",
      "Epoch 30/50\n",
      "105/105 [==============================] - 2s 23ms/step - loss: 0.0656 - accuracy: 0.9664 - val_loss: 0.2407 - val_accuracy: 0.9509 - lr: 1.0000e-05\n",
      "Epoch 31/50\n",
      "105/105 [==============================] - 3s 24ms/step - loss: 0.0655 - accuracy: 0.9663 - val_loss: 0.2410 - val_accuracy: 0.9509 - lr: 1.0000e-05\n",
      "Epoch 32/50\n",
      "105/105 [==============================] - 3s 25ms/step - loss: 0.0654 - accuracy: 0.9667 - val_loss: 0.2409 - val_accuracy: 0.9509 - lr: 1.0000e-06\n",
      "Epoch 33/50\n",
      "105/105 [==============================] - 3s 24ms/step - loss: 0.0654 - accuracy: 0.9666 - val_loss: 0.2410 - val_accuracy: 0.9509 - lr: 1.0000e-06\n",
      "Epoch 34/50\n",
      "105/105 [==============================] - 3s 24ms/step - loss: 0.0653 - accuracy: 0.9665 - val_loss: 0.2410 - val_accuracy: 0.9509 - lr: 1.0000e-06\n",
      "Epoch 35/50\n",
      "105/105 [==============================] - 2s 24ms/step - loss: 0.0654 - accuracy: 0.9663 - val_loss: 0.2409 - val_accuracy: 0.9509 - lr: 1.0000e-06\n",
      "Epoch 36/50\n",
      "105/105 [==============================] - 3s 24ms/step - loss: 0.0653 - accuracy: 0.9665 - val_loss: 0.2410 - val_accuracy: 0.9509 - lr: 1.0000e-06\n",
      "Epoch 37/50\n",
      "105/105 [==============================] - 2s 23ms/step - loss: 0.0653 - accuracy: 0.9664 - val_loss: 0.2410 - val_accuracy: 0.9509 - lr: 1.0000e-06\n",
      "Epoch 38/50\n",
      "105/105 [==============================] - 3s 24ms/step - loss: 0.0653 - accuracy: 0.9663 - val_loss: 0.2410 - val_accuracy: 0.9509 - lr: 1.0000e-06\n",
      "Epoch 39/50\n",
      "105/105 [==============================] - 3s 24ms/step - loss: 0.0653 - accuracy: 0.9663 - val_loss: 0.2411 - val_accuracy: 0.9509 - lr: 1.0000e-06\n",
      "Epoch 40/50\n",
      "105/105 [==============================] - 3s 24ms/step - loss: 0.0653 - accuracy: 0.9663 - val_loss: 0.2411 - val_accuracy: 0.9509 - lr: 1.0000e-06\n",
      "Epoch 41/50\n",
      "105/105 [==============================] - 2s 23ms/step - loss: 0.0653 - accuracy: 0.9664 - val_loss: 0.2411 - val_accuracy: 0.9509 - lr: 1.0000e-06\n",
      "Epoch 42/50\n",
      "105/105 [==============================] - 2s 23ms/step - loss: 0.0653 - accuracy: 0.9663 - val_loss: 0.2411 - val_accuracy: 0.9509 - lr: 1.0000e-07\n",
      "Epoch 43/50\n",
      "105/105 [==============================] - 3s 24ms/step - loss: 0.0653 - accuracy: 0.9664 - val_loss: 0.2411 - val_accuracy: 0.9509 - lr: 1.0000e-07\n",
      "Epoch 44/50\n",
      "105/105 [==============================] - 2s 24ms/step - loss: 0.0653 - accuracy: 0.9664 - val_loss: 0.2411 - val_accuracy: 0.9509 - lr: 1.0000e-07\n",
      "Epoch 45/50\n",
      "105/105 [==============================] - 3s 24ms/step - loss: 0.0653 - accuracy: 0.9664 - val_loss: 0.2411 - val_accuracy: 0.9509 - lr: 1.0000e-07\n",
      "Epoch 46/50\n",
      "105/105 [==============================] - 3s 24ms/step - loss: 0.0653 - accuracy: 0.9664 - val_loss: 0.2411 - val_accuracy: 0.9509 - lr: 1.0000e-07\n",
      "Epoch 47/50\n",
      "105/105 [==============================] - 3s 24ms/step - loss: 0.0653 - accuracy: 0.9664 - val_loss: 0.2411 - val_accuracy: 0.9509 - lr: 1.0000e-07\n",
      "Epoch 48/50\n",
      "105/105 [==============================] - 2s 23ms/step - loss: 0.0653 - accuracy: 0.9664 - val_loss: 0.2411 - val_accuracy: 0.9509 - lr: 1.0000e-07\n",
      "Epoch 49/50\n",
      "105/105 [==============================] - 2s 23ms/step - loss: 0.0653 - accuracy: 0.9664 - val_loss: 0.2411 - val_accuracy: 0.9509 - lr: 1.0000e-07\n",
      "Epoch 50/50\n",
      "105/105 [==============================] - 3s 24ms/step - loss: 0.0653 - accuracy: 0.9664 - val_loss: 0.2411 - val_accuracy: 0.9509 - lr: 1.0000e-07\n",
      "3125/3125 [==============================] - 7s 2ms/step\n",
      "Keras  Accuracy: 0.95447\n",
      "1563/1563 [==============================] - 4s 2ms/step\n",
      "Total correct: 46653\n",
      "Total incorrect: 3347\n",
      "Total samples: 50000\n",
      "Keras Excited Accuracy: 0.93306\n",
      "1563/1563 [==============================] - 3s 2ms/step\n",
      "Total correct: 48794\n",
      "Total incorrect: 1206\n",
      "Total samples: 50000\n",
      "Keras Ground Accuracy: 0.97588\n",
      "\n",
      "===================================\n",
      "Fidelity 0.9544699999999999\n",
      "===================================\n",
      "Epoch 1/50\n",
      "105/105 [==============================] - 3s 25ms/step - loss: 0.1781 - accuracy: 0.9527 - val_loss: 0.1797 - val_accuracy: 0.9504 - lr: 0.0010\n",
      "Epoch 2/50\n",
      "105/105 [==============================] - 2s 23ms/step - loss: 0.1719 - accuracy: 0.9536 - val_loss: 0.1794 - val_accuracy: 0.9505 - lr: 0.0010\n",
      "Epoch 3/50\n",
      "105/105 [==============================] - 2s 23ms/step - loss: 0.1671 - accuracy: 0.9541 - val_loss: 0.1827 - val_accuracy: 0.9503 - lr: 0.0010\n",
      "Epoch 4/50\n",
      "105/105 [==============================] - 2s 23ms/step - loss: 0.1606 - accuracy: 0.9547 - val_loss: 0.1850 - val_accuracy: 0.9501 - lr: 0.0010\n",
      "Epoch 5/50\n",
      "105/105 [==============================] - 2s 23ms/step - loss: 0.1522 - accuracy: 0.9553 - val_loss: 0.1908 - val_accuracy: 0.9493 - lr: 0.0010\n",
      "Epoch 6/50\n",
      "105/105 [==============================] - 2s 23ms/step - loss: 0.1426 - accuracy: 0.9559 - val_loss: 0.1989 - val_accuracy: 0.9492 - lr: 0.0010\n",
      "Epoch 7/50\n",
      "105/105 [==============================] - 3s 24ms/step - loss: 0.1328 - accuracy: 0.9567 - val_loss: 0.2065 - val_accuracy: 0.9491 - lr: 0.0010\n",
      "Epoch 8/50\n",
      "105/105 [==============================] - 2s 24ms/step - loss: 0.1236 - accuracy: 0.9575 - val_loss: 0.2135 - val_accuracy: 0.9485 - lr: 0.0010\n",
      "Epoch 9/50\n",
      "105/105 [==============================] - 2s 23ms/step - loss: 0.1152 - accuracy: 0.9584 - val_loss: 0.2217 - val_accuracy: 0.9476 - lr: 0.0010\n",
      "Epoch 10/50\n",
      "105/105 [==============================] - 2s 23ms/step - loss: 0.1076 - accuracy: 0.9594 - val_loss: 0.2295 - val_accuracy: 0.9467 - lr: 0.0010\n",
      "Epoch 11/50\n",
      "105/105 [==============================] - 2s 23ms/step - loss: 0.1006 - accuracy: 0.9602 - val_loss: 0.2390 - val_accuracy: 0.9473 - lr: 0.0010\n",
      "Epoch 12/50\n",
      "105/105 [==============================] - 2s 23ms/step - loss: 0.0843 - accuracy: 0.9622 - val_loss: 0.2354 - val_accuracy: 0.9476 - lr: 1.0000e-04\n",
      "Epoch 13/50\n",
      "105/105 [==============================] - 2s 23ms/step - loss: 0.0816 - accuracy: 0.9626 - val_loss: 0.2362 - val_accuracy: 0.9477 - lr: 1.0000e-04\n",
      "Epoch 14/50\n",
      "105/105 [==============================] - 2s 23ms/step - loss: 0.0803 - accuracy: 0.9627 - val_loss: 0.2375 - val_accuracy: 0.9474 - lr: 1.0000e-04\n",
      "Epoch 15/50\n",
      "105/105 [==============================] - 2s 23ms/step - loss: 0.0792 - accuracy: 0.9628 - val_loss: 0.2393 - val_accuracy: 0.9473 - lr: 1.0000e-04\n",
      "Epoch 16/50\n",
      "105/105 [==============================] - 2s 24ms/step - loss: 0.0781 - accuracy: 0.9630 - val_loss: 0.2413 - val_accuracy: 0.9475 - lr: 1.0000e-04\n",
      "Epoch 17/50\n",
      "105/105 [==============================] - 2s 23ms/step - loss: 0.0772 - accuracy: 0.9630 - val_loss: 0.2434 - val_accuracy: 0.9474 - lr: 1.0000e-04\n",
      "Epoch 18/50\n",
      "105/105 [==============================] - 2s 23ms/step - loss: 0.0763 - accuracy: 0.9631 - val_loss: 0.2445 - val_accuracy: 0.9473 - lr: 1.0000e-04\n",
      "Epoch 19/50\n",
      "105/105 [==============================] - 2s 23ms/step - loss: 0.0755 - accuracy: 0.9632 - val_loss: 0.2459 - val_accuracy: 0.9472 - lr: 1.0000e-04\n",
      "Epoch 20/50\n",
      "105/105 [==============================] - 2s 23ms/step - loss: 0.0746 - accuracy: 0.9633 - val_loss: 0.2480 - val_accuracy: 0.9475 - lr: 1.0000e-04\n",
      "Epoch 21/50\n",
      "105/105 [==============================] - 2s 23ms/step - loss: 0.0738 - accuracy: 0.9633 - val_loss: 0.2503 - val_accuracy: 0.9472 - lr: 1.0000e-04\n",
      "Epoch 22/50\n",
      "105/105 [==============================] - 2s 23ms/step - loss: 0.0723 - accuracy: 0.9639 - val_loss: 0.2499 - val_accuracy: 0.9474 - lr: 1.0000e-05\n",
      "Epoch 23/50\n",
      "105/105 [==============================] - 2s 23ms/step - loss: 0.0721 - accuracy: 0.9635 - val_loss: 0.2499 - val_accuracy: 0.9474 - lr: 1.0000e-05\n",
      "Epoch 24/50\n",
      "105/105 [==============================] - 2s 23ms/step - loss: 0.0719 - accuracy: 0.9637 - val_loss: 0.2501 - val_accuracy: 0.9474 - lr: 1.0000e-05\n",
      "Epoch 25/50\n",
      "105/105 [==============================] - 2s 23ms/step - loss: 0.0718 - accuracy: 0.9636 - val_loss: 0.2502 - val_accuracy: 0.9474 - lr: 1.0000e-05\n",
      "Epoch 26/50\n",
      "105/105 [==============================] - 3s 24ms/step - loss: 0.0717 - accuracy: 0.9637 - val_loss: 0.2503 - val_accuracy: 0.9474 - lr: 1.0000e-05\n",
      "Epoch 27/50\n",
      "105/105 [==============================] - 2s 24ms/step - loss: 0.0717 - accuracy: 0.9635 - val_loss: 0.2506 - val_accuracy: 0.9474 - lr: 1.0000e-05\n",
      "Epoch 28/50\n",
      "105/105 [==============================] - 2s 23ms/step - loss: 0.0716 - accuracy: 0.9637 - val_loss: 0.2506 - val_accuracy: 0.9474 - lr: 1.0000e-05\n",
      "Epoch 29/50\n",
      "105/105 [==============================] - 2s 23ms/step - loss: 0.0715 - accuracy: 0.9636 - val_loss: 0.2510 - val_accuracy: 0.9474 - lr: 1.0000e-05\n",
      "Epoch 30/50\n",
      "105/105 [==============================] - 2s 23ms/step - loss: 0.0715 - accuracy: 0.9635 - val_loss: 0.2512 - val_accuracy: 0.9474 - lr: 1.0000e-05\n",
      "Epoch 31/50\n",
      "105/105 [==============================] - 3s 24ms/step - loss: 0.0713 - accuracy: 0.9638 - val_loss: 0.2512 - val_accuracy: 0.9474 - lr: 1.0000e-05\n",
      "Epoch 32/50\n",
      "105/105 [==============================] - 2s 23ms/step - loss: 0.0712 - accuracy: 0.9635 - val_loss: 0.2512 - val_accuracy: 0.9474 - lr: 1.0000e-06\n",
      "Epoch 33/50\n",
      "105/105 [==============================] - 2s 23ms/step - loss: 0.0712 - accuracy: 0.9636 - val_loss: 0.2513 - val_accuracy: 0.9474 - lr: 1.0000e-06\n",
      "Epoch 34/50\n",
      "105/105 [==============================] - 2s 23ms/step - loss: 0.0711 - accuracy: 0.9637 - val_loss: 0.2513 - val_accuracy: 0.9474 - lr: 1.0000e-06\n",
      "Epoch 35/50\n",
      "105/105 [==============================] - 2s 23ms/step - loss: 0.0711 - accuracy: 0.9637 - val_loss: 0.2514 - val_accuracy: 0.9474 - lr: 1.0000e-06\n",
      "Epoch 36/50\n",
      "105/105 [==============================] - 2s 23ms/step - loss: 0.0711 - accuracy: 0.9637 - val_loss: 0.2514 - val_accuracy: 0.9474 - lr: 1.0000e-06\n",
      "Epoch 37/50\n",
      "105/105 [==============================] - 2s 23ms/step - loss: 0.0711 - accuracy: 0.9637 - val_loss: 0.2514 - val_accuracy: 0.9474 - lr: 1.0000e-06\n",
      "Epoch 38/50\n",
      "105/105 [==============================] - 2s 22ms/step - loss: 0.0711 - accuracy: 0.9637 - val_loss: 0.2514 - val_accuracy: 0.9474 - lr: 1.0000e-06\n",
      "Epoch 39/50\n",
      "105/105 [==============================] - 2s 23ms/step - loss: 0.0711 - accuracy: 0.9637 - val_loss: 0.2515 - val_accuracy: 0.9474 - lr: 1.0000e-06\n",
      "Epoch 40/50\n",
      "105/105 [==============================] - 2s 23ms/step - loss: 0.0711 - accuracy: 0.9637 - val_loss: 0.2515 - val_accuracy: 0.9474 - lr: 1.0000e-06\n",
      "Epoch 41/50\n",
      "105/105 [==============================] - 2s 22ms/step - loss: 0.0711 - accuracy: 0.9636 - val_loss: 0.2515 - val_accuracy: 0.9474 - lr: 1.0000e-06\n",
      "Epoch 42/50\n",
      "105/105 [==============================] - 2s 23ms/step - loss: 0.0711 - accuracy: 0.9638 - val_loss: 0.2515 - val_accuracy: 0.9474 - lr: 1.0000e-07\n",
      "Epoch 43/50\n",
      "105/105 [==============================] - 2s 23ms/step - loss: 0.0711 - accuracy: 0.9638 - val_loss: 0.2515 - val_accuracy: 0.9474 - lr: 1.0000e-07\n",
      "Epoch 44/50\n",
      "105/105 [==============================] - 2s 23ms/step - loss: 0.0710 - accuracy: 0.9637 - val_loss: 0.2515 - val_accuracy: 0.9474 - lr: 1.0000e-07\n",
      "Epoch 45/50\n",
      "105/105 [==============================] - 2s 23ms/step - loss: 0.0710 - accuracy: 0.9637 - val_loss: 0.2515 - val_accuracy: 0.9474 - lr: 1.0000e-07\n",
      "Epoch 46/50\n",
      "105/105 [==============================] - 2s 23ms/step - loss: 0.0710 - accuracy: 0.9637 - val_loss: 0.2515 - val_accuracy: 0.9474 - lr: 1.0000e-07\n",
      "Epoch 47/50\n",
      "105/105 [==============================] - 2s 22ms/step - loss: 0.0710 - accuracy: 0.9637 - val_loss: 0.2515 - val_accuracy: 0.9474 - lr: 1.0000e-07\n",
      "Epoch 48/50\n",
      "105/105 [==============================] - 2s 24ms/step - loss: 0.0711 - accuracy: 0.9637 - val_loss: 0.2515 - val_accuracy: 0.9474 - lr: 1.0000e-07\n",
      "Epoch 49/50\n",
      "105/105 [==============================] - 2s 24ms/step - loss: 0.0711 - accuracy: 0.9637 - val_loss: 0.2515 - val_accuracy: 0.9474 - lr: 1.0000e-07\n",
      "Epoch 50/50\n",
      "105/105 [==============================] - 2s 23ms/step - loss: 0.0711 - accuracy: 0.9637 - val_loss: 0.2515 - val_accuracy: 0.9474 - lr: 1.0000e-07\n",
      "3125/3125 [==============================] - 7s 2ms/step\n",
      "Keras  Accuracy: 0.95162\n",
      "1563/1563 [==============================] - 4s 2ms/step\n",
      "Total correct: 46371\n",
      "Total incorrect: 3629\n",
      "Total samples: 50000\n",
      "Keras Excited Accuracy: 0.92742\n",
      "1563/1563 [==============================] - 4s 2ms/step\n",
      "Total correct: 48791\n",
      "Total incorrect: 1209\n",
      "Total samples: 50000\n",
      "Keras Ground Accuracy: 0.97582\n",
      "\n",
      "===================================\n",
      "Fidelity 0.95162\n",
      "===================================\n",
      "Epoch 1/50\n",
      "105/105 [==============================] - 3s 25ms/step - loss: 0.1860 - accuracy: 0.9499 - val_loss: 0.1878 - val_accuracy: 0.9468 - lr: 0.0010\n",
      "Epoch 2/50\n",
      "105/105 [==============================] - 2s 23ms/step - loss: 0.1797 - accuracy: 0.9508 - val_loss: 0.1890 - val_accuracy: 0.9470 - lr: 0.0010\n",
      "Epoch 3/50\n",
      "105/105 [==============================] - 2s 22ms/step - loss: 0.1750 - accuracy: 0.9513 - val_loss: 0.1901 - val_accuracy: 0.9469 - lr: 0.0010\n",
      "Epoch 4/50\n",
      "105/105 [==============================] - 2s 22ms/step - loss: 0.1686 - accuracy: 0.9518 - val_loss: 0.1927 - val_accuracy: 0.9463 - lr: 0.0010\n",
      "Epoch 5/50\n",
      "105/105 [==============================] - 2s 23ms/step - loss: 0.1603 - accuracy: 0.9525 - val_loss: 0.2002 - val_accuracy: 0.9462 - lr: 0.0010\n",
      "Epoch 6/50\n",
      "105/105 [==============================] - 2s 23ms/step - loss: 0.1506 - accuracy: 0.9530 - val_loss: 0.2057 - val_accuracy: 0.9453 - lr: 0.0010\n",
      "Epoch 7/50\n",
      "105/105 [==============================] - 2s 23ms/step - loss: 0.1408 - accuracy: 0.9537 - val_loss: 0.2156 - val_accuracy: 0.9449 - lr: 0.0010\n",
      "Epoch 8/50\n",
      "105/105 [==============================] - 2s 22ms/step - loss: 0.1316 - accuracy: 0.9546 - val_loss: 0.2211 - val_accuracy: 0.9445 - lr: 0.0010\n",
      "Epoch 9/50\n",
      "105/105 [==============================] - 2s 23ms/step - loss: 0.1227 - accuracy: 0.9555 - val_loss: 0.2306 - val_accuracy: 0.9446 - lr: 0.0010\n",
      "Epoch 10/50\n",
      "105/105 [==============================] - 2s 23ms/step - loss: 0.1153 - accuracy: 0.9563 - val_loss: 0.2393 - val_accuracy: 0.9438 - lr: 0.0010\n",
      "Epoch 11/50\n",
      "105/105 [==============================] - 2s 22ms/step - loss: 0.1083 - accuracy: 0.9573 - val_loss: 0.2491 - val_accuracy: 0.9426 - lr: 0.0010\n",
      "Epoch 12/50\n",
      "105/105 [==============================] - 2s 23ms/step - loss: 0.0918 - accuracy: 0.9592 - val_loss: 0.2416 - val_accuracy: 0.9438 - lr: 1.0000e-04\n",
      "Epoch 13/50\n",
      "105/105 [==============================] - 2s 23ms/step - loss: 0.0888 - accuracy: 0.9596 - val_loss: 0.2435 - val_accuracy: 0.9442 - lr: 1.0000e-04\n",
      "Epoch 14/50\n",
      "105/105 [==============================] - 2s 22ms/step - loss: 0.0874 - accuracy: 0.9597 - val_loss: 0.2447 - val_accuracy: 0.9442 - lr: 1.0000e-04\n",
      "Epoch 15/50\n",
      "105/105 [==============================] - 2s 22ms/step - loss: 0.0863 - accuracy: 0.9599 - val_loss: 0.2465 - val_accuracy: 0.9441 - lr: 1.0000e-04\n",
      "Epoch 16/50\n",
      "105/105 [==============================] - 2s 22ms/step - loss: 0.0853 - accuracy: 0.9599 - val_loss: 0.2488 - val_accuracy: 0.9440 - lr: 1.0000e-04\n",
      "Epoch 17/50\n",
      "105/105 [==============================] - 2s 22ms/step - loss: 0.0843 - accuracy: 0.9601 - val_loss: 0.2506 - val_accuracy: 0.9439 - lr: 1.0000e-04\n",
      "Epoch 18/50\n",
      "105/105 [==============================] - 2s 22ms/step - loss: 0.0834 - accuracy: 0.9601 - val_loss: 0.2525 - val_accuracy: 0.9440 - lr: 1.0000e-04\n",
      "Epoch 19/50\n",
      "105/105 [==============================] - 2s 22ms/step - loss: 0.0825 - accuracy: 0.9602 - val_loss: 0.2542 - val_accuracy: 0.9438 - lr: 1.0000e-04\n",
      "Epoch 20/50\n",
      "105/105 [==============================] - 2s 22ms/step - loss: 0.0817 - accuracy: 0.9603 - val_loss: 0.2557 - val_accuracy: 0.9440 - lr: 1.0000e-04\n",
      "Epoch 21/50\n",
      "105/105 [==============================] - 2s 22ms/step - loss: 0.0809 - accuracy: 0.9605 - val_loss: 0.2579 - val_accuracy: 0.9440 - lr: 1.0000e-04\n",
      "Epoch 22/50\n",
      "105/105 [==============================] - 2s 22ms/step - loss: 0.0792 - accuracy: 0.9607 - val_loss: 0.2575 - val_accuracy: 0.9440 - lr: 1.0000e-05\n",
      "Epoch 23/50\n",
      "105/105 [==============================] - 2s 22ms/step - loss: 0.0791 - accuracy: 0.9606 - val_loss: 0.2577 - val_accuracy: 0.9439 - lr: 1.0000e-05\n",
      "Epoch 24/50\n",
      "105/105 [==============================] - 2s 22ms/step - loss: 0.0789 - accuracy: 0.9606 - val_loss: 0.2577 - val_accuracy: 0.9440 - lr: 1.0000e-05\n",
      "Epoch 25/50\n",
      "105/105 [==============================] - 2s 22ms/step - loss: 0.0788 - accuracy: 0.9607 - val_loss: 0.2577 - val_accuracy: 0.9439 - lr: 1.0000e-05\n",
      "Epoch 26/50\n",
      "105/105 [==============================] - 2s 22ms/step - loss: 0.0787 - accuracy: 0.9607 - val_loss: 0.2580 - val_accuracy: 0.9439 - lr: 1.0000e-05\n",
      "Epoch 27/50\n",
      "105/105 [==============================] - 2s 22ms/step - loss: 0.0787 - accuracy: 0.9606 - val_loss: 0.2582 - val_accuracy: 0.9439 - lr: 1.0000e-05\n",
      "Epoch 28/50\n",
      "105/105 [==============================] - 2s 22ms/step - loss: 0.0786 - accuracy: 0.9606 - val_loss: 0.2582 - val_accuracy: 0.9439 - lr: 1.0000e-05\n",
      "Epoch 29/50\n",
      "105/105 [==============================] - 2s 22ms/step - loss: 0.0785 - accuracy: 0.9606 - val_loss: 0.2585 - val_accuracy: 0.9439 - lr: 1.0000e-05\n",
      "Epoch 30/50\n",
      "105/105 [==============================] - 2s 22ms/step - loss: 0.0784 - accuracy: 0.9607 - val_loss: 0.2587 - val_accuracy: 0.9439 - lr: 1.0000e-05\n",
      "Epoch 31/50\n",
      "105/105 [==============================] - 2s 22ms/step - loss: 0.0784 - accuracy: 0.9606 - val_loss: 0.2588 - val_accuracy: 0.9438 - lr: 1.0000e-05\n",
      "Epoch 32/50\n",
      "105/105 [==============================] - 2s 22ms/step - loss: 0.0782 - accuracy: 0.9609 - val_loss: 0.2589 - val_accuracy: 0.9438 - lr: 1.0000e-06\n",
      "Epoch 33/50\n",
      "105/105 [==============================] - 2s 22ms/step - loss: 0.0781 - accuracy: 0.9608 - val_loss: 0.2589 - val_accuracy: 0.9438 - lr: 1.0000e-06\n",
      "Epoch 34/50\n",
      "105/105 [==============================] - 2s 21ms/step - loss: 0.0781 - accuracy: 0.9608 - val_loss: 0.2590 - val_accuracy: 0.9438 - lr: 1.0000e-06\n",
      "Epoch 35/50\n",
      "105/105 [==============================] - 2s 21ms/step - loss: 0.0781 - accuracy: 0.9607 - val_loss: 0.2590 - val_accuracy: 0.9438 - lr: 1.0000e-06\n",
      "Epoch 36/50\n",
      "105/105 [==============================] - 2s 22ms/step - loss: 0.0781 - accuracy: 0.9607 - val_loss: 0.2590 - val_accuracy: 0.9438 - lr: 1.0000e-06\n",
      "Epoch 37/50\n",
      "105/105 [==============================] - 2s 22ms/step - loss: 0.0781 - accuracy: 0.9607 - val_loss: 0.2590 - val_accuracy: 0.9439 - lr: 1.0000e-06\n",
      "Epoch 38/50\n",
      "105/105 [==============================] - 2s 22ms/step - loss: 0.0781 - accuracy: 0.9608 - val_loss: 0.2591 - val_accuracy: 0.9439 - lr: 1.0000e-06\n",
      "Epoch 39/50\n",
      "105/105 [==============================] - 2s 22ms/step - loss: 0.0781 - accuracy: 0.9608 - val_loss: 0.2591 - val_accuracy: 0.9439 - lr: 1.0000e-06\n",
      "Epoch 40/50\n",
      "105/105 [==============================] - 2s 22ms/step - loss: 0.0781 - accuracy: 0.9606 - val_loss: 0.2591 - val_accuracy: 0.9439 - lr: 1.0000e-06\n",
      "Epoch 41/50\n",
      "105/105 [==============================] - 2s 22ms/step - loss: 0.0781 - accuracy: 0.9607 - val_loss: 0.2591 - val_accuracy: 0.9438 - lr: 1.0000e-06\n",
      "Epoch 42/50\n",
      "105/105 [==============================] - 2s 22ms/step - loss: 0.0780 - accuracy: 0.9607 - val_loss: 0.2591 - val_accuracy: 0.9438 - lr: 1.0000e-07\n",
      "Epoch 43/50\n",
      "105/105 [==============================] - 2s 22ms/step - loss: 0.0781 - accuracy: 0.9608 - val_loss: 0.2591 - val_accuracy: 0.9439 - lr: 1.0000e-07\n",
      "Epoch 44/50\n",
      "105/105 [==============================] - 2s 22ms/step - loss: 0.0780 - accuracy: 0.9607 - val_loss: 0.2591 - val_accuracy: 0.9438 - lr: 1.0000e-07\n",
      "Epoch 45/50\n",
      "105/105 [==============================] - 2s 22ms/step - loss: 0.0780 - accuracy: 0.9607 - val_loss: 0.2591 - val_accuracy: 0.9439 - lr: 1.0000e-07\n",
      "Epoch 46/50\n",
      "105/105 [==============================] - 2s 22ms/step - loss: 0.0781 - accuracy: 0.9607 - val_loss: 0.2591 - val_accuracy: 0.9438 - lr: 1.0000e-07\n",
      "Epoch 47/50\n",
      "105/105 [==============================] - 2s 22ms/step - loss: 0.0780 - accuracy: 0.9607 - val_loss: 0.2591 - val_accuracy: 0.9439 - lr: 1.0000e-07\n",
      "Epoch 48/50\n",
      "105/105 [==============================] - 2s 22ms/step - loss: 0.0780 - accuracy: 0.9607 - val_loss: 0.2591 - val_accuracy: 0.9438 - lr: 1.0000e-07\n",
      "Epoch 49/50\n",
      "105/105 [==============================] - 2s 22ms/step - loss: 0.0781 - accuracy: 0.9607 - val_loss: 0.2591 - val_accuracy: 0.9438 - lr: 1.0000e-07\n",
      "Epoch 50/50\n",
      "105/105 [==============================] - 2s 21ms/step - loss: 0.0781 - accuracy: 0.9607 - val_loss: 0.2591 - val_accuracy: 0.9439 - lr: 1.0000e-07\n",
      "3125/3125 [==============================] - 7s 2ms/step\n",
      "Keras  Accuracy: 0.94871\n",
      "1563/1563 [==============================] - 3s 2ms/step\n",
      "Total correct: 46120\n",
      "Total incorrect: 3880\n",
      "Total samples: 50000\n",
      "Keras Excited Accuracy: 0.9224\n",
      "1563/1563 [==============================] - 4s 2ms/step\n",
      "Total correct: 48751\n",
      "Total incorrect: 1249\n",
      "Total samples: 50000\n",
      "Keras Ground Accuracy: 0.97502\n",
      "\n",
      "===================================\n",
      "Fidelity 0.9487099999999999\n",
      "===================================\n"
     ]
    }
   ],
   "source": [
    "checkpoint_filename = 'multi_layer_model_subwindow.h5'\n",
    "callbacks = [\n",
    "        ModelCheckpoint(\n",
    "        checkpoint_filename,\n",
    "        monitor=\"val_loss\",\n",
    "        verbose=0,\n",
    "        save_best_only=True,\n",
    "        save_weights_only=False,\n",
    "        save_freq=\"epoch\",\n",
    "    ),\n",
    "    ReduceLROnPlateau(patience=10, min_delta=1**-6),\n",
    "]\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(int(hn/8), activation='relu', input_shape=(800,)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(2, activation='relu'))\n",
    "\n",
    "ml_accuracy, ml_e_accuracy, ml_g_accuracy  = scan_readout_window(model, window_start_locations, window_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy [0.95646, 0.95971, 0.96031, 0.95946, 0.9571, 0.95447, 0.95162, 0.94871]\n",
      "Fidelity [0.91292 0.91942 0.92062 0.91892 0.9142  0.90894 0.90324 0.89742]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ml_fidelity = 1 - (1 - np.array(ml_e_accuracy)) - (1 - np.array(ml_g_accuracy)) \n",
    "\n",
    "plt.figure()\n",
    "plt.plot(window_start_locations, ml_fidelity)\n",
    "plt.xlabel('Readout window start location')\n",
    "plt.ylabel('Fidelity')\n",
    "\n",
    "print('Accuracy', ml_accuracy)\n",
    "print('Fidelity', ml_fidelity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Single-Layer Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "105/105 [==============================] - 2s 11ms/step - loss: 0.3384 - accuracy: 0.8935 - val_loss: 0.2044 - val_accuracy: 0.9497 - lr: 0.0010\n",
      "Epoch 2/50\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.2277 - accuracy: 0.9545 - val_loss: 0.2005 - val_accuracy: 0.9548 - lr: 0.0010\n",
      "Epoch 3/50\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.2082 - accuracy: 0.9572 - val_loss: 0.1969 - val_accuracy: 0.9556 - lr: 0.0010\n",
      "Epoch 4/50\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.1975 - accuracy: 0.9578 - val_loss: 0.1921 - val_accuracy: 0.9556 - lr: 0.0010\n",
      "Epoch 5/50\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.1906 - accuracy: 0.9580 - val_loss: 0.1878 - val_accuracy: 0.9558 - lr: 0.0010\n",
      "Epoch 6/50\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.1857 - accuracy: 0.9581 - val_loss: 0.1841 - val_accuracy: 0.9560 - lr: 0.0010\n",
      "Epoch 7/50\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.1822 - accuracy: 0.9582 - val_loss: 0.1814 - val_accuracy: 0.9561 - lr: 0.0010\n",
      "Epoch 8/50\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.1796 - accuracy: 0.9582 - val_loss: 0.1794 - val_accuracy: 0.9561 - lr: 0.0010\n",
      "Epoch 9/50\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.1776 - accuracy: 0.9583 - val_loss: 0.1774 - val_accuracy: 0.9561 - lr: 0.0010\n",
      "Epoch 10/50\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.1761 - accuracy: 0.9582 - val_loss: 0.1768 - val_accuracy: 0.9558 - lr: 0.0010\n",
      "Epoch 11/50\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.1750 - accuracy: 0.9582 - val_loss: 0.1756 - val_accuracy: 0.9564 - lr: 0.0010\n",
      "Epoch 12/50\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.1741 - accuracy: 0.9582 - val_loss: 0.1748 - val_accuracy: 0.9561 - lr: 0.0010\n",
      "Epoch 13/50\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.1734 - accuracy: 0.9582 - val_loss: 0.1741 - val_accuracy: 0.9562 - lr: 0.0010\n",
      "Epoch 14/50\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.1730 - accuracy: 0.9582 - val_loss: 0.1739 - val_accuracy: 0.9562 - lr: 0.0010\n",
      "Epoch 15/50\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.1726 - accuracy: 0.9582 - val_loss: 0.1738 - val_accuracy: 0.9560 - lr: 0.0010\n",
      "Epoch 16/50\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.1723 - accuracy: 0.9582 - val_loss: 0.1733 - val_accuracy: 0.9563 - lr: 0.0010\n",
      "Epoch 17/50\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.1721 - accuracy: 0.9582 - val_loss: 0.1731 - val_accuracy: 0.9560 - lr: 0.0010\n",
      "Epoch 18/50\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.1720 - accuracy: 0.9582 - val_loss: 0.1730 - val_accuracy: 0.9562 - lr: 0.0010\n",
      "Epoch 19/50\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.1718 - accuracy: 0.9582 - val_loss: 0.1730 - val_accuracy: 0.9562 - lr: 0.0010\n",
      "Epoch 20/50\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.1718 - accuracy: 0.9582 - val_loss: 0.1729 - val_accuracy: 0.9562 - lr: 0.0010\n",
      "Epoch 21/50\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.1717 - accuracy: 0.9583 - val_loss: 0.1729 - val_accuracy: 0.9562 - lr: 0.0010\n",
      "Epoch 22/50\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.1716 - accuracy: 0.9582 - val_loss: 0.1728 - val_accuracy: 0.9563 - lr: 0.0010\n",
      "Epoch 23/50\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.1716 - accuracy: 0.9582 - val_loss: 0.1729 - val_accuracy: 0.9561 - lr: 0.0010\n",
      "Epoch 24/50\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.1716 - accuracy: 0.9582 - val_loss: 0.1727 - val_accuracy: 0.9561 - lr: 0.0010\n",
      "Epoch 25/50\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.1715 - accuracy: 0.9582 - val_loss: 0.1727 - val_accuracy: 0.9561 - lr: 0.0010\n",
      "Epoch 26/50\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.1715 - accuracy: 0.9582 - val_loss: 0.1726 - val_accuracy: 0.9562 - lr: 0.0010\n",
      "Epoch 27/50\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.1715 - accuracy: 0.9582 - val_loss: 0.1724 - val_accuracy: 0.9560 - lr: 0.0010\n",
      "Epoch 28/50\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.1715 - accuracy: 0.9582 - val_loss: 0.1727 - val_accuracy: 0.9563 - lr: 0.0010\n",
      "Epoch 29/50\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.1715 - accuracy: 0.9583 - val_loss: 0.1729 - val_accuracy: 0.9562 - lr: 0.0010\n",
      "Epoch 30/50\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.1714 - accuracy: 0.9582 - val_loss: 0.1725 - val_accuracy: 0.9560 - lr: 0.0010\n",
      "Epoch 31/50\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.1714 - accuracy: 0.9583 - val_loss: 0.1728 - val_accuracy: 0.9562 - lr: 0.0010\n",
      "Epoch 32/50\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.1714 - accuracy: 0.9583 - val_loss: 0.1727 - val_accuracy: 0.9561 - lr: 0.0010\n",
      "Epoch 33/50\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.1714 - accuracy: 0.9582 - val_loss: 0.1727 - val_accuracy: 0.9563 - lr: 0.0010\n",
      "Epoch 34/50\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.1714 - accuracy: 0.9583 - val_loss: 0.1727 - val_accuracy: 0.9561 - lr: 0.0010\n",
      "Epoch 35/50\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.1714 - accuracy: 0.9583 - val_loss: 0.1729 - val_accuracy: 0.9563 - lr: 0.0010\n",
      "Epoch 36/50\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.1713 - accuracy: 0.9583 - val_loss: 0.1725 - val_accuracy: 0.9563 - lr: 0.0010\n",
      "Epoch 37/50\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.1713 - accuracy: 0.9583 - val_loss: 0.1723 - val_accuracy: 0.9562 - lr: 0.0010\n",
      "Epoch 38/50\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.1713 - accuracy: 0.9583 - val_loss: 0.1725 - val_accuracy: 0.9560 - lr: 0.0010\n",
      "Epoch 39/50\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.1713 - accuracy: 0.9583 - val_loss: 0.1723 - val_accuracy: 0.9561 - lr: 0.0010\n",
      "Epoch 40/50\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.1713 - accuracy: 0.9583 - val_loss: 0.1725 - val_accuracy: 0.9562 - lr: 0.0010\n",
      "Epoch 41/50\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.1713 - accuracy: 0.9583 - val_loss: 0.1725 - val_accuracy: 0.9562 - lr: 0.0010\n",
      "Epoch 42/50\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.1713 - accuracy: 0.9583 - val_loss: 0.1724 - val_accuracy: 0.9562 - lr: 0.0010\n",
      "Epoch 43/50\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.1713 - accuracy: 0.9583 - val_loss: 0.1725 - val_accuracy: 0.9563 - lr: 0.0010\n",
      "Epoch 44/50\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.1713 - accuracy: 0.9583 - val_loss: 0.1723 - val_accuracy: 0.9563 - lr: 0.0010\n",
      "Epoch 45/50\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.1713 - accuracy: 0.9583 - val_loss: 0.1723 - val_accuracy: 0.9564 - lr: 0.0010\n",
      "Epoch 46/50\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.1712 - accuracy: 0.9583 - val_loss: 0.1723 - val_accuracy: 0.9562 - lr: 0.0010\n",
      "Epoch 47/50\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.1712 - accuracy: 0.9583 - val_loss: 0.1724 - val_accuracy: 0.9562 - lr: 0.0010\n",
      "Epoch 48/50\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.1712 - accuracy: 0.9583 - val_loss: 0.1724 - val_accuracy: 0.9560 - lr: 0.0010\n",
      "Epoch 49/50\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.1712 - accuracy: 0.9583 - val_loss: 0.1724 - val_accuracy: 0.9562 - lr: 0.0010\n",
      "Epoch 50/50\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.1712 - accuracy: 0.9583 - val_loss: 0.1720 - val_accuracy: 0.9561 - lr: 0.0010\n",
      "3125/3125 [==============================] - 5s 2ms/step\n",
      "Keras  Accuracy: 0.95765\n",
      "1563/1563 [==============================] - 3s 2ms/step\n",
      "Total correct: 47297\n",
      "Total incorrect: 2703\n",
      "Total samples: 50000\n",
      "Keras Excited Accuracy: 0.94594\n",
      "1563/1563 [==============================] - 2s 2ms/step\n",
      "Total correct: 48468\n",
      "Total incorrect: 1532\n",
      "Total samples: 50000\n",
      "Keras Ground Accuracy: 0.96936\n",
      "\n",
      "===================================\n",
      "Fidelity 0.95765\n",
      "===================================\n",
      "Epoch 1/50\n",
      "105/105 [==============================] - 3s 11ms/step - loss: 0.1717 - accuracy: 0.9601 - val_loss: 0.1703 - val_accuracy: 0.9580 - lr: 0.0010\n",
      "Epoch 2/50\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.1701 - accuracy: 0.9605 - val_loss: 0.1702 - val_accuracy: 0.9580 - lr: 0.0010\n",
      "Epoch 3/50\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.1700 - accuracy: 0.9605 - val_loss: 0.1702 - val_accuracy: 0.9580 - lr: 0.0010\n",
      "Epoch 4/50\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.1699 - accuracy: 0.9606 - val_loss: 0.1704 - val_accuracy: 0.9580 - lr: 0.0010\n",
      "Epoch 5/50\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.1699 - accuracy: 0.9605 - val_loss: 0.1703 - val_accuracy: 0.9580 - lr: 0.0010\n",
      "Epoch 6/50\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.1699 - accuracy: 0.9606 - val_loss: 0.1704 - val_accuracy: 0.9578 - lr: 0.0010\n",
      "Epoch 7/50\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.1698 - accuracy: 0.9606 - val_loss: 0.1704 - val_accuracy: 0.9580 - lr: 0.0010\n",
      "Epoch 8/50\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.1698 - accuracy: 0.9605 - val_loss: 0.1702 - val_accuracy: 0.9580 - lr: 0.0010\n",
      "Epoch 9/50\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.1698 - accuracy: 0.9606 - val_loss: 0.1704 - val_accuracy: 0.9579 - lr: 0.0010\n",
      "Epoch 10/50\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.1698 - accuracy: 0.9606 - val_loss: 0.1704 - val_accuracy: 0.9580 - lr: 0.0010\n",
      "Epoch 11/50\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.1698 - accuracy: 0.9606 - val_loss: 0.1704 - val_accuracy: 0.9580 - lr: 0.0010\n",
      "Epoch 12/50\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.1698 - accuracy: 0.9606 - val_loss: 0.1703 - val_accuracy: 0.9578 - lr: 0.0010\n",
      "Epoch 13/50\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.1698 - accuracy: 0.9605 - val_loss: 0.1704 - val_accuracy: 0.9579 - lr: 0.0010\n",
      "Epoch 14/50\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.1698 - accuracy: 0.9606 - val_loss: 0.1705 - val_accuracy: 0.9579 - lr: 0.0010\n",
      "Epoch 15/50\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.1698 - accuracy: 0.9605 - val_loss: 0.1702 - val_accuracy: 0.9580 - lr: 0.0010\n",
      "Epoch 16/50\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.1698 - accuracy: 0.9605 - val_loss: 0.1703 - val_accuracy: 0.9580 - lr: 0.0010\n",
      "Epoch 17/50\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.1697 - accuracy: 0.9606 - val_loss: 0.1704 - val_accuracy: 0.9579 - lr: 0.0010\n",
      "Epoch 18/50\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.1698 - accuracy: 0.9605 - val_loss: 0.1704 - val_accuracy: 0.9579 - lr: 0.0010\n",
      "Epoch 19/50\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.1697 - accuracy: 0.9606 - val_loss: 0.1703 - val_accuracy: 0.9580 - lr: 0.0010\n",
      "Epoch 20/50\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.1698 - accuracy: 0.9606 - val_loss: 0.1705 - val_accuracy: 0.9579 - lr: 0.0010\n",
      "Epoch 21/50\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.1697 - accuracy: 0.9605 - val_loss: 0.1703 - val_accuracy: 0.9579 - lr: 0.0010\n",
      "Epoch 22/50\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.1697 - accuracy: 0.9606 - val_loss: 0.1703 - val_accuracy: 0.9580 - lr: 0.0010\n",
      "Epoch 23/50\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.1697 - accuracy: 0.9606 - val_loss: 0.1703 - val_accuracy: 0.9580 - lr: 0.0010\n",
      "Epoch 24/50\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.1697 - accuracy: 0.9606 - val_loss: 0.1703 - val_accuracy: 0.9579 - lr: 0.0010\n",
      "Epoch 25/50\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.1697 - accuracy: 0.9605 - val_loss: 0.1703 - val_accuracy: 0.9578 - lr: 0.0010\n",
      "Epoch 26/50\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.1697 - accuracy: 0.9605 - val_loss: 0.1704 - val_accuracy: 0.9579 - lr: 0.0010\n",
      "Epoch 27/50\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.1697 - accuracy: 0.9606 - val_loss: 0.1703 - val_accuracy: 0.9580 - lr: 0.0010\n",
      "Epoch 28/50\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.1697 - accuracy: 0.9606 - val_loss: 0.1703 - val_accuracy: 0.9579 - lr: 0.0010\n",
      "Epoch 29/50\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.1697 - accuracy: 0.9605 - val_loss: 0.1704 - val_accuracy: 0.9579 - lr: 0.0010\n",
      "Epoch 30/50\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.1697 - accuracy: 0.9606 - val_loss: 0.1703 - val_accuracy: 0.9579 - lr: 0.0010\n",
      "Epoch 31/50\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.1697 - accuracy: 0.9605 - val_loss: 0.1703 - val_accuracy: 0.9580 - lr: 0.0010\n",
      "Epoch 32/50\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.1697 - accuracy: 0.9606 - val_loss: 0.1704 - val_accuracy: 0.9579 - lr: 0.0010\n",
      "Epoch 33/50\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.1697 - accuracy: 0.9605 - val_loss: 0.1703 - val_accuracy: 0.9578 - lr: 0.0010\n",
      "Epoch 34/50\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.1697 - accuracy: 0.9605 - val_loss: 0.1702 - val_accuracy: 0.9579 - lr: 0.0010\n",
      "Epoch 35/50\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.1697 - accuracy: 0.9606 - val_loss: 0.1703 - val_accuracy: 0.9579 - lr: 0.0010\n",
      "Epoch 36/50\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.1697 - accuracy: 0.9606 - val_loss: 0.1703 - val_accuracy: 0.9578 - lr: 0.0010\n",
      "Epoch 37/50\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.1697 - accuracy: 0.9605 - val_loss: 0.1702 - val_accuracy: 0.9579 - lr: 0.0010\n",
      "Epoch 38/50\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.1697 - accuracy: 0.9605 - val_loss: 0.1703 - val_accuracy: 0.9580 - lr: 0.0010\n",
      "Epoch 39/50\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.1697 - accuracy: 0.9606 - val_loss: 0.1703 - val_accuracy: 0.9580 - lr: 0.0010\n",
      "Epoch 40/50\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.1697 - accuracy: 0.9606 - val_loss: 0.1704 - val_accuracy: 0.9580 - lr: 0.0010\n",
      "Epoch 41/50\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.1697 - accuracy: 0.9606 - val_loss: 0.1705 - val_accuracy: 0.9579 - lr: 0.0010\n",
      "Epoch 42/50\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.1697 - accuracy: 0.9605 - val_loss: 0.1704 - val_accuracy: 0.9579 - lr: 0.0010\n",
      "Epoch 43/50\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.1697 - accuracy: 0.9606 - val_loss: 0.1702 - val_accuracy: 0.9580 - lr: 0.0010\n",
      "Epoch 44/50\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.1697 - accuracy: 0.9605 - val_loss: 0.1703 - val_accuracy: 0.9578 - lr: 0.0010\n",
      "Epoch 45/50\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.1697 - accuracy: 0.9606 - val_loss: 0.1704 - val_accuracy: 0.9578 - lr: 0.0010\n",
      "Epoch 46/50\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.1697 - accuracy: 0.9606 - val_loss: 0.1702 - val_accuracy: 0.9580 - lr: 0.0010\n",
      "Epoch 47/50\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.1697 - accuracy: 0.9606 - val_loss: 0.1703 - val_accuracy: 0.9580 - lr: 0.0010\n",
      "Epoch 48/50\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.1696 - accuracy: 0.9605 - val_loss: 0.1703 - val_accuracy: 0.9580 - lr: 0.0010\n",
      "Epoch 49/50\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.1697 - accuracy: 0.9606 - val_loss: 0.1702 - val_accuracy: 0.9580 - lr: 0.0010\n",
      "Epoch 50/50\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.1697 - accuracy: 0.9606 - val_loss: 0.1703 - val_accuracy: 0.9580 - lr: 0.0010\n",
      "3125/3125 [==============================] - 5s 2ms/step\n",
      "Keras  Accuracy: 0.96008\n",
      "1563/1563 [==============================] - 2s 1ms/step\n",
      "Total correct: 47323\n",
      "Total incorrect: 2677\n",
      "Total samples: 50000\n",
      "Keras Excited Accuracy: 0.94646\n",
      "1563/1563 [==============================] - 2s 1ms/step\n",
      "Total correct: 48685\n",
      "Total incorrect: 1315\n",
      "Total samples: 50000\n",
      "Keras Ground Accuracy: 0.9737\n",
      "\n",
      "===================================\n",
      "Fidelity 0.96008\n",
      "===================================\n",
      "Epoch 1/50\n",
      "105/105 [==============================] - 2s 11ms/step - loss: 0.1728 - accuracy: 0.9604 - val_loss: 0.1725 - val_accuracy: 0.9581 - lr: 0.0010\n",
      "Epoch 2/50\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.1716 - accuracy: 0.9608 - val_loss: 0.1724 - val_accuracy: 0.9584 - lr: 0.0010\n",
      "Epoch 3/50\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.1714 - accuracy: 0.9609 - val_loss: 0.1724 - val_accuracy: 0.9584 - lr: 0.0010\n",
      "Epoch 4/50\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.1713 - accuracy: 0.9609 - val_loss: 0.1723 - val_accuracy: 0.9584 - lr: 0.0010\n",
      "Epoch 5/50\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.1713 - accuracy: 0.9609 - val_loss: 0.1724 - val_accuracy: 0.9584 - lr: 0.0010\n",
      "Epoch 6/50\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.1713 - accuracy: 0.9609 - val_loss: 0.1725 - val_accuracy: 0.9584 - lr: 0.0010\n",
      "Epoch 7/50\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.1713 - accuracy: 0.9609 - val_loss: 0.1723 - val_accuracy: 0.9584 - lr: 0.0010\n",
      "Epoch 8/50\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.1712 - accuracy: 0.9609 - val_loss: 0.1724 - val_accuracy: 0.9584 - lr: 0.0010\n",
      "Epoch 9/50\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.1713 - accuracy: 0.9609 - val_loss: 0.1723 - val_accuracy: 0.9584 - lr: 0.0010\n",
      "Epoch 10/50\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.1712 - accuracy: 0.9609 - val_loss: 0.1725 - val_accuracy: 0.9583 - lr: 0.0010\n",
      "Epoch 11/50\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.1712 - accuracy: 0.9609 - val_loss: 0.1724 - val_accuracy: 0.9584 - lr: 0.0010\n",
      "Epoch 12/50\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.1712 - accuracy: 0.9609 - val_loss: 0.1724 - val_accuracy: 0.9583 - lr: 0.0010\n",
      "Epoch 13/50\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.1712 - accuracy: 0.9609 - val_loss: 0.1723 - val_accuracy: 0.9584 - lr: 0.0010\n",
      "Epoch 14/50\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.1712 - accuracy: 0.9610 - val_loss: 0.1723 - val_accuracy: 0.9584 - lr: 0.0010\n",
      "Epoch 15/50\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.1712 - accuracy: 0.9609 - val_loss: 0.1723 - val_accuracy: 0.9583 - lr: 0.0010\n",
      "Epoch 16/50\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.1712 - accuracy: 0.9609 - val_loss: 0.1724 - val_accuracy: 0.9584 - lr: 0.0010\n",
      "Epoch 17/50\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.1712 - accuracy: 0.9609 - val_loss: 0.1725 - val_accuracy: 0.9583 - lr: 0.0010\n",
      "Epoch 18/50\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.1712 - accuracy: 0.9609 - val_loss: 0.1725 - val_accuracy: 0.9583 - lr: 0.0010\n",
      "Epoch 19/50\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.1712 - accuracy: 0.9609 - val_loss: 0.1724 - val_accuracy: 0.9583 - lr: 0.0010\n",
      "Epoch 20/50\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.1712 - accuracy: 0.9609 - val_loss: 0.1724 - val_accuracy: 0.9584 - lr: 0.0010\n",
      "Epoch 21/50\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.1712 - accuracy: 0.9609 - val_loss: 0.1724 - val_accuracy: 0.9583 - lr: 0.0010\n",
      "Epoch 22/50\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.1712 - accuracy: 0.9609 - val_loss: 0.1725 - val_accuracy: 0.9582 - lr: 0.0010\n",
      "Epoch 23/50\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.1711 - accuracy: 0.9609 - val_loss: 0.1724 - val_accuracy: 0.9583 - lr: 0.0010\n",
      "Epoch 24/50\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.1712 - accuracy: 0.9609 - val_loss: 0.1724 - val_accuracy: 0.9584 - lr: 0.0010\n",
      "Epoch 25/50\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.1712 - accuracy: 0.9609 - val_loss: 0.1723 - val_accuracy: 0.9584 - lr: 0.0010\n",
      "Epoch 26/50\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.1712 - accuracy: 0.9609 - val_loss: 0.1723 - val_accuracy: 0.9584 - lr: 0.0010\n",
      "Epoch 27/50\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.1712 - accuracy: 0.9609 - val_loss: 0.1724 - val_accuracy: 0.9583 - lr: 0.0010\n",
      "Epoch 28/50\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.1711 - accuracy: 0.9609 - val_loss: 0.1724 - val_accuracy: 0.9583 - lr: 0.0010\n",
      "Epoch 29/50\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.1711 - accuracy: 0.9609 - val_loss: 0.1725 - val_accuracy: 0.9582 - lr: 0.0010\n",
      "Epoch 30/50\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.1711 - accuracy: 0.9609 - val_loss: 0.1724 - val_accuracy: 0.9583 - lr: 0.0010\n",
      "Epoch 31/50\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.1712 - accuracy: 0.9609 - val_loss: 0.1724 - val_accuracy: 0.9583 - lr: 0.0010\n",
      "Epoch 32/50\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.1711 - accuracy: 0.9609 - val_loss: 0.1724 - val_accuracy: 0.9583 - lr: 0.0010\n",
      "Epoch 33/50\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.1711 - accuracy: 0.9609 - val_loss: 0.1724 - val_accuracy: 0.9583 - lr: 0.0010\n",
      "Epoch 34/50\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.1712 - accuracy: 0.9609 - val_loss: 0.1724 - val_accuracy: 0.9583 - lr: 0.0010\n",
      "Epoch 35/50\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.1712 - accuracy: 0.9609 - val_loss: 0.1724 - val_accuracy: 0.9583 - lr: 0.0010\n",
      "Epoch 36/50\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.1711 - accuracy: 0.9609 - val_loss: 0.1725 - val_accuracy: 0.9583 - lr: 0.0010\n",
      "Epoch 37/50\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.1712 - accuracy: 0.9609 - val_loss: 0.1723 - val_accuracy: 0.9582 - lr: 0.0010\n",
      "Epoch 38/50\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.1711 - accuracy: 0.9609 - val_loss: 0.1724 - val_accuracy: 0.9584 - lr: 0.0010\n",
      "Epoch 39/50\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.1711 - accuracy: 0.9609 - val_loss: 0.1723 - val_accuracy: 0.9584 - lr: 0.0010\n",
      "Epoch 40/50\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.1711 - accuracy: 0.9609 - val_loss: 0.1724 - val_accuracy: 0.9583 - lr: 0.0010\n",
      "Epoch 41/50\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.1711 - accuracy: 0.9609 - val_loss: 0.1725 - val_accuracy: 0.9582 - lr: 0.0010\n",
      "Epoch 42/50\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.1711 - accuracy: 0.9609 - val_loss: 0.1724 - val_accuracy: 0.9584 - lr: 0.0010\n",
      "Epoch 43/50\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.1711 - accuracy: 0.9609 - val_loss: 0.1724 - val_accuracy: 0.9583 - lr: 0.0010\n",
      "Epoch 44/50\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.1711 - accuracy: 0.9610 - val_loss: 0.1724 - val_accuracy: 0.9582 - lr: 0.0010\n",
      "Epoch 45/50\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.1711 - accuracy: 0.9609 - val_loss: 0.1725 - val_accuracy: 0.9582 - lr: 0.0010\n",
      "Epoch 46/50\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.1711 - accuracy: 0.9609 - val_loss: 0.1724 - val_accuracy: 0.9583 - lr: 0.0010\n",
      "Epoch 47/50\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.1711 - accuracy: 0.9609 - val_loss: 0.1724 - val_accuracy: 0.9583 - lr: 0.0010\n",
      "Epoch 48/50\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.1711 - accuracy: 0.9609 - val_loss: 0.1724 - val_accuracy: 0.9584 - lr: 0.0010\n",
      "Epoch 49/50\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.1711 - accuracy: 0.9609 - val_loss: 0.1723 - val_accuracy: 0.9583 - lr: 0.0010\n",
      "Epoch 50/50\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.1711 - accuracy: 0.9609 - val_loss: 0.1724 - val_accuracy: 0.9583 - lr: 0.0010\n",
      "3125/3125 [==============================] - 4s 1ms/step\n",
      "Keras  Accuracy: 0.95982\n",
      "1563/1563 [==============================] - 2s 1ms/step\n",
      "Total correct: 47187\n",
      "Total incorrect: 2813\n",
      "Total samples: 50000\n",
      "Keras Excited Accuracy: 0.94374\n",
      "1563/1563 [==============================] - 2s 1ms/step\n",
      "Total correct: 48795\n",
      "Total incorrect: 1205\n",
      "Total samples: 50000\n",
      "Keras Ground Accuracy: 0.9759\n",
      "\n",
      "===================================\n",
      "Fidelity 0.95982\n",
      "===================================\n",
      "Epoch 1/50\n",
      "105/105 [==============================] - 2s 11ms/step - loss: 0.1779 - accuracy: 0.9588 - val_loss: 0.1767 - val_accuracy: 0.9572 - lr: 0.0010\n",
      "Epoch 2/50\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.1757 - accuracy: 0.9595 - val_loss: 0.1762 - val_accuracy: 0.9573 - lr: 0.0010\n",
      "Epoch 3/50\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.1753 - accuracy: 0.9597 - val_loss: 0.1764 - val_accuracy: 0.9574 - lr: 0.0010\n",
      "Epoch 4/50\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.1752 - accuracy: 0.9598 - val_loss: 0.1764 - val_accuracy: 0.9574 - lr: 0.0010\n",
      "Epoch 5/50\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.1751 - accuracy: 0.9598 - val_loss: 0.1764 - val_accuracy: 0.9574 - lr: 0.0010\n",
      "Epoch 6/50\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.1751 - accuracy: 0.9598 - val_loss: 0.1765 - val_accuracy: 0.9574 - lr: 0.0010\n",
      "Epoch 7/50\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.1750 - accuracy: 0.9598 - val_loss: 0.1765 - val_accuracy: 0.9575 - lr: 0.0010\n",
      "Epoch 8/50\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.1750 - accuracy: 0.9598 - val_loss: 0.1765 - val_accuracy: 0.9575 - lr: 0.0010\n",
      "Epoch 9/50\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.1750 - accuracy: 0.9598 - val_loss: 0.1764 - val_accuracy: 0.9574 - lr: 0.0010\n",
      "Epoch 10/50\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.1750 - accuracy: 0.9598 - val_loss: 0.1765 - val_accuracy: 0.9574 - lr: 0.0010\n",
      "Epoch 11/50\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.1750 - accuracy: 0.9598 - val_loss: 0.1765 - val_accuracy: 0.9574 - lr: 0.0010\n",
      "Epoch 12/50\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.1750 - accuracy: 0.9598 - val_loss: 0.1764 - val_accuracy: 0.9574 - lr: 0.0010\n",
      "Epoch 13/50\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.1750 - accuracy: 0.9598 - val_loss: 0.1765 - val_accuracy: 0.9575 - lr: 0.0010\n",
      "Epoch 14/50\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.1750 - accuracy: 0.9598 - val_loss: 0.1764 - val_accuracy: 0.9575 - lr: 0.0010\n",
      "Epoch 15/50\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.1750 - accuracy: 0.9598 - val_loss: 0.1765 - val_accuracy: 0.9574 - lr: 0.0010\n",
      "Epoch 16/50\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.1750 - accuracy: 0.9598 - val_loss: 0.1764 - val_accuracy: 0.9574 - lr: 0.0010\n",
      "Epoch 17/50\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.1750 - accuracy: 0.9598 - val_loss: 0.1763 - val_accuracy: 0.9575 - lr: 0.0010\n",
      "Epoch 18/50\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.1750 - accuracy: 0.9598 - val_loss: 0.1764 - val_accuracy: 0.9575 - lr: 0.0010\n",
      "Epoch 19/50\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.1750 - accuracy: 0.9598 - val_loss: 0.1763 - val_accuracy: 0.9575 - lr: 0.0010\n",
      "Epoch 20/50\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.1750 - accuracy: 0.9598 - val_loss: 0.1763 - val_accuracy: 0.9575 - lr: 0.0010\n",
      "Epoch 21/50\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.1750 - accuracy: 0.9598 - val_loss: 0.1764 - val_accuracy: 0.9574 - lr: 0.0010\n",
      "Epoch 22/50\n",
      "105/105 [==============================] - 1s 9ms/step - loss: 0.1750 - accuracy: 0.9598 - val_loss: 0.1765 - val_accuracy: 0.9574 - lr: 0.0010\n",
      "Epoch 23/50\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.1750 - accuracy: 0.9598 - val_loss: 0.1764 - val_accuracy: 0.9575 - lr: 0.0010\n",
      "Epoch 24/50\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.1749 - accuracy: 0.9598 - val_loss: 0.1763 - val_accuracy: 0.9574 - lr: 0.0010\n",
      "Epoch 25/50\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.1749 - accuracy: 0.9598 - val_loss: 0.1763 - val_accuracy: 0.9574 - lr: 0.0010\n",
      "Epoch 26/50\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.1749 - accuracy: 0.9598 - val_loss: 0.1763 - val_accuracy: 0.9575 - lr: 0.0010\n",
      "Epoch 27/50\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.1749 - accuracy: 0.9598 - val_loss: 0.1763 - val_accuracy: 0.9574 - lr: 0.0010\n",
      "Epoch 28/50\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.1749 - accuracy: 0.9598 - val_loss: 0.1764 - val_accuracy: 0.9574 - lr: 0.0010\n",
      "Epoch 29/50\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.1749 - accuracy: 0.9598 - val_loss: 0.1764 - val_accuracy: 0.9574 - lr: 0.0010\n",
      "Epoch 30/50\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.1749 - accuracy: 0.9598 - val_loss: 0.1764 - val_accuracy: 0.9575 - lr: 0.0010\n",
      "Epoch 31/50\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.1749 - accuracy: 0.9598 - val_loss: 0.1763 - val_accuracy: 0.9575 - lr: 0.0010\n",
      "Epoch 32/50\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.1749 - accuracy: 0.9598 - val_loss: 0.1764 - val_accuracy: 0.9575 - lr: 0.0010\n",
      "Epoch 33/50\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.1749 - accuracy: 0.9598 - val_loss: 0.1764 - val_accuracy: 0.9574 - lr: 0.0010\n",
      "Epoch 34/50\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.1749 - accuracy: 0.9598 - val_loss: 0.1764 - val_accuracy: 0.9574 - lr: 0.0010\n",
      "Epoch 35/50\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.1749 - accuracy: 0.9598 - val_loss: 0.1764 - val_accuracy: 0.9575 - lr: 0.0010\n",
      "Epoch 36/50\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.1749 - accuracy: 0.9598 - val_loss: 0.1765 - val_accuracy: 0.9573 - lr: 0.0010\n",
      "Epoch 37/50\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.1749 - accuracy: 0.9598 - val_loss: 0.1764 - val_accuracy: 0.9574 - lr: 0.0010\n",
      "Epoch 38/50\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.1749 - accuracy: 0.9598 - val_loss: 0.1763 - val_accuracy: 0.9574 - lr: 0.0010\n",
      "Epoch 39/50\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.1749 - accuracy: 0.9598 - val_loss: 0.1763 - val_accuracy: 0.9575 - lr: 0.0010\n",
      "Epoch 40/50\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.1749 - accuracy: 0.9598 - val_loss: 0.1763 - val_accuracy: 0.9574 - lr: 0.0010\n",
      "Epoch 41/50\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.1749 - accuracy: 0.9599 - val_loss: 0.1764 - val_accuracy: 0.9574 - lr: 0.0010\n",
      "Epoch 42/50\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.1749 - accuracy: 0.9598 - val_loss: 0.1763 - val_accuracy: 0.9574 - lr: 0.0010\n",
      "Epoch 43/50\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.1749 - accuracy: 0.9598 - val_loss: 0.1763 - val_accuracy: 0.9574 - lr: 0.0010\n",
      "Epoch 44/50\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.1749 - accuracy: 0.9598 - val_loss: 0.1764 - val_accuracy: 0.9573 - lr: 0.0010\n",
      "Epoch 45/50\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.1749 - accuracy: 0.9598 - val_loss: 0.1763 - val_accuracy: 0.9574 - lr: 0.0010\n",
      "Epoch 46/50\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.1749 - accuracy: 0.9598 - val_loss: 0.1764 - val_accuracy: 0.9574 - lr: 0.0010\n",
      "Epoch 47/50\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.1749 - accuracy: 0.9598 - val_loss: 0.1763 - val_accuracy: 0.9574 - lr: 0.0010\n",
      "Epoch 48/50\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.1749 - accuracy: 0.9598 - val_loss: 0.1764 - val_accuracy: 0.9574 - lr: 0.0010\n",
      "Epoch 49/50\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.1749 - accuracy: 0.9598 - val_loss: 0.1764 - val_accuracy: 0.9575 - lr: 0.0010\n",
      "Epoch 50/50\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.1749 - accuracy: 0.9598 - val_loss: 0.1763 - val_accuracy: 0.9574 - lr: 0.0010\n",
      "3125/3125 [==============================] - 5s 2ms/step\n",
      "Keras  Accuracy: 0.95773\n",
      "1563/1563 [==============================] - 3s 2ms/step\n",
      "Total correct: 46960\n",
      "Total incorrect: 3040\n",
      "Total samples: 50000\n",
      "Keras Excited Accuracy: 0.9392\n",
      "1563/1563 [==============================] - 2s 1ms/step\n",
      "Total correct: 48813\n",
      "Total incorrect: 1187\n",
      "Total samples: 50000\n",
      "Keras Ground Accuracy: 0.97626\n",
      "\n",
      "===================================\n",
      "Fidelity 0.95773\n",
      "===================================\n",
      "Epoch 1/50\n",
      "105/105 [==============================] - 2s 11ms/step - loss: 0.1848 - accuracy: 0.9566 - val_loss: 0.1840 - val_accuracy: 0.9550 - lr: 0.0010\n",
      "Epoch 2/50\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.1818 - accuracy: 0.9575 - val_loss: 0.1832 - val_accuracy: 0.9555 - lr: 0.0010\n",
      "Epoch 3/50\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.1811 - accuracy: 0.9579 - val_loss: 0.1830 - val_accuracy: 0.9558 - lr: 0.0010\n",
      "Epoch 4/50\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.1809 - accuracy: 0.9579 - val_loss: 0.1830 - val_accuracy: 0.9556 - lr: 0.0010\n",
      "Epoch 5/50\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.1808 - accuracy: 0.9580 - val_loss: 0.1830 - val_accuracy: 0.9556 - lr: 0.0010\n",
      "Epoch 6/50\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.1808 - accuracy: 0.9580 - val_loss: 0.1828 - val_accuracy: 0.9556 - lr: 0.0010\n",
      "Epoch 7/50\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.1808 - accuracy: 0.9580 - val_loss: 0.1829 - val_accuracy: 0.9556 - lr: 0.0010\n",
      "Epoch 8/50\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.1807 - accuracy: 0.9580 - val_loss: 0.1830 - val_accuracy: 0.9556 - lr: 0.0010\n",
      "Epoch 9/50\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.1807 - accuracy: 0.9580 - val_loss: 0.1828 - val_accuracy: 0.9557 - lr: 0.0010\n",
      "Epoch 10/50\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.1807 - accuracy: 0.9580 - val_loss: 0.1827 - val_accuracy: 0.9556 - lr: 0.0010\n",
      "Epoch 11/50\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.1807 - accuracy: 0.9580 - val_loss: 0.1829 - val_accuracy: 0.9556 - lr: 0.0010\n",
      "Epoch 12/50\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.1807 - accuracy: 0.9580 - val_loss: 0.1828 - val_accuracy: 0.9555 - lr: 0.0010\n",
      "Epoch 13/50\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.1807 - accuracy: 0.9580 - val_loss: 0.1828 - val_accuracy: 0.9556 - lr: 0.0010\n",
      "Epoch 14/50\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.1807 - accuracy: 0.9580 - val_loss: 0.1828 - val_accuracy: 0.9556 - lr: 0.0010\n",
      "Epoch 15/50\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.1807 - accuracy: 0.9580 - val_loss: 0.1828 - val_accuracy: 0.9556 - lr: 0.0010\n",
      "Epoch 16/50\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.1806 - accuracy: 0.9580 - val_loss: 0.1827 - val_accuracy: 0.9556 - lr: 0.0010\n",
      "Epoch 17/50\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.1806 - accuracy: 0.9579 - val_loss: 0.1828 - val_accuracy: 0.9555 - lr: 0.0010\n",
      "Epoch 18/50\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.1806 - accuracy: 0.9579 - val_loss: 0.1828 - val_accuracy: 0.9555 - lr: 0.0010\n",
      "Epoch 19/50\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.1807 - accuracy: 0.9579 - val_loss: 0.1828 - val_accuracy: 0.9555 - lr: 0.0010\n",
      "Epoch 20/50\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.1806 - accuracy: 0.9579 - val_loss: 0.1829 - val_accuracy: 0.9556 - lr: 0.0010\n",
      "Epoch 21/50\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.1806 - accuracy: 0.9580 - val_loss: 0.1827 - val_accuracy: 0.9556 - lr: 0.0010\n",
      "Epoch 22/50\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.1806 - accuracy: 0.9579 - val_loss: 0.1828 - val_accuracy: 0.9556 - lr: 0.0010\n",
      "Epoch 23/50\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.1806 - accuracy: 0.9579 - val_loss: 0.1828 - val_accuracy: 0.9555 - lr: 0.0010\n",
      "Epoch 24/50\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.1806 - accuracy: 0.9579 - val_loss: 0.1827 - val_accuracy: 0.9556 - lr: 0.0010\n",
      "Epoch 25/50\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.1806 - accuracy: 0.9580 - val_loss: 0.1828 - val_accuracy: 0.9555 - lr: 0.0010\n",
      "Epoch 26/50\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.1806 - accuracy: 0.9579 - val_loss: 0.1828 - val_accuracy: 0.9555 - lr: 0.0010\n",
      "Epoch 27/50\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.1806 - accuracy: 0.9580 - val_loss: 0.1828 - val_accuracy: 0.9556 - lr: 0.0010\n",
      "Epoch 28/50\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.1806 - accuracy: 0.9580 - val_loss: 0.1829 - val_accuracy: 0.9556 - lr: 0.0010\n",
      "Epoch 29/50\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.1806 - accuracy: 0.9580 - val_loss: 0.1828 - val_accuracy: 0.9556 - lr: 0.0010\n",
      "Epoch 30/50\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.1806 - accuracy: 0.9579 - val_loss: 0.1828 - val_accuracy: 0.9556 - lr: 0.0010\n",
      "Epoch 31/50\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.1806 - accuracy: 0.9579 - val_loss: 0.1827 - val_accuracy: 0.9555 - lr: 0.0010\n",
      "Epoch 32/50\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.1806 - accuracy: 0.9579 - val_loss: 0.1828 - val_accuracy: 0.9556 - lr: 0.0010\n",
      "Epoch 33/50\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.1806 - accuracy: 0.9580 - val_loss: 0.1828 - val_accuracy: 0.9557 - lr: 0.0010\n",
      "Epoch 34/50\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.1806 - accuracy: 0.9580 - val_loss: 0.1829 - val_accuracy: 0.9555 - lr: 0.0010\n",
      "Epoch 35/50\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.1806 - accuracy: 0.9579 - val_loss: 0.1826 - val_accuracy: 0.9556 - lr: 0.0010\n",
      "Epoch 36/50\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.1806 - accuracy: 0.9580 - val_loss: 0.1829 - val_accuracy: 0.9556 - lr: 0.0010\n",
      "Epoch 37/50\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.1806 - accuracy: 0.9580 - val_loss: 0.1828 - val_accuracy: 0.9556 - lr: 0.0010\n",
      "Epoch 38/50\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.1806 - accuracy: 0.9580 - val_loss: 0.1828 - val_accuracy: 0.9556 - lr: 0.0010\n",
      "Epoch 39/50\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.1806 - accuracy: 0.9579 - val_loss: 0.1826 - val_accuracy: 0.9556 - lr: 0.0010\n",
      "Epoch 40/50\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.1806 - accuracy: 0.9580 - val_loss: 0.1828 - val_accuracy: 0.9555 - lr: 0.0010\n",
      "Epoch 41/50\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.1806 - accuracy: 0.9580 - val_loss: 0.1828 - val_accuracy: 0.9555 - lr: 0.0010\n",
      "Epoch 42/50\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.1806 - accuracy: 0.9580 - val_loss: 0.1828 - val_accuracy: 0.9556 - lr: 0.0010\n",
      "Epoch 43/50\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.1806 - accuracy: 0.9580 - val_loss: 0.1828 - val_accuracy: 0.9556 - lr: 0.0010\n",
      "Epoch 44/50\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.1806 - accuracy: 0.9580 - val_loss: 0.1828 - val_accuracy: 0.9556 - lr: 0.0010\n",
      "Epoch 45/50\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.1806 - accuracy: 0.9579 - val_loss: 0.1827 - val_accuracy: 0.9556 - lr: 0.0010\n",
      "Epoch 46/50\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.1806 - accuracy: 0.9580 - val_loss: 0.1828 - val_accuracy: 0.9556 - lr: 0.0010\n",
      "Epoch 47/50\n",
      "105/105 [==============================] - 1s 13ms/step - loss: 0.1806 - accuracy: 0.9579 - val_loss: 0.1828 - val_accuracy: 0.9556 - lr: 0.0010\n",
      "Epoch 48/50\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.1806 - accuracy: 0.9580 - val_loss: 0.1828 - val_accuracy: 0.9555 - lr: 0.0010\n",
      "Epoch 49/50\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.1806 - accuracy: 0.9580 - val_loss: 0.1828 - val_accuracy: 0.9556 - lr: 0.0010\n",
      "Epoch 50/50\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.1805 - accuracy: 0.9579 - val_loss: 0.1827 - val_accuracy: 0.9556 - lr: 0.0010\n",
      "3125/3125 [==============================] - 5s 2ms/step\n",
      "Keras  Accuracy: 0.95521\n",
      "1563/1563 [==============================] - 3s 2ms/step\n",
      "Total correct: 46699\n",
      "Total incorrect: 3301\n",
      "Total samples: 50000\n",
      "Keras Excited Accuracy: 0.93398\n",
      "1563/1563 [==============================] - 3s 2ms/step\n",
      "Total correct: 48822\n",
      "Total incorrect: 1178\n",
      "Total samples: 50000\n",
      "Keras Ground Accuracy: 0.97644\n",
      "\n",
      "===================================\n",
      "Fidelity 0.95521\n",
      "===================================\n",
      "Epoch 1/50\n",
      "105/105 [==============================] - 2s 11ms/step - loss: 0.1929 - accuracy: 0.9541 - val_loss: 0.1926 - val_accuracy: 0.9520 - lr: 0.0010\n",
      "Epoch 2/50\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.1893 - accuracy: 0.9551 - val_loss: 0.1913 - val_accuracy: 0.9527 - lr: 0.0010\n",
      "Epoch 3/50\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.1885 - accuracy: 0.9554 - val_loss: 0.1912 - val_accuracy: 0.9529 - lr: 0.0010\n",
      "Epoch 4/50\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.1882 - accuracy: 0.9555 - val_loss: 0.1910 - val_accuracy: 0.9530 - lr: 0.0010\n",
      "Epoch 5/50\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.1881 - accuracy: 0.9555 - val_loss: 0.1909 - val_accuracy: 0.9529 - lr: 0.0010\n",
      "Epoch 6/50\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.1880 - accuracy: 0.9555 - val_loss: 0.1908 - val_accuracy: 0.9528 - lr: 0.0010\n",
      "Epoch 7/50\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.1880 - accuracy: 0.9555 - val_loss: 0.1909 - val_accuracy: 0.9528 - lr: 0.0010\n",
      "Epoch 8/50\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.1879 - accuracy: 0.9554 - val_loss: 0.1908 - val_accuracy: 0.9528 - lr: 0.0010\n",
      "Epoch 9/50\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.1879 - accuracy: 0.9554 - val_loss: 0.1908 - val_accuracy: 0.9528 - lr: 0.0010\n",
      "Epoch 10/50\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.1879 - accuracy: 0.9555 - val_loss: 0.1907 - val_accuracy: 0.9528 - lr: 0.0010\n",
      "Epoch 11/50\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.1879 - accuracy: 0.9554 - val_loss: 0.1906 - val_accuracy: 0.9527 - lr: 0.0010\n",
      "Epoch 12/50\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.1879 - accuracy: 0.9555 - val_loss: 0.1907 - val_accuracy: 0.9528 - lr: 0.0010\n",
      "Epoch 13/50\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.1879 - accuracy: 0.9555 - val_loss: 0.1906 - val_accuracy: 0.9527 - lr: 0.0010\n",
      "Epoch 14/50\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.1878 - accuracy: 0.9554 - val_loss: 0.1906 - val_accuracy: 0.9527 - lr: 0.0010\n",
      "Epoch 15/50\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.1879 - accuracy: 0.9555 - val_loss: 0.1908 - val_accuracy: 0.9528 - lr: 0.0010\n",
      "Epoch 16/50\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.1878 - accuracy: 0.9554 - val_loss: 0.1906 - val_accuracy: 0.9528 - lr: 0.0010\n",
      "Epoch 17/50\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.1878 - accuracy: 0.9555 - val_loss: 0.1907 - val_accuracy: 0.9527 - lr: 0.0010\n",
      "Epoch 18/50\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.1878 - accuracy: 0.9554 - val_loss: 0.1907 - val_accuracy: 0.9527 - lr: 0.0010\n",
      "Epoch 19/50\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.1878 - accuracy: 0.9555 - val_loss: 0.1907 - val_accuracy: 0.9527 - lr: 0.0010\n",
      "Epoch 20/50\n",
      "105/105 [==============================] - 1s 12ms/step - loss: 0.1878 - accuracy: 0.9554 - val_loss: 0.1907 - val_accuracy: 0.9527 - lr: 0.0010\n",
      "Epoch 21/50\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.1878 - accuracy: 0.9555 - val_loss: 0.1906 - val_accuracy: 0.9527 - lr: 0.0010\n",
      "Epoch 22/50\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.1878 - accuracy: 0.9554 - val_loss: 0.1907 - val_accuracy: 0.9528 - lr: 0.0010\n",
      "Epoch 23/50\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.1878 - accuracy: 0.9554 - val_loss: 0.1907 - val_accuracy: 0.9528 - lr: 0.0010\n",
      "Epoch 24/50\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.1878 - accuracy: 0.9555 - val_loss: 0.1908 - val_accuracy: 0.9528 - lr: 0.0010\n",
      "Epoch 25/50\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.1878 - accuracy: 0.9554 - val_loss: 0.1907 - val_accuracy: 0.9527 - lr: 0.0010\n",
      "Epoch 26/50\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.1878 - accuracy: 0.9555 - val_loss: 0.1908 - val_accuracy: 0.9527 - lr: 0.0010\n",
      "Epoch 27/50\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.1878 - accuracy: 0.9554 - val_loss: 0.1907 - val_accuracy: 0.9527 - lr: 0.0010\n",
      "Epoch 28/50\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.1878 - accuracy: 0.9554 - val_loss: 0.1907 - val_accuracy: 0.9527 - lr: 0.0010\n",
      "Epoch 29/50\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.1878 - accuracy: 0.9554 - val_loss: 0.1907 - val_accuracy: 0.9528 - lr: 0.0010\n",
      "Epoch 30/50\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.1878 - accuracy: 0.9555 - val_loss: 0.1907 - val_accuracy: 0.9528 - lr: 0.0010\n",
      "Epoch 31/50\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.1878 - accuracy: 0.9554 - val_loss: 0.1907 - val_accuracy: 0.9528 - lr: 0.0010\n",
      "Epoch 32/50\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.1878 - accuracy: 0.9555 - val_loss: 0.1908 - val_accuracy: 0.9527 - lr: 0.0010\n",
      "Epoch 33/50\n",
      "105/105 [==============================] - 1s 12ms/step - loss: 0.1878 - accuracy: 0.9554 - val_loss: 0.1908 - val_accuracy: 0.9527 - lr: 0.0010\n",
      "Epoch 34/50\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.1878 - accuracy: 0.9554 - val_loss: 0.1907 - val_accuracy: 0.9528 - lr: 0.0010\n",
      "Epoch 35/50\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.1878 - accuracy: 0.9555 - val_loss: 0.1908 - val_accuracy: 0.9527 - lr: 0.0010\n",
      "Epoch 36/50\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.1878 - accuracy: 0.9555 - val_loss: 0.1908 - val_accuracy: 0.9527 - lr: 0.0010\n",
      "Epoch 37/50\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.1878 - accuracy: 0.9554 - val_loss: 0.1906 - val_accuracy: 0.9527 - lr: 0.0010\n",
      "Epoch 38/50\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.1878 - accuracy: 0.9554 - val_loss: 0.1906 - val_accuracy: 0.9528 - lr: 0.0010\n",
      "Epoch 39/50\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.1878 - accuracy: 0.9554 - val_loss: 0.1907 - val_accuracy: 0.9528 - lr: 0.0010\n",
      "Epoch 40/50\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.1878 - accuracy: 0.9554 - val_loss: 0.1907 - val_accuracy: 0.9528 - lr: 0.0010\n",
      "Epoch 41/50\n",
      "105/105 [==============================] - 1s 11ms/step - loss: 0.1877 - accuracy: 0.9555 - val_loss: 0.1907 - val_accuracy: 0.9528 - lr: 0.0010\n",
      "Epoch 42/50\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.1878 - accuracy: 0.9555 - val_loss: 0.1907 - val_accuracy: 0.9528 - lr: 0.0010\n",
      "Epoch 43/50\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.1878 - accuracy: 0.9555 - val_loss: 0.1908 - val_accuracy: 0.9527 - lr: 0.0010\n",
      "Epoch 44/50\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.1878 - accuracy: 0.9555 - val_loss: 0.1908 - val_accuracy: 0.9527 - lr: 0.0010\n",
      "Epoch 45/50\n",
      "105/105 [==============================] - 1s 12ms/step - loss: 0.1878 - accuracy: 0.9554 - val_loss: 0.1907 - val_accuracy: 0.9528 - lr: 0.0010\n",
      "Epoch 46/50\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.1877 - accuracy: 0.9555 - val_loss: 0.1908 - val_accuracy: 0.9527 - lr: 0.0010\n",
      "Epoch 47/50\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.1877 - accuracy: 0.9555 - val_loss: 0.1907 - val_accuracy: 0.9527 - lr: 0.0010\n",
      "Epoch 48/50\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.1877 - accuracy: 0.9554 - val_loss: 0.1906 - val_accuracy: 0.9528 - lr: 0.0010\n",
      "Epoch 49/50\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.1877 - accuracy: 0.9554 - val_loss: 0.1907 - val_accuracy: 0.9527 - lr: 0.0010\n",
      "Epoch 50/50\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.1877 - accuracy: 0.9555 - val_loss: 0.1908 - val_accuracy: 0.9528 - lr: 0.0010\n",
      "3125/3125 [==============================] - 5s 2ms/step\n",
      "Keras  Accuracy: 0.95263\n",
      "1563/1563 [==============================] - 3s 2ms/step\n",
      "Total correct: 46436\n",
      "Total incorrect: 3564\n",
      "Total samples: 50000\n",
      "Keras Excited Accuracy: 0.92872\n",
      "1563/1563 [==============================] - 2s 1ms/step\n",
      "Total correct: 48827\n",
      "Total incorrect: 1173\n",
      "Total samples: 50000\n",
      "Keras Ground Accuracy: 0.97654\n",
      "\n",
      "===================================\n",
      "Fidelity 0.95263\n",
      "===================================\n",
      "Epoch 1/50\n",
      "105/105 [==============================] - 2s 11ms/step - loss: 0.2013 - accuracy: 0.9514 - val_loss: 0.2013 - val_accuracy: 0.9490 - lr: 0.0010\n",
      "Epoch 2/50\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.1975 - accuracy: 0.9524 - val_loss: 0.1997 - val_accuracy: 0.9496 - lr: 0.0010\n",
      "Epoch 3/50\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.1965 - accuracy: 0.9527 - val_loss: 0.1994 - val_accuracy: 0.9498 - lr: 0.0010\n",
      "Epoch 4/50\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.1961 - accuracy: 0.9529 - val_loss: 0.1992 - val_accuracy: 0.9498 - lr: 0.0010\n",
      "Epoch 5/50\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.1960 - accuracy: 0.9529 - val_loss: 0.1992 - val_accuracy: 0.9497 - lr: 0.0010\n",
      "Epoch 6/50\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.1959 - accuracy: 0.9528 - val_loss: 0.1991 - val_accuracy: 0.9495 - lr: 0.0010\n",
      "Epoch 7/50\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.1958 - accuracy: 0.9528 - val_loss: 0.1989 - val_accuracy: 0.9496 - lr: 0.0010\n",
      "Epoch 8/50\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.1957 - accuracy: 0.9528 - val_loss: 0.1989 - val_accuracy: 0.9495 - lr: 0.0010\n",
      "Epoch 9/50\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.1957 - accuracy: 0.9528 - val_loss: 0.1987 - val_accuracy: 0.9496 - lr: 0.0010\n",
      "Epoch 10/50\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.1957 - accuracy: 0.9528 - val_loss: 0.1988 - val_accuracy: 0.9495 - lr: 0.0010\n",
      "Epoch 11/50\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.1956 - accuracy: 0.9528 - val_loss: 0.1988 - val_accuracy: 0.9496 - lr: 0.0010\n",
      "Epoch 12/50\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.1956 - accuracy: 0.9528 - val_loss: 0.1988 - val_accuracy: 0.9495 - lr: 0.0010\n",
      "Epoch 13/50\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.1956 - accuracy: 0.9528 - val_loss: 0.1990 - val_accuracy: 0.9494 - lr: 0.0010\n",
      "Epoch 14/50\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.1956 - accuracy: 0.9527 - val_loss: 0.1986 - val_accuracy: 0.9496 - lr: 0.0010\n",
      "Epoch 15/50\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.1956 - accuracy: 0.9527 - val_loss: 0.1987 - val_accuracy: 0.9494 - lr: 0.0010\n",
      "Epoch 16/50\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.1956 - accuracy: 0.9528 - val_loss: 0.1988 - val_accuracy: 0.9494 - lr: 0.0010\n",
      "Epoch 17/50\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.1956 - accuracy: 0.9527 - val_loss: 0.1987 - val_accuracy: 0.9495 - lr: 0.0010\n",
      "Epoch 18/50\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.1956 - accuracy: 0.9527 - val_loss: 0.1986 - val_accuracy: 0.9494 - lr: 0.0010\n",
      "Epoch 19/50\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.1956 - accuracy: 0.9528 - val_loss: 0.1986 - val_accuracy: 0.9494 - lr: 0.0010\n",
      "Epoch 20/50\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.1956 - accuracy: 0.9527 - val_loss: 0.1987 - val_accuracy: 0.9494 - lr: 0.0010\n",
      "Epoch 21/50\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.1956 - accuracy: 0.9528 - val_loss: 0.1986 - val_accuracy: 0.9494 - lr: 0.0010\n",
      "Epoch 22/50\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.1955 - accuracy: 0.9527 - val_loss: 0.1989 - val_accuracy: 0.9493 - lr: 0.0010\n",
      "Epoch 23/50\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.1956 - accuracy: 0.9527 - val_loss: 0.1988 - val_accuracy: 0.9493 - lr: 0.0010\n",
      "Epoch 24/50\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.1956 - accuracy: 0.9527 - val_loss: 0.1988 - val_accuracy: 0.9494 - lr: 0.0010\n",
      "Epoch 25/50\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.1955 - accuracy: 0.9527 - val_loss: 0.1986 - val_accuracy: 0.9494 - lr: 0.0010\n",
      "Epoch 26/50\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.1955 - accuracy: 0.9527 - val_loss: 0.1986 - val_accuracy: 0.9494 - lr: 0.0010\n",
      "Epoch 27/50\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.1956 - accuracy: 0.9527 - val_loss: 0.1985 - val_accuracy: 0.9494 - lr: 0.0010\n",
      "Epoch 28/50\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.1955 - accuracy: 0.9528 - val_loss: 0.1987 - val_accuracy: 0.9494 - lr: 0.0010\n",
      "Epoch 29/50\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.1955 - accuracy: 0.9527 - val_loss: 0.1987 - val_accuracy: 0.9494 - lr: 0.0010\n",
      "Epoch 30/50\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.1956 - accuracy: 0.9527 - val_loss: 0.1987 - val_accuracy: 0.9493 - lr: 0.0010\n",
      "Epoch 31/50\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.1955 - accuracy: 0.9527 - val_loss: 0.1988 - val_accuracy: 0.9494 - lr: 0.0010\n",
      "Epoch 32/50\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.1955 - accuracy: 0.9527 - val_loss: 0.1987 - val_accuracy: 0.9494 - lr: 0.0010\n",
      "Epoch 33/50\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.1955 - accuracy: 0.9527 - val_loss: 0.1987 - val_accuracy: 0.9494 - lr: 0.0010\n",
      "Epoch 34/50\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.1955 - accuracy: 0.9527 - val_loss: 0.1987 - val_accuracy: 0.9492 - lr: 0.0010\n",
      "Epoch 35/50\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.1955 - accuracy: 0.9527 - val_loss: 0.1988 - val_accuracy: 0.9494 - lr: 0.0010\n",
      "Epoch 36/50\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.1955 - accuracy: 0.9527 - val_loss: 0.1987 - val_accuracy: 0.9494 - lr: 0.0010\n",
      "Epoch 37/50\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.1955 - accuracy: 0.9528 - val_loss: 0.1987 - val_accuracy: 0.9493 - lr: 0.0010\n",
      "Epoch 38/50\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.1955 - accuracy: 0.9527 - val_loss: 0.1987 - val_accuracy: 0.9493 - lr: 0.0010\n",
      "Epoch 39/50\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.1955 - accuracy: 0.9527 - val_loss: 0.1988 - val_accuracy: 0.9494 - lr: 0.0010\n",
      "Epoch 40/50\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.1955 - accuracy: 0.9527 - val_loss: 0.1987 - val_accuracy: 0.9495 - lr: 0.0010\n",
      "Epoch 41/50\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.1955 - accuracy: 0.9527 - val_loss: 0.1989 - val_accuracy: 0.9494 - lr: 0.0010\n",
      "Epoch 42/50\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.1955 - accuracy: 0.9527 - val_loss: 0.1986 - val_accuracy: 0.9494 - lr: 0.0010\n",
      "Epoch 43/50\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.1955 - accuracy: 0.9527 - val_loss: 0.1988 - val_accuracy: 0.9492 - lr: 0.0010\n",
      "Epoch 44/50\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.1955 - accuracy: 0.9527 - val_loss: 0.1988 - val_accuracy: 0.9494 - lr: 0.0010\n",
      "Epoch 45/50\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.1955 - accuracy: 0.9528 - val_loss: 0.1987 - val_accuracy: 0.9493 - lr: 0.0010\n",
      "Epoch 46/50\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.1955 - accuracy: 0.9528 - val_loss: 0.1987 - val_accuracy: 0.9493 - lr: 0.0010\n",
      "Epoch 47/50\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.1955 - accuracy: 0.9527 - val_loss: 0.1985 - val_accuracy: 0.9493 - lr: 0.0010\n",
      "Epoch 48/50\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.1955 - accuracy: 0.9527 - val_loss: 0.1989 - val_accuracy: 0.9493 - lr: 0.0010\n",
      "Epoch 49/50\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.1955 - accuracy: 0.9527 - val_loss: 0.1988 - val_accuracy: 0.9494 - lr: 0.0010\n",
      "Epoch 50/50\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.1955 - accuracy: 0.9527 - val_loss: 0.1986 - val_accuracy: 0.9493 - lr: 0.0010\n",
      "3125/3125 [==============================] - 5s 2ms/step\n",
      "Keras  Accuracy: 0.94974\n",
      "1563/1563 [==============================] - 2s 2ms/step\n",
      "Total correct: 46166\n",
      "Total incorrect: 3834\n",
      "Total samples: 50000\n",
      "Keras Excited Accuracy: 0.92332\n",
      "1563/1563 [==============================] - 3s 2ms/step\n",
      "Total correct: 48808\n",
      "Total incorrect: 1192\n",
      "Total samples: 50000\n",
      "Keras Ground Accuracy: 0.97616\n",
      "\n",
      "===================================\n",
      "Fidelity 0.94974\n",
      "===================================\n",
      "Epoch 1/50\n",
      "105/105 [==============================] - 2s 11ms/step - loss: 0.2099 - accuracy: 0.9488 - val_loss: 0.2093 - val_accuracy: 0.9464 - lr: 0.0010\n",
      "Epoch 2/50\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.2057 - accuracy: 0.9497 - val_loss: 0.2072 - val_accuracy: 0.9466 - lr: 0.0010\n",
      "Epoch 3/50\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.2045 - accuracy: 0.9500 - val_loss: 0.2067 - val_accuracy: 0.9466 - lr: 0.0010\n",
      "Epoch 4/50\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.2041 - accuracy: 0.9501 - val_loss: 0.2065 - val_accuracy: 0.9467 - lr: 0.0010\n",
      "Epoch 5/50\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.2039 - accuracy: 0.9502 - val_loss: 0.2062 - val_accuracy: 0.9466 - lr: 0.0010\n",
      "Epoch 6/50\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.2037 - accuracy: 0.9502 - val_loss: 0.2062 - val_accuracy: 0.9466 - lr: 0.0010\n",
      "Epoch 7/50\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.2036 - accuracy: 0.9501 - val_loss: 0.2060 - val_accuracy: 0.9466 - lr: 0.0010\n",
      "Epoch 8/50\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.2036 - accuracy: 0.9501 - val_loss: 0.2058 - val_accuracy: 0.9465 - lr: 0.0010\n",
      "Epoch 9/50\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.2035 - accuracy: 0.9501 - val_loss: 0.2057 - val_accuracy: 0.9465 - lr: 0.0010\n",
      "Epoch 10/50\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.2035 - accuracy: 0.9501 - val_loss: 0.2057 - val_accuracy: 0.9465 - lr: 0.0010\n",
      "Epoch 11/50\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.2034 - accuracy: 0.9501 - val_loss: 0.2057 - val_accuracy: 0.9466 - lr: 0.0010\n",
      "Epoch 12/50\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.2034 - accuracy: 0.9501 - val_loss: 0.2059 - val_accuracy: 0.9465 - lr: 0.0010\n",
      "Epoch 13/50\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.2034 - accuracy: 0.9500 - val_loss: 0.2057 - val_accuracy: 0.9464 - lr: 0.0010\n",
      "Epoch 14/50\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.2034 - accuracy: 0.9500 - val_loss: 0.2055 - val_accuracy: 0.9464 - lr: 0.0010\n",
      "Epoch 15/50\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.2034 - accuracy: 0.9500 - val_loss: 0.2056 - val_accuracy: 0.9464 - lr: 0.0010\n",
      "Epoch 16/50\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.2034 - accuracy: 0.9500 - val_loss: 0.2056 - val_accuracy: 0.9464 - lr: 0.0010\n",
      "Epoch 17/50\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.2033 - accuracy: 0.9500 - val_loss: 0.2055 - val_accuracy: 0.9464 - lr: 0.0010\n",
      "Epoch 18/50\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.2033 - accuracy: 0.9500 - val_loss: 0.2055 - val_accuracy: 0.9464 - lr: 0.0010\n",
      "Epoch 19/50\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.2033 - accuracy: 0.9500 - val_loss: 0.2057 - val_accuracy: 0.9465 - lr: 0.0010\n",
      "Epoch 20/50\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.2033 - accuracy: 0.9500 - val_loss: 0.2056 - val_accuracy: 0.9464 - lr: 0.0010\n",
      "Epoch 21/50\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.2033 - accuracy: 0.9500 - val_loss: 0.2054 - val_accuracy: 0.9464 - lr: 0.0010\n",
      "Epoch 22/50\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.2033 - accuracy: 0.9500 - val_loss: 0.2055 - val_accuracy: 0.9464 - lr: 0.0010\n",
      "Epoch 23/50\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.2033 - accuracy: 0.9500 - val_loss: 0.2056 - val_accuracy: 0.9464 - lr: 0.0010\n",
      "Epoch 24/50\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.2033 - accuracy: 0.9500 - val_loss: 0.2057 - val_accuracy: 0.9464 - lr: 0.0010\n",
      "Epoch 25/50\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.2033 - accuracy: 0.9500 - val_loss: 0.2058 - val_accuracy: 0.9464 - lr: 0.0010\n",
      "Epoch 26/50\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.2033 - accuracy: 0.9500 - val_loss: 0.2055 - val_accuracy: 0.9464 - lr: 0.0010\n",
      "Epoch 27/50\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.2033 - accuracy: 0.9500 - val_loss: 0.2056 - val_accuracy: 0.9463 - lr: 0.0010\n",
      "Epoch 28/50\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.2033 - accuracy: 0.9500 - val_loss: 0.2055 - val_accuracy: 0.9464 - lr: 0.0010\n",
      "Epoch 29/50\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.2033 - accuracy: 0.9500 - val_loss: 0.2056 - val_accuracy: 0.9464 - lr: 0.0010\n",
      "Epoch 30/50\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.2033 - accuracy: 0.9500 - val_loss: 0.2056 - val_accuracy: 0.9463 - lr: 0.0010\n",
      "Epoch 31/50\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.2033 - accuracy: 0.9500 - val_loss: 0.2056 - val_accuracy: 0.9465 - lr: 0.0010\n",
      "Epoch 32/50\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.2033 - accuracy: 0.9500 - val_loss: 0.2056 - val_accuracy: 0.9464 - lr: 0.0010\n",
      "Epoch 33/50\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.2033 - accuracy: 0.9500 - val_loss: 0.2056 - val_accuracy: 0.9464 - lr: 0.0010\n",
      "Epoch 34/50\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.2033 - accuracy: 0.9500 - val_loss: 0.2057 - val_accuracy: 0.9464 - lr: 0.0010\n",
      "Epoch 35/50\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.2033 - accuracy: 0.9500 - val_loss: 0.2057 - val_accuracy: 0.9464 - lr: 0.0010\n",
      "Epoch 36/50\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.2033 - accuracy: 0.9500 - val_loss: 0.2056 - val_accuracy: 0.9464 - lr: 0.0010\n",
      "Epoch 37/50\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.2033 - accuracy: 0.9500 - val_loss: 0.2056 - val_accuracy: 0.9464 - lr: 0.0010\n",
      "Epoch 38/50\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.2033 - accuracy: 0.9500 - val_loss: 0.2055 - val_accuracy: 0.9464 - lr: 0.0010\n",
      "Epoch 39/50\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.2033 - accuracy: 0.9500 - val_loss: 0.2055 - val_accuracy: 0.9464 - lr: 0.0010\n",
      "Epoch 40/50\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.2033 - accuracy: 0.9500 - val_loss: 0.2056 - val_accuracy: 0.9464 - lr: 0.0010\n",
      "Epoch 41/50\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.2033 - accuracy: 0.9500 - val_loss: 0.2055 - val_accuracy: 0.9464 - lr: 0.0010\n",
      "Epoch 42/50\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.2033 - accuracy: 0.9500 - val_loss: 0.2058 - val_accuracy: 0.9463 - lr: 0.0010\n",
      "Epoch 43/50\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.2033 - accuracy: 0.9500 - val_loss: 0.2056 - val_accuracy: 0.9464 - lr: 0.0010\n",
      "Epoch 44/50\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.2033 - accuracy: 0.9500 - val_loss: 0.2056 - val_accuracy: 0.9464 - lr: 0.0010\n",
      "Epoch 45/50\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.2033 - accuracy: 0.9500 - val_loss: 0.2055 - val_accuracy: 0.9463 - lr: 0.0010\n",
      "Epoch 46/50\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.2033 - accuracy: 0.9500 - val_loss: 0.2057 - val_accuracy: 0.9463 - lr: 0.0010\n",
      "Epoch 47/50\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.2033 - accuracy: 0.9500 - val_loss: 0.2056 - val_accuracy: 0.9463 - lr: 0.0010\n",
      "Epoch 48/50\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.2033 - accuracy: 0.9500 - val_loss: 0.2056 - val_accuracy: 0.9463 - lr: 0.0010\n",
      "Epoch 49/50\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.2033 - accuracy: 0.9500 - val_loss: 0.2055 - val_accuracy: 0.9464 - lr: 0.0010\n",
      "Epoch 50/50\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.2033 - accuracy: 0.9500 - val_loss: 0.2056 - val_accuracy: 0.9464 - lr: 0.0010\n",
      "3125/3125 [==============================] - 5s 2ms/step\n",
      "Keras  Accuracy: 0.94706\n",
      "1563/1563 [==============================] - 3s 2ms/step\n",
      "Total correct: 45923\n",
      "Total incorrect: 4077\n",
      "Total samples: 50000\n",
      "Keras Excited Accuracy: 0.91846\n",
      "1563/1563 [==============================] - 3s 2ms/step\n",
      "Total correct: 48783\n",
      "Total incorrect: 1217\n",
      "Total samples: 50000\n",
      "Keras Ground Accuracy: 0.97566\n",
      "\n",
      "===================================\n",
      "Fidelity 0.94706\n",
      "===================================\n"
     ]
    }
   ],
   "source": [
    "checkpoint_filename = 'single_layer_model_subwindow.h5'\n",
    "callbacks = [\n",
    "        ModelCheckpoint(\n",
    "        checkpoint_filename,\n",
    "        monitor=\"val_loss\",\n",
    "        verbose=0,\n",
    "        save_best_only=True,\n",
    "        save_weights_only=False,\n",
    "        save_freq=\"epoch\",\n",
    "    ),\n",
    "    ReduceLROnPlateau(patience=75, min_delta=1**-6),\n",
    "]\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(2, activation='relu', input_shape=(sr,)))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "sl_accuracy, sl_e_accuracy, sl_g_accuracy = scan_readout_window(model, window_start_locations, window_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy [0.95765, 0.96008, 0.95982, 0.95773, 0.95521, 0.95263, 0.94974, 0.94706]\n",
      "Fidelity [0.9153  0.92016 0.91964 0.91546 0.91042 0.90526 0.89948 0.89412]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAkgAAAGwCAYAAABSN5pGAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8WgzjOAAAACXBIWXMAAA9hAAAPYQGoP6dpAABf5klEQVR4nO3deVhUZcMG8HsGmBm2GUR2xAVQyQ0UAdEyLRKzzK1etxRwN7SFzFfLtLSy+sq0tMwVxbVyadeMFFMRkMUVXFFcAEVkl23m+f4w5w0EBQQPy/27rrlyzpw5cz9nJuf2zDNnZEIIASIiIiLSk0sdgIiIiKi+YUEiIiIiKocFiYiIiKgcFiQiIiKicliQiIiIiMphQSIiIiIqhwWJiIiIqBxDqQM0VDqdDteuXYO5uTlkMpnUcYiIiKgKhBDIzc2Fg4MD5PLKjxOxINXQtWvX4OTkJHUMIiIiqoHLly+jRYsWld7OglRD5ubmAO7sYLVaLXEaIiIiqoqcnBw4OTnp38crw4JUQ3c/VlOr1SxIREREDcyDpsdwkjYRERFROSxIREREROWwIBERERGVw4JEREREVA4LEhEREVE5LEhERERE5bAgEREREZXDgkRERERUDgsSERERUTksSERERETlsCARERERlcOCRERERFROvShIy5YtQ+vWraFSqeDj44Po6OhK1y0pKcH8+fPh4uIClUoFd3d37Nq1q8w6CxcuhJeXF8zNzWFjY4PBgwfj9OnTZdYpLCxEcHAwmjdvDjMzMwwbNgzp6el1Mj6qnuJSHbJvl0AIIXUUIiJqogylDrB161aEhIRg+fLl8PHxweLFi+Hv74/Tp0/DxsbmnvXnzJmDDRs2YOXKlXBzc8Pu3bsxZMgQHDp0CF27dgUAREREIDg4GF5eXigtLcXbb7+Nfv364dSpUzA1NQUAvPHGG/j111/x/fffQ6PRYNq0aRg6dCgOHjz4SMdPZR2+cBNTNsQiq6AExkYGsNOoYGOuhJ1GBTu1CjbqO/+10yhhY66CrVoFhWG96PlERNSIyITE/0z38fGBl5cXli5dCgDQ6XRwcnLC9OnTMWvWrHvWd3BwwDvvvIPg4GD9smHDhsHY2BgbNmyo8DFu3LgBGxsbREREoHfv3sjOzoa1tTU2bdqEF198EQCQlJSExx57DJGRkejRo8cDc+fk5ECj0SA7OxtqtbomQ6dyDpzNwIT1MSgs0VXrfs1NFf8UJ+U/hUr1r0KlhJ1aBUtTBWQyWR0lJyKihqKq79+SHkEqLi5GbGwsZs+erV8ml8vh5+eHyMjICu9TVFQElUpVZpmxsTEOHDhQ6eNkZ2cDACwtLQEAsbGxKCkpgZ+fn34dNzc3tGzZstKCVFRUhKKiIv31nJycKoyQqmpv0nVM3hCL4lId+ra3xuLhXZF1uxhp2YVIyynE9ZwipOXc/fOd/6ZnF6FYq8PN/GLczC9GYmrl21cYyGFd5kiU8p8jUWULlbHC4NENmoiI6i1JC1JGRga0Wi1sbW3LLLe1tUVSUlKF9/H398eiRYvQu3dvuLi4IDw8HNu3b4dWq61wfZ1Oh9dffx29evVCp06dAABpaWlQKBSwsLC453HT0tIq3M7ChQvx/vvvV3OEVBV/nExD8KY4lGgFnulgi6WjukJpaACNiRFaNTet9H5CCNwqKEG6vjAVIv2fIpX+r0tGXjGKtTpczbqNq1m375vFXGVYrjgpy320p4KVmRIGch6NIiJqzCSfg1RdS5YswcSJE+Hm5gaZTAYXFxcEBQVhzZo1Fa4fHByMEydO3PcIU1XMnj0bISEh+us5OTlwcnJ6qG0S8OuxVLy2JR6lOoHnOttj8QgPGBlUbU6RTCaDpakClqYKPGZf+WHS4lIdbuQVIS37f6Xp34Xq7vWCYi1yC0uRW5iHs9fzKt2eXIY7R6PKFafyc6XUKkN+rEdE1EBJWpCsrKxgYGBwz7fH0tPTYWdnV+F9rK2tsXPnThQWFuLmzZtwcHDArFmz4OzsfM+606ZNwy+//IL9+/ejRYsW+uV2dnYoLi5GVlZWmaNI93tcpVIJpVJZg1FSZX5MuIo3tiZAJ4DBHg747CV3GFaxHFWHwlAORwtjOFoYV7qOEAJ5RaV3ylL2/0rT/wpVEdKzC3EjrwhanfinWBUByK50mxVNMrf952KnUcJWfecoFSeZExHVP5IWJIVCAU9PT4SHh2Pw4MEA7nwkFh4ejmnTpt33viqVCo6OjigpKcG2bdvwn//8R3+bEALTp0/Hjh07sG/fPrRp06bMfT09PWFkZITw8HAMGzYMAHD69GmkpKTA19e3dgdJFfr+yGXM3HYMQgAverbAJ8O6SPqxlUwmg7nKCOYqI7jamFe6nlYncDPvn/lQ2YVIz71TnMqUqexC5BSW4naJFskZ+UjOyL/vYzc3VfxTnO4UKVu1Cm1tzNG/kx0/yiMikojkH7GFhIQgICAA3bt3h7e3NxYvXoz8/HwEBQUBAMaOHQtHR0csXLgQABAVFYWrV6/Cw8MDV69exXvvvQedToeZM2fqtxkcHIxNmzbhxx9/hLm5uX5ekUajgbGxMTQaDcaPH4+QkBBYWlpCrVZj+vTp8PX1rdI32OjhbIpKwds7jgMARvm0xAeDOkHeQIqAgVwGm38+QuvSovL1bhdr7z0KlV2E9NxCfaG6nlN2kvmpcpPMn3azwZKRXWGmlPx/UyKiJkfyv3mHDx+OGzduYO7cuUhLS4OHhwd27dqln7idkpICufx/H0EUFhZizpw5uHDhAszMzDBgwACEhYWV+ajsm2++AQD06dOnzGOtXbsWgYGBAIAvvvgCcrkcw4YNQ1FREfz9/fH111/X6VgJWHfoIub9dBIAENizNeYN7NAo5+kYKwzQ2soUra0ePMn8zpGo/xWn1KxC7Ei4ivCk63jxm0NYFdAdLZqZPML0REQk+XmQGiqeB6n6Vu6/gA9/SwQATOrtjNnPujXKclQb4lNuYeL6WGTkFcHKTIFvx3jCs5Wl1LGIiBq8qr5/c3YoPRLL9p7Tl6NpfV1Zjh6ga8tm+GlaLzxmr0ZGXjFGrojC9rgrUsciImoyWJCoTgkh8MWeM/i/3Xd+Cy/kmXaY4d+e5agKHCyM8cMUX/TrYItirQ4h3x3Fp7uSoNPxoC8RUV1jQaI6I4TAp7tPY0n4WQDAf/u74dWn20qcqmExVRpi+cueeKWPCwDg633n8crGOBQUl0qcjIiocWNBojohhMAHvybim33nAQBznnsMU/95k6fqkctlmNnfDZ+/5A6FgRy7TqbhpeWRSM2+/1nBiYio5liQqNbpdALzfjqJ1QeSAQALBnXEhCfuPZEnVc8wzxbYNNEHzU0VOHktBy8sPYiEy1lSxyIiapRYkKhW6XQCb+84jvWRlyCTAR8P7Ywxvq2ljtVodG9tiZ3BvdDe1hw3cosw/NtI/Hz0mtSxiIgaHRYkqjVancBbPxzDlpjLkMuAz150xwjvllLHanScLE3ww1RfPOVmg6JSHaZvjsfiP8+AZ+wgIqo9LEhUK0q1OoR8l4BtcVdgIJdh8YiuGOZ5n1NN00MxVxlh5djumPD4nZ/RWfznWUzfHI/CEq3EyYiIGgcWJHpoJVodXt0Sjx8TrsFQLsPSkV3xgruD1LEaPQO5DHOe74CPh3aGoVyGX46lYvi3kbieUyh1NCKiBo8FiR5KUakWUzfE4bfjaVAYyLH8ZU8829le6lhNygjvlggb7wMLEyMcvZKNF5YexImr2VLHIiJq0FiQqMYKS7SYHBaLPxPToTSUY8VYT/h1sJU6VpPk69IcO1/pBRdrU6TlFOKl5ZHYdSJN6lhERA0WCxLVyO1iLSasO4J9p29AZSTHmkAv9GlvI3WsJq21lSm2v9ILT7S1wu0SLaZsiMWyvec4eZuIqAZYkKja8otKEbg2GgfOZcBUYYB1Qd7o5WoldSwCoDE2wtpALwT4tgIA/N/u03jzu6MoKuXkbSKi6mBBomrJKSzB2DXRiErOhLnSEOvH+8DHubnUsehfDA3keH9QJywY1BEGchm2x1/FqJVRyMgrkjoaEVGDwYJEVZZdUIIxq6IQe+kW1CpDbJjgA89WzaSORZUY49saoUFeMFcZIvbSLQxaehBJaTlSxyIiahBYkKhKMvOLMWrVYRy9ko1mJkbYNLEH3J0spI5FD/BEW2vseKUXWjc3wdWs2xj29SGEJ6ZLHYuIqN5jQaIHysgrwqiVh3HyWg6szBTYPKkHOjlqpI5FVeRqY4adwb3g69wc+cVaTFh/BCv3X+DkbSKi+2BBovu6nlOIESsOIyktFzbmSmyZ1ANudmqpY1E1WZgosH68N0Z6O0EI4MPfEjFr23EUl+qkjkZEVC+xIFGlUrNvY/iKwzh3PQ/2GhW2TvaFq4251LGohowM5PhoSGe8+3wHyGXA1iOX8fLqKGTmF0sdjYio3mFBogpdzizAf76NRHJGPhwtjPHdZF+0sTKVOhY9JJlMhvGPt8HqAC+YKQ0RnZyJwcsO4mx6rtTRiIjqFRYkuselm/kYseIwLmfeRqvmJvhuii+cLE2kjkW1qK+bDba/0hNOlsZIySzA0K8PIeLMDaljERHVGyxIVMb5G3n4z7eRuJp1G87Wptg6yReOFsZSx6I60M7WHDtf6QWv1s2QW1SKoLXRCD2YzMnbRERgQaJ/OZOei+HfHkZ6ThHa2phhy6QesNOopI5Fdai5mRIbJvhgWLcW0AngvZ9P4d0fT6BEy8nbRNS0sSARAODUtRyMWHEYGXlFeMxejS2TesDGnOWoKVAaGuCzl7pg1rNukMmADYdTELg2GtkFJVJHIyKSDAsS4fiVbIxceRiZ+cXo7KjB5ok+aG6mlDoWPUIymQxTnnTBty97wkRhgIPnbmLI1weRnJEvdTQiIkmwIDVxcSm3MGrVYWTfLkHXlhbYMMEHFiYKqWORRPp1tMMPU3rCQaPChYx8DF52EIfOZUgdi4jokWNBasJiLmZi7Opo5BaWwqt1M4SN94HG2EjqWCSxDg5q7JzWC11bWiD79p0fJ94YdUnqWEREjxQLUhMVef4mAtZEI6+oFL7OzbFunDfMlIZSx6J6wsZchc0Te2CQhwNKdQLv7DiB938+iVJO3iaiJoIFqQn6++wNBIVGo6BYiyfaWmFNoBdMFCxHVJbKyACLh3tgRr92AIC1By9iwvojyCnk5G0iavxYkJqYvUnXMX7dERSW6PCUmw1Wju0OY4WB1LGonpLJZJj2VFt8PbobVEZy7Dt9A8O+PoSUmwVSRyMiqlMsSE3I7pNpmBR2BMWlOvh3tMXylz2hMmI5ogcb0Nke30/uCVu1Emev52HQsgOITs6UOhYRUZ1hQWoifj2WiuCNcSjRCjzfxR5LR3WDwpBPP1Vd5xYa/Bj8ODo7anCroASjVx3G90cuSx2LiKhO8B2yCdgZfxXTN8ehVCcwtKsjFg/3gJEBn3qqPjuNCt9N9sWAznYo0Qq89cMxLPwtEVodf56EiBoXvks2ct8duYw3vkuATgD/6d4C//eSOwxZjughGCsMsHRkN7z6lCsA4Nv9FzA5LBZ5RaUSJyMiqj18p2zENkZdwswfjkEI4OUeLfHx0C4wkMukjkWNgFwuQ0i/9lgywgMKQzn+TEzHi98cwpVbnLxNRI0DC1IjFXowGe/sOAEACOrVGgsGdYKc5Yhq2SAPR2yd1ANWZkokpeVi8LKDiL10S+pYREQPjQWpEVqx/zze+/kUAGDyk86Y+3wHyGQsR1Q3urZshh+n9cJj9mpk5BVj5MrD2Bl/VepYREQPhQWpkVn611l89FsSAGD6U66Y1d+N5YjqnKOFMX6Y4otnOtiiuFSH17cm4LPdp6Hj5G0iaqBYkBoJIQQW7TmDz/44AwAIeaYd3uzXnuWIHhlTpSG+fdkTU550AQAs3XsOwZviUFDMydtE1PCwIDUCQgh8sus0vgw/CwCY9awbXn26rcSpqCmSy2WY9awbPnvJHUYGMvx+Ig3/+TYSadmFUkcjIqoWFqQGTgiBBb8kYnnEeQDAu8930P8LnkgqL3q2wKaJPWBpqsCJqzl4YekBHLuSJXUsIqIqY0FqwHQ6gbk/nsSag8kAgAWDO2H8420kTkV0h1drS/wY3AvtbM1wPbcILy2PxK/HUqWORURUJSxIDZROJ/D2juMIO3wJMhnwybDOGNOjldSxiMpwsjTBtqk90be9NYpKdQjeFIcvw89CCE7eJqL6jQWpAdLqBGb8cBRbYi5DLgM+f8kdw71aSh2LqELmKiOsCvDSH91ctOcMXt2SgMISrcTJiIgqx4LUwJRo73yFenvcVRjIZVgyoiuGdmshdSyi+zKQy/Du8x2wcGhnGMpl+PnoNQxfcRjXczh5m4jqJxakBqS4VIfpm+Lx89FrMDKQYdmorhjo7iB1LKIqG+ndEuvHe0NjbISjl7MwaNlBnLyWLXUsIqJ7sCA1EEWlWryyMRa7TqZBYSDH8pc90b+TvdSxiKqtp4sVdgb3grO1KVKzC/HiN5HYfTJN6lhERGWwIDUAhSVaTFofiz8Tr0NpKMfKgO54+jFbqWMR1VgbK1PseKUXnmhrhdslWkzZEItv9p3n5G0iqjdYkOq5guJSjF8Xg4gzN2BsZIC1gV54sp211LGIHprG2AhrA70w1rcVhAA+2ZWEN78/iqJSTt4mIumxINVjeUWlCFwbg4PnbsJUYYB147zR09VK6lhEtcbQQI75gzph/qCOMJDLsD3uKkavjMLNvCKpoxFRE8eCVE/lFJZg7OooRCdnwlxpiPXjfeDdxlLqWER1Yqxva6wN9IK5yhBHLt3CoGUHcSY9V+pYRNSEsSDVQ9kFJRizKgpxKVnQGBth40QfeLZqJnUsojrVu501drzSC62am+DKrdsYseIwktJypI5FRE0UC1I9k5lfjJErD+PolWxYmiqwaaIPurSwkDoW0SPhamOGna/0QpcWGmTmF2P0yigeSSIiSbAg1SNCCEwJi8Wp1BxYmSmxeWIPdHTQSB2L6JFqZqpA2DgfdHJU42Z+MUatPIyzLElE9IhJXpCWLVuG1q1bQ6VSwcfHB9HR0ZWuW1JSgvnz58PFxQUqlQru7u7YtWtXmXX279+PgQMHwsHBATKZDDt37rxnO4GBgZDJZGUu/fv3r+2hVZtMJsOsAW5wtjbFlkk90N7OXOpIRJLQmBhhw3gfdHRQIyOvGCNXRuHc9TypYxFREyJpQdq6dStCQkIwb948xMXFwd3dHf7+/rh+/XqF68+ZMwfffvstvvrqK5w6dQpTpkzBkCFDEB8fr18nPz8f7u7uWLZs2X0fu3///khNTdVfNm/eXKtjq6luLZthzxtPwtXGTOooRJKyMFFg4wQfdLBXIyOvCCNXHsb5GyxJRPRoyISEZ2bz8fGBl5cXli5dCgDQ6XRwcnLC9OnTMWvWrHvWd3BwwDvvvIPg4GD9smHDhsHY2BgbNmy4Z32ZTIYdO3Zg8ODBZZYHBgYiKyurwqNLVZWTkwONRoPs7Gyo1eoab4eI7u/WP/PyktJyYWOuxJZJPeBszX9AEFHNVPX9W7IjSMXFxYiNjYWfn9//wsjl8PPzQ2RkZIX3KSoqgkqlKrPM2NgYBw4cqPbj79u3DzY2Nmjfvj2mTp2Kmzdv3nf9oqIi5OTklLkQUd1rZqrApok94GZnjuu5d44kJWfkSx2LiBo5yQpSRkYGtFotbG3L/mSGra0t0tIq/l0mf39/LFq0CGfPnoVOp8OePXuwfft2pKamVuux+/fvj/Xr1yM8PByffPIJIiIi8Oyzz0KrrfwMvgsXLoRGo9FfnJycqvWYRFRzlqZ3Pm5rZ2uG9JwijFxxGBdZkoioDkk+Sbs6lixZgrZt28LNzQ0KhQLTpk1DUFAQ5PLqDWPEiBF44YUX0LlzZwwePBi//PILYmJisG/fvkrvM3v2bGRnZ+svly9ffsjREFF1NDdTYtPEHmhrY4a0nEKMXHkYKTcLpI5FRI2UZAXJysoKBgYGSE9PL7M8PT0ddnZ2Fd7H2toaO3fuRH5+Pi5duoSkpCSYmZnB2dn5obI4OzvDysoK586dq3QdpVIJtVpd5kJEj5bVPyXJ1cYMqdl3StLlTJYkIqp9khUkhUIBT09PhIeH65fpdDqEh4fD19f3vvdVqVRwdHREaWkptm3bhkGDBj1UlitXruDmzZuwt7d/qO0QUd2zNldi00QfOFub4mrWnTNusyQRUW2T9CO2kJAQrFy5EuvWrUNiYiKmTp2K/Px8BAUFAQDGjh2L2bNn69ePiorC9u3bceHCBfz999/o378/dDodZs6cqV8nLy8PCQkJSEhIAAAkJycjISEBKSkp+tvfeustHD58GBcvXkR4eDgGDRoEV1dX+Pv7P7rBE1GN2ZirsGViDzhb3SlJI1cexpVbLElEVHsMpXzw4cOH48aNG5g7dy7S0tLg4eGBXbt26Sdup6SklJlfVFhYiDlz5uDChQswMzPDgAEDEBYWBgsLC/06R44cQd++ffXXQ0JCAAABAQEIDQ2FgYEBjh07hnXr1iErKwsODg7o168fFixYAKVS+WgGTkQPzUatwqaJPTBiRSQu3izAyJWHsXWSLxwsjKWORkSNgKTnQWrIeB4kovohNfvOx2yXbhagpaUJtk7uAXsNSxIRVazenweJiKg22GuMsXliD7S0NEFKZgFGrjiMtOxCqWMRUQPHgkREDZ6DhTE2T+oBJ0tj/cdt6TksSURUcyxIRNQoOFrcOZLUopkxkjPyMXLlYVxnSSKiGmJBIqJGo0UzE2ye2AOOFsa4cOOfkpTLkkRE1ceCRESNipPlnZLkoFHh/I18jFoZhRu5RVLHIqIGhgWJiBqdls1NsHlSD9hrVDh3PQ+jVx1GRh5LEhFVHQsSETVKrZqbYvPEHrBVK3EmPQ+jV0bhJksSEVURCxIRNVqtrUyxZZIvbMyVOJ2ei9GropCZXyx1LCJqAFiQiKhRa2Nlis2TesDaXImktDsl6RZLEhE9AAsSETV6LtZm2DyxB6zMlEhMzcHoVVHIKmBJIqLKsSARUZPgamOGLZN8YGWmwKnUHLy8OgrZBSVSxyKieooFiYiaDFcbc2ya2APNTRU4cfWfknSbJYmI7sWCRERNSjvbOyXJ0lSB41ezMXZ1FHIKWZKIqCwWJCJqctrbmWPTRB80MzHC0SvZGLs6miWJiMpgQSKiJsnNTo2NE3rAwsQICZezELAmGrksSUT0DxYkImqyOjiosXGCDzTGRohPyULg2hjkFZVKHYuI6gEWJCJq0jo6aLBxgg/UKkPEXrqFoLXRyGdJImryWJCIqMnr5KjBxgk9YK4yRMzFWwhaG8OSRNTEsSAREQHo3EKDDeN9YK40RPTFTIwLjUFBMUsSUVPFgkRE9A93JwusH+8Nc6UhopIzMT70CG4Xa6WORUQSYEEiIvqXri2bYd14b5gpDRF54SbGr4thSSJqgliQiIjK6dayGdaN84KpwgCHzt/ExPVHUFjCkkTUlLAgERFVwLOVJULHecNEYYAD5zJYkoiaGBYkIqJKeLW2RGjQnZL099kMTA6LZUkiaiJYkIiI7sO7jSXWBHrB2MgAEWduYOqGWBSVsiQRNXYsSERED9DDuTnWBHpBZSTH3tM3MHVDHEsSUSPHgkREVAW+Ls2xJsALSkM5/kq6juCNcSgu1Ukdi4jqCAsSEVEV9XS1wup/StKfidcRvIkliaixYkEiIqqGx9taYeXY7lAYyrHnVDqmb45DiZYliaixYUEiIqqm3u2ssWKMJxQGcuw+mY5XN8ezJBE1MixIREQ10Ke9Db79pyT9fiINr29JQClLElGjwYJERFRDfd1ssHxMNxgZyPDr8VS88d1RliSiRoIFiYjoITzlZotvRnvCyECGn49eQwhLElGjwIJERPSQ/DrYYtmobjCUy/DT0WuY8f1RaHVC6lhE9BBYkIiIakG/jnZY+k9J2plwDW+xJBE1aCxIRES1pH8nO3w1sisM5DJsj7+K/247Bh1LElGDxIJERFSLnu1sjy9H3ClJP8RewaztLElEDRELEhFRLXuuiz0WD/eAXAZ8d+QK3t5xnCWJqIFhQSIiqgMD3R3wxT8laUvMZbyz8wRLElEDwoJERFRHBnk4YtF/7pSkzdEpePfHExCCJYmoIWBBIiKqQ4O7OuKzl9whkwEbo1Iw98eTLElEDQALEhFRHRvarQX+78U7JSns8CW8//MpliSieo4FiYjoEXjRswU+GdYFMhkQeugi5v/CkkRUn7EgERE9Iv/p7oSPh3YGAKw9eBEf/JrIkkRUT7EgERE9QsO9WmLhPyVp9YFkfPQbSxJRfcSCRET0iI30bokPh3QCAKz8Oxkf70piSSKqZ1iQiIgkMNqnFRYM6ggA+DbiAj7dfZoliageYUEiIpLIGN/WeP+FOyXpm33n8fkfZ1iSiOoJFiQiIgkF9GyNeQM7AACW7j2HL/48K3EiIgJYkIiIJBfUqw3eff5OSfoy/CwW/3lG4kRExIJERFQPjH+8DeY89xgAYPGfZ/FlOI8kEUmJBYmIqJ6Y8IQzZj/rBgBYtOcMvtl3XuJERE0XCxIRUT0y+UkXzOzfHgDwya4krDmQLHEioqZJ8oK0bNkytG7dGiqVCj4+PoiOjq503ZKSEsyfPx8uLi5QqVRwd3fHrl27yqyzf/9+DBw4EA4ODpDJZNi5c+c92xFCYO7cubC3t4exsTH8/Pxw9iwPZxNR/fBKH1e89nRbAMD8X05hY9QliRMRNT2SFqStW7ciJCQE8+bNQ1xcHNzd3eHv74/r169XuP6cOXPw7bff4quvvsKpU6cwZcoUDBkyBPHx8fp18vPz4e7ujmXLllX6uJ9++im+/PJLLF++HFFRUTA1NYW/vz8KCwtrfYxERDXxul9bTH7SGQDwzo4T+CH2isSJiJoWmZDwpBs+Pj7w8vLC0qVLAQA6nQ5OTk6YPn06Zs2adc/6Dg4OeOeddxAcHKxfNmzYMBgbG2PDhg33rC+TybBjxw4MHjxYv0wIAQcHB7z55puYMWMGACA7Oxu2trYIDQ3FiBEjqpQ9JycHGo0G2dnZUKvV1Rk2EVGVCCHw/s+nEHroIuQy4IvhHhjk4Sh1LKIGrarv35IdQSouLkZsbCz8/Pz+F0Yuh5+fHyIjIyu8T1FREVQqVZllxsbGOHDgQJUfNzk5GWlpaWUeV6PRwMfHp9LHvfvYOTk5ZS5ERHVJJpNh3sAOGOXTEjoBhHx3FLtOpEodi6hJkKwgZWRkQKvVwtbWtsxyW1tbpKWlVXgff39/LFq0CGfPnoVOp8OePXuwfft2pKZW/S+Mu9uuzuMCwMKFC6HRaPQXJyenKj8mEVFNyWQyfDCoE4Z1awGtTmD65nj8lZQudSyiRk/ySdrVsWTJErRt2xZubm5QKBSYNm0agoKCIJfX/TBmz56N7Oxs/eXy5ct1/phERAAgl8vw6YtdMNDdASVagSkb4vD32RtSxyJq1CQrSFZWVjAwMEB6etl/CaWnp8POzq7C+1hbW2Pnzp3Iz8/HpUuXkJSUBDMzMzg7O1f5ce9uuzqPCwBKpRJqtbrMhYjoUTGQy7DoP+7w72iL4lIdJq4/gsMXbkodi6jRkqwgKRQKeHp6Ijw8XL9Mp9MhPDwcvr6+972vSqWCo6MjSktLsW3bNgwaNKjKj9umTRvY2dmVedycnBxERUU98HGJiKRkZCDHVyO7oW97axSW6DAuNAaxl25JHYuoUZL0I7aQkBCsXLkS69atQ2JiIqZOnYr8/HwEBQUBAMaOHYvZs2fr14+KisL27dtx4cIF/P333+jfvz90Oh1mzpypXycvLw8JCQlISEgAcGdSdkJCAlJSUgDc+Tz/9ddfxwcffICffvoJx48fx9ixY+Hg4FDm225ERPWRwlCOb172xOOuVigo1iJwTTSOXcmSOhZRo2Mo5YMPHz4cN27cwNy5c5GWlgYPDw/s2rVLP4E6JSWlzPyiwsJCzJkzBxcuXICZmRkGDBiAsLAwWFhY6Nc5cuQI+vbtq78eEhICAAgICEBoaCgAYObMmcjPz8ekSZOQlZWFxx9/HLt27brnG3JERPWRysgAK8Z6InBtDKKTMzFmdTQ2T+yBDg786J+otkh6HqSGjOdBIiKp5RWVYszqKMSnZKG5qQJbJvVAW1tzqWMR1Wv1/jxIRET0cMyUhggN8kYnRzVu5hdj9KooJGfkSx2LqFFgQSIiasA0xkYIG+cDNztzXM8twqiVh3E5s0DqWEQNHgsSEVED18xUgQ0TfOBibYrU7EKMWnUYqdm3pY5F1KCxIBERNQJWZkpsmtgDrZqb4HLmbYxaGYXrOfwBbqKaYkEiImokbNUqbJrYA44WxkjOyMfoVVG4mVckdSyiBokFiYioEXG0MMbmiT1gp1bh7PU8vLw6GlkFxVLHImpwWJCIiBqZls1NsHGiD6zMlEhMzUHAmmjkFJZIHYuoQWFBIiJqhFyszbBpog8sTRU4eiUbQWtjkF9UKnUsogaDBYmIqJFqZ2uOsPHeUKsMEXvpFsavi8HtYq3UsYgahBoVpAsXLtR2DiIiqgMdHTRYP94HZkpDHL6QiUlhR1BYwpJE9CA1Kkiurq7o27cvNmzYgMJCfo2UiKg+83CyQGiQF0wUBvj7bAambYpDcalO6lhE9VqNClJcXBy6dOmCkJAQ2NnZYfLkyYiOjq7tbEREVEu6t7bEqoDuUBrK8Wfidby2JR6lWpYkosrUqCB5eHhgyZIluHbtGtasWYPU1FQ8/vjj6NSpExYtWoQbN27Udk4iInpIPV2s8O0YTygM5Pj9RBre/P4otDr+XjlRRR5qkrahoSGGDh2K77//Hp988gnOnTuHGTNmwMnJCWPHjkVqampt5SQiolrQp70Nlo3uBkO5DD8mXMPs7cegY0kiusdDFaQjR47glVdegb29PRYtWoQZM2bg/Pnz2LNnD65du4ZBgwbVVk4iIqolz3SwxZIRXSGXAd8duYK5P52AECxJRP9mWJM7LVq0CGvXrsXp06cxYMAArF+/HgMGDIBcfqdvtWnTBqGhoWjdunVtZiUiolryXBd7FGvdEfLdUWw4nAKloQHmPPcYZDKZ1NGI6oUaFaRvvvkG48aNQ2BgIOzt7Stcx8bGBqtXr36ocEREVHeGdG2B4lId/rvtOFYfSIbSUI63/NuzJBEBkIkaHFe9ePEiWrZsqT9idJcQApcvX0bLli1rLWB9lZOTA41Gg+zsbKjVaqnjEBHVWFjkRbz740kAQMgz7fDq020lTkRUd6r6/l2jOUguLi7IyMi4Z3lmZibatGlTk00SEZFExvi2xpznHgMALNpzBt9GnJc4EZH0alSQKjvolJeXB5VK9VCBiIjo0ZvwhDPe8m8PAFj4exJCDyZLnIhIWtWagxQSEgIAkMlkmDt3LkxMTPS3abVaREVFwcPDo1YDEhHRoxHc1xVFJVp8+dc5vPfzKSgMDTDKp/FPmSCqSLUKUnx8PIA7R5COHz8OhUKhv02hUMDd3R0zZsyo3YRERPTIvPFMOxSW6rBi/wW8s/M4lIZyDPNsIXUsokeuWgVp7969AICgoCAsWbKEk5OJiBoZmUyG2c+6oahEi3WRl/DWD0ehMJRjoLuD1NGIHqkafc1/7dq1tZ2DiIjqCZlMhnkDO6JYq8Pm6Mt4fWsCjAzk6N/JTupoRI9MlQvS0KFDERoaCrVajaFDh9533e3btz90MCIiko5cLsOHgzujqESH7fFXMX1zHFaM6Y6+bjZSRyN6JKpckDQajf7kYRqNps4CERFR/SCXy/Dpi11QpNXh12OpmLwhFmsDvdDL1UrqaER1rkYniiSeKJKImo4SrQ6vbIzDnlPpUBnJsS7IGz7OzaWORVQjdXqiSCIiajqMDORYOqornmxnjcISHcaFxiAu5ZbUsYjqVJWPIHXt2rXKv88TFxf3UKEaAh5BIqKmprBEi3GhMTh0/ibMVYbYPLEHOjlyygU1LFV9/67yHKTBgwfXRi4iImqgVEYGWBXQHQFrohFz8RZeXh2FLZN6wM2O/0ikxodzkGqIR5CIqKnKLSzBmNXRSLicheamCmyd7AtXGzOpYxFVSZ3PQcrKysKqVaswe/ZsZGZmArjz0drVq1drukkiImoAzFVGWBfkjY4OatzML8aolYdxMSNf6lhEtapGBenYsWNo164dPvnkE3z22WfIysoCcOf8R7Nnz67NfEREVA9pTIwQNt4H7W3NcT23CKNXReHKrQKpYxHVmhoVpJCQEAQGBuLs2bNQqVT65QMGDMD+/ftrLRwREdVflqYKbJjgA2drU1zNuo1RK6OQll0odSyiWlGjghQTE4PJkyffs9zR0RFpaWkPHYqIiBoGa3MlNk3ogZaWJkjJLMColYdxPZcliRq+GhUkpVKJnJyce5afOXMG1tbWDx2KiIgaDjuNCpsm+sDRwhgXMvLx8qooZOYXSx2L6KHUqCC98MILmD9/PkpKSgDc+WHDlJQU/Pe//8WwYcNqNSAREdV/LZqZYNNEH9iqlTiTnoeXV0Uhu6BE6lhENVajgvT5558jLy8PNjY2uH37Np588km4urrC3NwcH374YW1nJCKiBqBVc1NsnNADVmYKnErNwdi10cgtZEmihumhzoN04MABHDt2DHl5eejWrRv8/PxqM1u9xvMgERFV7HRaLkasiMStghJ0b9UM68Z5w1RZ5fMSE9Wpqr5/80SRNcSCRERUuRNXszFy5WHkFpbC17k51gZ5QWVkIHUsotovSF9++WWVH/zVV1+t8roNFQsSEdH9xafcwsuropBfrEXvdtZYOdYTSkOWJJJWrRekNm3alLl+48YNFBQUwMLCAsCdM2ubmJjAxsYGFy5cqHnyBoIFiYjowaKTMxGwJhq3S7Twe8wW37zcDUYGNf4RB6KHVus/NZKcnKy/fPjhh/Dw8EBiYiIyMzORmZmJxMREdOvWDQsWLKiVARARUcPn3cYSqwK6Q2Eox5+J6Xh9SwJKtTqpYxE9UI3mILm4uOCHH35A165dyyyPjY3Fiy++iOTk5FoLWF/xCBIRUdXtPX0dk9YfQYlWYEhXR3z2kjsM5DKpY1ETVKc/VpuamorS0tJ7lmu1WqSnp9dkk0RE1Ij1bW+DZaO6wVAuw474q3hnx3HodPyOENVfNSpITz/9NCZPnoy4uDj9stjYWEydOrVJfdWfiIiqrl9HOywe4QG5DNgScxnv/XwS/CI11Vc1Kkhr1qyBnZ0dunfvDqVSCaVSCW9vb9ja2mLVqlW1nZGIiBqJ57s44LOX3CGTAesjL+Gj3xJZkqheqtGZu6ytrfHbb7/hzJkzSEpKAgC4ubmhXbt2tRqOiIgan6HdWqCoVIfZ249j5d/JUBkZ4M1+7aWORVTGQ53atF27dixFRERUbSO9W6K4VId5P53EV3+dg8JAjulPt5U6FpFelQtSSEgIFixYAFNTU4SEhNx33UWLFj10MCIiatwCerZGUakWH/2WhM/3nIHKyAATeztLHYsIQDUKUnx8PJKSktC1a1fEx8dXup5Mxq9tEhFR1Uzq7YKiEh0+33MGH/6WCKWRHGN9W0sdi6jqBWnv3r0wMDBAamoq9u7dCwAYPnw4vvzyS9ja2tZZQCIiatymP90WhaVaLNt7HnN/PAmFgRwjvFtKHYuauGp9i638Nw1+//135Ofn12ogIiJqemb0a48Jj9/5SavZO45jR/wViRNRU/dQP4jDr2YSEVFtkMlkeOe5xzCmRysIAbz53VHsOpEqdSxqwqpVkGQy2T1zjGpjztGyZcvQunVrqFQq+Pj4IDo6utJ1S0pKMH/+fLi4uEClUsHd3R27du2q9jb79OmjH8/dy5QpUx56LEREVDMymQzvv9ARw7s7QSeA17YkIC7lltSxqImq1tf8hRAIDAyEUqkEABQWFmLKlCkwNTUts9727durvM2tW7ciJCQEy5cvh4+PDxYvXgx/f3+cPn0aNjY296w/Z84cbNiwAStXroSbmxt2796NIUOG4NChQ/rfhqvqNidOnIj58+frr5uYmFRndxARUS2Ty2X4cEgnZOQVITzpOiauO4Idr/RCy+b8+5kerWr9WG1QUFCV1lu7dm2VA/j4+MDLywtLly4FAOh0Ojg5OWH69OmYNWvWPes7ODjgnXfeQXBwsH7ZsGHDYGxsjA0bNlR5m3369IGHhwcWL15c5az/xh+rJSKqO/lFpfjPt5E4eS0Hztam2D61JyxMFFLHokagqu/f1TqCVJ3iUxXFxcWIjY3F7Nmz9cvkcjn8/PwQGRlZ4X2KioqgUqnKLDM2NsaBAweqvc2NGzdiw4YNsLOzw8CBA/Huu+9WehSpqKgIRUVF+us5OTnVGywREVWZqdIQawK9MGTZQVy4kY/JYbFYP94bSkMDqaNRE/FQk7QfVkZGBrRa7T2nCbC1tUVaWlqF9/H398eiRYtw9uxZ6HQ67NmzB9u3b0dqamq1tjlq1Chs2LABe/fuxezZsxEWFoaXX3650qwLFy6ERqPRX5ycnGo6bCIiqgJbtQprgrxgpjREVHImZm87zi8H0SMjaUGqiSVLlqBt27Zwc3ODQqHAtGnTEBQUBLm8ekOZNGkS/P390blzZ4wePRrr16/Hjh07cP78+QrXnz17NrKzs/WXy5cv18ZwiIjoPtzs1Ph6dDcYyGXYHn8Vi/88K3UkaiIkLUhWVlYwMDBAenp6meXp6emws7Or8D7W1tbYuXMn8vPzcenSJSQlJcHMzAzOzs413iZwZ94SAJw7d67C25VKJdRqdZkLERHVvd7trPHB4E4AgCXhZ7EtludIoronaUFSKBTw9PREeHi4fplOp0N4eDh8fX3ve1+VSgVHR0eUlpZi27ZtGDRo0ENtMyEhAQBgb2//ECMiIqK6MNK7JaY86QIAmLX9GCLP35Q4ETV2kn/EFhISgpUrV2LdunVITEzE1KlTkZ+fr//G3NixY8tMuI6KisL27dtx4cIF/P333+jfvz90Oh1mzpxZ5W2eP38eCxYsQGxsLC5evIiffvoJY8eORe/evdGlS5dHuwOIiKhKZvq3x3Nd7FGiFZgcdgTnrudKHYkasWp9i60uDB8+HDdu3MDcuXORlpYGDw8P7Nq1Sz/JOiUlpcz8osLCQsyZMwcXLlyAmZkZBgwYgLCwMFhYWFR5mwqFAn/++ScWL16M/Px8ODk5YdiwYZgzZ84jHTsREVWdXC7D5y+5IzXrNuJSshAUGoMdr/SClZlS6mjUCFXrPEj0PzwPEhGRNG7mFWHI14eQklkADycLbJnUAyojfv2fqqaq79+Sf8RGRERUHc3NlAgN8oKFiRESLmfhja0J0On4b32qXSxIRETU4Dhbm2HFmO5QGMjx+4k0fLwrSepI1MiwIBERUYPk3cYS//fSnS/WrNh/AWGHL0mciBoTFiQiImqwBnk44s1n2gEA5v14AnuTrkuciBoLFiQiImrQpj3lihc9W0AngGmb4nDyWrbUkagRYEEiIqIGTSaT4aMhndHTpTnyi7UYFxqD1OzbUseiBo4FiYiIGjyFoRzfvOyJtjZmSM8pwrjQI8grKpU6FjVgLEhERNQoaIyNsCbQC1ZmSiSm5iB4YxxKtTqpY1EDxYJERESNhpOlCVYHdIfKSI6IMzcw76eT4PmQqSZYkIiIqFFxd7LAkhFdIZMBG6NSsPLvC1JHogaIBYmIiBod/452mPNcBwDAR78l4ffjqRInooaGBYmIiBqlcb1aI8C3FQDg9a0JiEu5JXEiakhYkIiIqFGSyWSYO7AjnnazQVGpDhPXHUHKzQKpY1EDwYJERESNloFchi9HdkVHBzVu5hcjMDQaWQXFUseiBoAFiYiIGjVTpSHWBHrBQaPChRv5mBwWi6JSrdSxqJ5jQSIiokbPVq3CmiAvmCkNEZWcidnbjvPr/3RfLEhERNQkuNmp8fXobjCQy7A9/ioW/3lW6khUj7EgERFRk9G7nTU+GNwJALAk/Cy2xV6ROBHVVyxIRETUpIz0bompfVwAALO2H0Pk+ZsSJ6L6iAWJiIianLf6tcfzXexRohWYHHYE567nSh2J6hkWJCIianLkchk+e8kdnq2aIaewFIFrY3Ajt0jqWFSPsCAREVGTpDIywMqx3dGquQmu3LqNCeuP4HYxv/5Pd7AgERFRk2VpqsDaQC9YmBjh6OUsvLE1ATodv/5PLEhERNTEOVubYcWY7lAYyLHrZBoW/p4odSSqB1iQiIioyfNuY4n/e6kLAGDl38kIO3xJ4kQkNRYkIiIiAIM8HPHmM+0AAPN+PIG9SdclTkRSYkEiIiL6x7SnXPGiZwvoBDBtUxxOXsuWOhJJhAWJiIjoHzKZDB8N6Yxers2RX6zFuNAYpGbfljoWSYAFiYiI6F8UhnJ8PdoTbW3MkJ5ThHGhR5BXVCp1LHrEWJCIiIjK0RgbYW2QF6zMlEhMzUHwxjiUanVSx6JHiAWJiIioAi2amWB1QHeojOSIOHMD8346CSF4jqSmggWJiIioEu5OFvhyRFfIZMDGqBSs2H9B6kj0iLAgERER3Ue/jnaY81wHAMDC35Pw2/FUiRPRo8CCRERE9ADjerVGgG8rAMAbWxMQl3JL4kRU11iQiIiIHkAmk2HuwI542s0GRaU6TFx3BCk3C6SORXWIBYmIiKgKDOQyfDmyKzo6qHEzvxiBodHIKiiWOhbVERYkIiKiKjJVGmJNoBccNCpcuJGPyWGxKCrVSh2L6gALEhERUTXYqlVYE+QFM6UhopIzMXvbcX79vxFiQSIiIqomNzs1vh7dDQZyGbbHX8XiP89KHYlqGQsSERFRDfRuZ40PB3cCACwJP4ttsVckTkS1iQWJiIiohkZ4t8TUPi4AgFnbj+HQ+QyJE1FtYUEiIiJ6CG/1a4/nu9ijRCswOSwW567nSh2JagELEhER0UOQy2X47CV3eLZqhtzCUgSujcGN3CKpY9FDYkEiIiJ6SCojA6wc2x2tmpvgyq3bmLD+CG4X8+v/DRkLEhERUS2wNFVgbaAXLEyMcPRyFt7YmgCdjl//b6hYkIiIiGqJs7UZVozpDoWBHLtOpmHh74lSR6IaYkEiIiKqRd5tLPF/L3UBAKz8Oxlhhy9JnIhqggWJiIiolg3ycMSMfu0AAPN+PIG9SdclTkTVxYJERERUB4L7uuI/3VtAJ4Bpm+Jw8lq21JGoGliQiIiI6oBMJsOHQzqjl2tz5BdrMS40BqnZt6WORVXEgkRERFRHjAzk+Hq0J9ramCE9pwhBa2OQW1gidSyqAhYkIiKiOqQxNsLaIC9YmSmRlJaLaZviUarVSR2LHoAFiYiIqI61aGaC1QHdoTKSI+LMDcz96SSE4DmS6rN6UZCWLVuG1q1bQ6VSwcfHB9HR0ZWuW1JSgvnz58PFxQUqlQru7u7YtWtXtbdZWFiI4OBgNG/eHGZmZhg2bBjS09NrfWxEREQA4O5kgS9HdIVMBmyKSsGK/RekjkT3IXlB2rp1K0JCQjBv3jzExcXB3d0d/v7+uH694q9EzpkzB99++y2++uornDp1ClOmTMGQIUMQHx9frW2+8cYb+Pnnn/H9998jIiIC165dw9ChQ+t8vERE1HT162iHOc91AAAs/D0Jvx1PlTgRVUYmJD7G5+PjAy8vLyxduhQAoNPp4OTkhOnTp2PWrFn3rO/g4IB33nkHwcHB+mXDhg2DsbExNmzYUKVtZmdnw9raGps2bcKLL74IAEhKSsJjjz2GyMhI9OjR44G5c3JyoNFokJ2dDbVa/dD7gYiImgYhBN7/+RRCD12E0lCOzZN6oFvLZlLHajKq+v4t6RGk4uJixMbGws/PT79MLpfDz88PkZGRFd6nqKgIKpWqzDJjY2McOHCgytuMjY1FSUlJmXXc3NzQsmXL+z5uTk5OmQsREVF1yWQyvPt8B/g9ZoOiUh0mrjuClJsFUseiciQtSBkZGdBqtbC1tS2z3NbWFmlpaRXex9/fH4sWLcLZs2eh0+mwZ88ebN++HampqVXeZlpaGhQKBSwsLKr8uAsXLoRGo9FfnJycajJkIiIiGMhlWDKiKzo5qnEzvxiBodHIKiiWOhb9i+RzkKpryZIlaNu2Ldzc3KBQKDBt2jQEBQVBLq/bocyePRvZ2dn6y+XLl+v08YiIqHEzVRpiTYAXHDQqXLiRj8lhsSgq1Uodi/4haUGysrKCgYHBPd8eS09Ph52dXYX3sba2xs6dO5Gfn49Lly4hKSkJZmZmcHZ2rvI27ezsUFxcjKysrCo/rlKphFqtLnMhIiJ6GDZqFdYEecFMaYio5EzM2nacX/+vJyQtSAqFAp6enggPD9cv0+l0CA8Ph6+v733vq1Kp4OjoiNLSUmzbtg2DBg2q8jY9PT1hZGRUZp3Tp08jJSXlgY9LRERUm9zs1Ph6dDcYyGXYEX8VX/x5VupIBMBQ6gAhISEICAhA9+7d4e3tjcWLFyM/Px9BQUEAgLFjx8LR0RELFy4EAERFReHq1avw8PDA1atX8d5770Gn02HmzJlV3qZGo8H48eMREhICS0tLqNVqTJ8+Hb6+vlX6BhsREVFt6t3OGh8O7oRZ24/jy/CzaGlpghc9W0gdq0mTvCANHz4cN27cwNy5c5GWlgYPDw/s2rVLP8k6JSWlzPyiwsJCzJkzBxcuXICZmRkGDBiAsLCwMhOuH7RNAPjiiy8gl8sxbNgwFBUVwd/fH19//fUjGzcREdG/jfBuiUuZBfhm33nM3n4MDhYq9HSxkjpWkyX5eZAaKp4HiYiIaptOJ/Dqlnj8ciwV5ipDbJnUAx0dNFLHalQaxHmQiIiI6H/kchk+e8kd3q0tkVtYioA10bhwI0/qWE0SCxIREVE9ojIywKrA7uhgr0ZGXjHGrI5GavZtqWM1OSxIRERE9YxaZYT1473hbGWKq1m38fKqKGTm80SSjxILEhERUT1kZaZE2AQf2GtUOH8jHwFropFbWCJ1rCaDBYmIiKiecrQwRth4H1iaKnD8ajYmrDuCwhKebftRYEEiIiKqx1xtzLB+nLf+bNvTNsWhRKuTOlajx4JERERUz3Vy1GB1QHcoDeX4M/E6Zv5wDDodz9JTl1iQiIiIGgAf5+b45uVuMPznJ0ne//kkf7etDrEgERERNRBPudni8/+4QyYD1kVe4u+21SEWJCIiogZkkIcj5r/QEQDwZfhZrD6QLHGixokFiYiIqIEZ49saM/q1AwAs+OUUvj9yWeJEjQ8LEhERUQMU3NcVEx5vAwD477Zj2H0yTeJEjQsLEhERUQMkk8nwznOP4T/dW0AngOmb4nHwXIbUsRoNFiQiIqIGSiaT4aMhndG/ox2KtTpMXH8E8Sm3pI7VKLAgERERNWCGBnIsGemBx12tUFCsRVBoDE6n5Uodq8FjQSIiImrglIYG+HaMJzycLJBVUIIxq6NwObNA6lgNGgsSERFRI2CqNERokBfa25rjem4RRq+KwvWcQqljNVgsSERERI2EhYkCYeO90dLSBCmZBRi7JhpZBcVSx2qQWJCIiIgaERu1ChvG+8DGXImktFwEhcagoLhU6lgNDgsSERFRI9OyuQnCxvtAY2yE+JQsTA6LRVGpVupYDQoLEhERUSPU3s4coUFeMFEY4O+zGXh9SwK0Ov64bVWxIBERETVSXVs2w4ox3aEwkOP3E2l4e/txCMGSVBUsSERERI3Y422t8OVID8hlwNYjl/HRb4ksSVXAgkRERNTI9e9kj4+HdQEArPw7GV/vOy9xovqPBYmIiKgJ+E93J8x57jEAwP/tPo2ww5ckTlS/sSARERE1EROecMb0p1wBAHN/PIEfE65KnKj+YkEiIiJqQkKeaYexvq0gBPDmd0fxV1K61JHqJRYkIiKiJkQmk+G9gR0xyMMBpTqBqRviEJ2cKXWseocFiYiIqImRy2X47CV3PO1mg6JSHcaHxuDE1WypY9UrLEhERERNkJGBHMtGd4N3G0vkFpUiYE00zt/IkzpWvcGCRERE1ESpjAywOqA7OjmqcTO/GGNWReFq1m2pY9ULLEhERERNmLnKCOuCvOFsbYpr2YUYsyoKGXlFUseSHAsSERFRE9fcTIkN433gaGGMCxn5CFgTjZzCEqljSYoFiYiIiOBgYYyw8d5obqrAyWs5mLDuCApLtFLHkgwLEhEREQEAnK3NsG6cN8yVhohOzsQrG+NQotVJHUsSLEhERESk18lRg9WBXlAayvFX0nXM+P4odLqm9+O2LEhERERUhncbSyx/2ROGchl+TLiGeT+dhBBNqySxIBEREdE9+rrZYNFwD8hkQNjhS/j8jzNSR3qkWJCIiIioQi+4O2DBoE4AgKV7z2Hl/gsSJ3p0WJCIiIioUi/3aIW3/NsDAD78LRHfxVyWONGjwYJERERE9/VKHxdM7u0MAJi1/Rh+P54qcaK6x4JERERE9yWTyTDrWTcM7+4EnQBe25KAv8/ekDpWnWJBIiIiogeSyWT4aGhnDOhsh2KtDpPDYhGXckvqWHWGBYmIiIiqxEAuwxfDPfBEWysUFGsRtDYGSWk5UseqEyxIREREVGVKQwN8O8YT3VpaIPt2Ccasjsalm/lSx6p1LEhERERULSYKQ6wN9IabnTlu5Bbh5dVRSM8plDpWrWJBIiIiomrTmBhh/XhvtGpugsuZtzFmdRSyCoqljlVrWJCIiIioRmzMVdgw3ge2aiXOpOchcG0M8otKpY5VK1iQiIiIqMacLE0QNt4HFiZGSLichUlhR1BUqpU61kNjQSIiIqKH0s7WHKFB3jBVGODguZt4dXM8SrU6qWM9FBYkIiIiemgeThZYObY7FAZy7D6Zjlnbj0OnE1LHqjEWJCIiIqoVPV2t8NWorjCQy/BD7BV8+FsihGiYJYkFiYiIiGqNf0c7fDKsCwBg9YFkLP3rnMSJaoYFiYiIiGrVi54tMPf5DgCAz/ecwbpDF6UNVAOSF6Rly5ahdevWUKlU8PHxQXR09H3XX7x4Mdq3bw9jY2M4OTnhjTfeQGHh/05OlZubi9dffx2tWrWCsbExevbsiZiYmDLbCAwMhEwmK3Pp379/nYyPiIioKRr3eBu89nRbAMC8n05iZ/xViRNVj6GUD75161aEhIRg+fLl8PHxweLFi+Hv74/Tp0/DxsbmnvU3bdqEWbNmYc2aNejZsyfOnDmjLzuLFi0CAEyYMAEnTpxAWFgYHBwcsGHDBvj5+eHUqVNwdHTUb6t///5Yu3at/rpSqaz7ARMRETUhr/u1RfbtEoQeuog3vz8KM6Uh/DrYSh2rSmRCwtlTPj4+8PLywtKlSwEAOp0OTk5OmD59OmbNmnXP+tOmTUNiYiLCw8P1y958801ERUXhwIEDuH37NszNzfHjjz/iueee06/j6emJZ599Fh988AGAO0eQsrKysHPnzhpnz8nJgUajQXZ2NtRqdY23Q0RE1JjpdAIzvj+K7fFXoTSUY904b/Rwbi5Znqq+f0v2EVtxcTFiY2Ph5+f3vzByOfz8/BAZGVnhfXr27InY2Fj9x3AXLlzAb7/9hgEDBgAASktLodVqoVKpytzP2NgYBw4cKLNs3759sLGxQfv27TF16lTcvHnzvnmLioqQk5NT5kJERET3J5fL8MmLXeD3mC2KSnWYsO4Ijl/JljrWA0lWkDIyMqDVamFrW/ZQm62tLdLS0iq8z6hRozB//nw8/vjjMDIygouLC/r06YO3334bAGBubg5fX18sWLAA165dg1arxYYNGxAZGYnU1FT9dvr374/169cjPDwcn3zyCSIiIvDss89Cq638zJ8LFy6ERqPRX5ycnGphLxARETV+RgZyLB3VFT2cLZFXVIqAtdE4dz1P6lj3Jfkk7erYt28fPvroI3z99deIi4vD9u3b8euvv2LBggX6dcLCwiCEgKOjI5RKJb788kuMHDkScvn/hjpixAi88MIL6Ny5MwYPHoxffvkFMTEx2LdvX6WPPXv2bGRnZ+svly9frsuhEhERNSoqIwOsCvBClxYaZOYXY8zqKFy5VSB1rEpJVpCsrKxgYGCA9PT0MsvT09NhZ2dX4X3effddjBkzBhMmTEDnzp0xZMgQfPTRR1i4cCF0ujunNHdxcUFERATy8vJw+fJlREdHo6SkBM7OzpVmcXZ2hpWVFc6dq/xcDUqlEmq1usyFiIiIqs5MaYjQIG+42pghNbsQY1ZH40ZukdSxKiRZQVIoFPD09Cwz4Vqn0yE8PBy+vr4V3qegoKDMkSAAMDAwAIB7ztRpamoKe3t73Lp1C7t378agQYMqzXLlyhXcvHkT9vb2NR0OERERVYGlqQJh473haGGM5Ix8BKyJRvbtEqlj3UPSj9hCQkKwcuVKrFu3DomJiZg6dSry8/MRFBQEABg7dixmz56tX3/gwIH45ptvsGXLFiQnJ2PPnj149913MXDgQH1R2r17N3bt2qW/vW/fvnBzc9NvMy8vD2+99RYOHz6MixcvIjw8HIMGDYKrqyv8/f0f/U4gIiJqYuw1xtgwwQdWZgqcSs3BhHUxuF1c+TxgKUh6HqThw4fjxo0bmDt3LtLS0uDh4YFdu3bpJ26npKSUOWI0Z84cyGQyzJkzB1evXoW1tTUGDhyIDz/8UL9OdnY2Zs+ejStXrsDS0hLDhg3Dhx9+CCMjIwB3jjgdO3YM69atQ1ZWFhwcHNCvXz8sWLCA50IiIiJ6RNpYmWL9OB8MXxGJmIu3MHVjLFaM6Q6FYf2YHi3peZAaMp4HiYiI6OEduZiJl1dHobBEh+e72GPJiDs/dltX6v15kIiIiIi6t7bE8pc9YWQgwy/HUvHujyfumVcsBRYkIiIiklSf9jb4YrgHZDJgU1QK/m/3aakjsSARERGR9J7v4oCPhnQGAHy97zy+jTgvaR4WJCIiIqoXRnq3xKxn3QAAC39PwuboFMmysCARERFRvTHlSRdMedIFSkM5bMyl+3a5pF/zJyIiIirvv/3b40XPFnC1MZMsA48gERERUb0ik8kkLUcACxIRERHRPViQiIiIiMphQSIiIiIqhwWJiIiIqBwWJCIiIqJyWJCIiIiIymFBIiIiIiqHBYmIiIioHBYkIiIionJYkIiIiIjKYUEiIiIiKocFiYiIiKgcFiQiIiKicgylDtBQCSEAADk5ORInISIioqq6+7599328MixINZSbmwsAcHJykjgJERERVVdubi40Gk2lt8vEgyoUVUin0+HatWswNzeHTCarte3m5OTAyckJly9fhlqtrrXtNiRNfR809fED3AdNffwA9wHHX3fjF0IgNzcXDg4OkMsrn2nEI0g1JJfL0aJFizrbvlqtbpL/U/xbU98HTX38APdBUx8/wH3A8dfN+O935OguTtImIiIiKocFiYiIiKgcFqR6RqlUYt68eVAqlVJHkUxT3wdNffwA90FTHz/AfcDxSz9+TtImIiIiKodHkIiIiIjKYUEiIiIiKocFiYiIiKgcFiQiIiKicliQ6plly5ahdevWUKlU8PHxQXR0tNSR6sR7770HmUxW5uLm5qa/vbCwEMHBwWjevDnMzMwwbNgwpKenS5j44e3fvx8DBw6Eg4MDZDIZdu7cWeZ2IQTmzp0Le3t7GBsbw8/PD2fPni2zTmZmJkaPHg21Wg0LCwuMHz8eeXl5j3AUNfeg8QcGBt7zmujfv3+ZdRry+BcuXAgvLy+Ym5vDxsYGgwcPxunTp8usU5XXfUpKCp577jmYmJjAxsYGb731FkpLSx/lUGqkKuPv06fPPa+BKVOmlFmnoY4fAL755ht06dJFf/JDX19f/P777/rbG/PzDzx4/PXt+WdBqke2bt2KkJAQzJs3D3FxcXB3d4e/vz+uX78udbQ60bFjR6SmpuovBw4c0N/2xhtv4Oeff8b333+PiIgIXLt2DUOHDpUw7cPLz8+Hu7s7li1bVuHtn376Kb788kssX74cUVFRMDU1hb+/PwoLC/XrjB49GidPnsSePXvwyy+/YP/+/Zg0adKjGsJDedD4AaB///5lXhObN28uc3tDHn9ERASCg4Nx+PBh7NmzByUlJejXrx/y8/P16zzoda/VavHcc8+huLgYhw4dwrp16xAaGoq5c+dKMaRqqcr4AWDixIllXgOffvqp/raGPH4AaNGiBT7++GPExsbiyJEjeOqppzBo0CCcPHkSQON+/oEHjx+oZ8+/oHrD29tbBAcH669rtVrh4OAgFi5cKGGqujFv3jzh7u5e4W1ZWVnCyMhIfP/99/pliYmJAoCIjIx8RAnrFgCxY8cO/XWdTifs7OzE//3f/+mXZWVlCaVSKTZv3iyEEOLUqVMCgIiJidGv8/vvvwuZTCauXr36yLLXhvLjF0KIgIAAMWjQoErv05jGL4QQ169fFwBERESEEKJqr/vffvtNyOVykZaWpl/nm2++EWq1WhQVFT3aATyk8uMXQognn3xSvPbaa5XepzGN/65mzZqJVatWNbnn/6674xei/j3/PIJUTxQXFyM2NhZ+fn76ZXK5HH5+foiMjJQwWd05e/YsHBwc4OzsjNGjRyMlJQUAEBsbi5KSkjL7ws3NDS1btmy0+yI5ORlpaWllxqzRaODj46Mfc2RkJCwsLNC9e3f9On5+fpDL5YiKinrkmevCvn37YGNjg/bt22Pq1Km4efOm/rbGNv7s7GwAgKWlJYCqve4jIyPRuXNn2Nra6tfx9/dHTk5OmX+FNwTlx3/Xxo0bYWVlhU6dOmH27NkoKCjQ39aYxq/VarFlyxbk5+fD19e3yT3/5cd/V316/vljtfVERkYGtFptmSceAGxtbZGUlCRRqrrj4+OD0NBQtG/fHqmpqXj//ffxxBNP4MSJE0hLS4NCoYCFhUWZ+9ja2iItLU2awHXs7rgqev7v3paWlgYbG5sytxsaGsLS0rJR7Jf+/ftj6NChaNOmDc6fP4+3334bzz77LCIjI2FgYNCoxq/T6fD666+jV69e6NSpEwBU6XWflpZW4Wvk7m0NRUXjB4BRo0ahVatWcHBwwLFjx/Df//4Xp0+fxvbt2wE0jvEfP34cvr6+KCwshJmZGXbs2IEOHTogISGhSTz/lY0fqH/PPwsSSeLZZ5/V/7lLly7w8fFBq1at8N1338HY2FjCZCSVESNG6P/cuXNndOnSBS4uLti3bx+efvppCZPVvuDgYJw4caLMvLumpLLx/3s+WefOnWFvb4+nn34a58+fh4uLy6OOWSfat2+PhIQEZGdn44cffkBAQAAiIiKkjvXIVDb+Dh061Lvnnx+x1RNWVlYwMDC45xsL6enpsLOzkyjVo2NhYYF27drh3LlzsLOzQ3FxMbKyssqs05j3xd1x3e/5t7Ozu2fCfmlpKTIzMxvlfnF2doaVlRXOnTsHoPGMf9q0afjll1+wd+9etGjRQr+8Kq97Ozu7Cl8jd29rCCobf0V8fHwAoMxroKGPX6FQwNXVFZ6enli4cCHc3d2xZMmSJvP8Vzb+ikj9/LMg1RMKhQKenp4IDw/XL9PpdAgPDy/z+WxjlZeXh/Pnz8Pe3h6enp4wMjIqsy9Onz6NlJSURrsv2rRpAzs7uzJjzsnJQVRUlH7Mvr6+yMrKQmxsrH6dv/76CzqdTv8XSWNy5coV3Lx5E/b29gAa/viFEJg2bRp27NiBv/76C23atClze1Ve976+vjh+/HiZorhnzx6o1Wr9xxT11YPGX5GEhAQAKPMaaKjjr4xOp0NRUVGjf/4rc3f8FZH8+a/1ad9UY1u2bBFKpVKEhoaKU6dOiUmTJgkLC4syM/YbizfffFPs27dPJCcni4MHDwo/Pz9hZWUlrl+/LoQQYsqUKaJly5bir7/+EkeOHBG+vr7C19dX4tQPJzc3V8THx4v4+HgBQCxatEjEx8eLS5cuCSGE+Pjjj4WFhYX48ccfxbFjx8SgQYNEmzZtxO3bt/Xb6N+/v+jatauIiooSBw4cEG3bthUjR46UakjVcr/x5+bmihkzZojIyEiRnJws/vzzT9GtWzfRtm1bUVhYqN9GQx7/1KlThUajEfv27ROpqan6S0FBgX6dB73uS0tLRadOnUS/fv1EQkKC2LVrl7C2thazZ8+WYkjV8qDxnzt3TsyfP18cOXJEJCcnix9//FE4OzuL3r1767fRkMcvhBCzZs0SERERIjk5WRw7dkzMmjVLyGQy8ccffwghGvfzL8T9x18fn38WpHrmq6++Ei1bthQKhUJ4e3uLw4cPSx2pTgwfPlzY29sLhUIhHB0dxfDhw8W5c+f0t9++fVu88sorolmzZsLExEQMGTJEpKamSpj44e3du1cAuOcSEBAghLjzVf93331X2NraCqVSKZ5++mlx+vTpMtu4efOmGDlypDAzMxNqtVoEBQWJ3NxcCUZTffcbf0FBgejXr5+wtrYWRkZGolWrVmLixIn3/OOgIY+/orEDEGvXrtWvU5XX/cWLF8Wzzz4rjI2NhZWVlXjzzTdFSUnJIx5N9T1o/CkpKaJ3797C0tJSKJVK4erqKt566y2RnZ1dZjsNdfxCCDFu3DjRqlUroVAohLW1tXj66af15UiIxv38C3H/8dfH518mhBC1f1yKiIiIqOHiHCQiIiKicliQiIiIiMphQSIiIiIqhwWJiIiIqBwWJCIiIqJyWJCIiIiIymFBIiIiIiqHBYmIiIioHBYkoiYmMDAQgwcPljrGA+3btw8ymeyeH++sroYy3rpUX/bBe++9Bw8PD6ljEFUJCxKRBAIDAyGTySCTyWBkZIQ2bdpg5syZKCwslDpajdTFG1/Pnj2RmpoKjUZTq9uVUmhoKCwsLGpte/W5cMhkMuzcubPMshkzZpT5MVai+sxQ6gBETVX//v2xdu1alJSUIDY2FgEBAZDJZPjkk0+kjlYvKBQK2NnZSR2jXhJCQKvVSh2j2szMzGBmZiZ1DKIq4REkIokolUrY2dnByckJgwcPhp+fH/bs2aO/XafTYeHChWjTpg2MjY3h7u6OH374QX+7VqvF+PHj9be3b98eS5YsKfMYWq0WISEhsLCwQPPmzTFz5kyU//nFoqIivPrqq7CxsYFKpcLjjz+OmJgY/e0VHfXYuXMnZDKZ/vb3338fR48e1R8VCw0NvWe8J06cgFwux40bNwAAmZmZkMvlGDFihH6dDz74AI8//jiAez9iu5tj9+7deOyxx2BmZob+/fsjNTW1VsfbvXt3fPbZZ/rrgwcPhpGREfLy8gAAV65cgUwmw7lz5+4ZIwAcPXoUffv2hbm5OdRqNTw9PXHkyBHs27cPQUFByM7O1u+n9957DwAQFhaG7t27w9zcHHZ2dhg1ahSuX7+u3+bdffH777/D09MTSqUSGzZsqNJ+r8iD9gEAnDx5Es8//zzUajXMzc3xxBNP4Pz58wCAmJgYPPPMM7CysoJGo8GTTz6JuLg4/X1bt24NABgyZAhkMpn+evkjXjqdDvPnz0eLFi2gVCrh4eGBXbt26W+/ePEiZDIZtm/fjr59+8LExATu7u6IjIys0jiJHgYLElE9cOLECRw6dAgKhUK/bOHChVi/fj2WL1+OkydP4o033sDLL7+MiIgIAHfeXFq0aIHvv/8ep06dwty5c/H222/ju+++02/j888/R2hoKNasWYMDBw4gMzMTO3bsKPPYM2fOxLZt27Bu3TrExcXB1dUV/v7+yMzMrFL24cOH480330THjh2RmpqK1NRUDB8+/J71OnbsiObNm+vz//3332WuA0BERAT69OlT6WMVFBTgs88+Q1hYGPbv34+UlBTMmDGjVsf75JNPYt++fQDuHKn5+++/YWFhgQMHDugzOjo6wtXVtcKMo0ePRosWLRATE4PY2FjMmjULRkZG6NmzJxYvXgy1Wq3fT3ezl5SUYMGCBTh69Ch27tyJixcvIjAw8J5tz5o1Cx9//DESExPxzDPPVGm/V+RB++Dq1avo3bs3lEol/vrrL8TGxmLcuHEoLS0FAOTm5iIgIAAHDhzA4cOH0bZtWwwYMAC5ubkAoC9ba9euRWpq6j3l664lS5bg888/x2effYZjx47B398fL7zwAs6ePVtmvXfeeQczZsxAQkIC2rVrh5EjR+qzENUZQUSPXEBAgDAwMBCmpqZCqVQKAEIul4sffvhBCCFEYWGhMDExEYcOHSpzv/Hjx4uRI0dWut3g4GAxbNgw/XV7e3vx6aef6q+XlJSIFi1aiEGDBgkhhMjLyxNGRkZi48aN+nWKi4uFg4OD/n5r164VGo2mzOPs2LFD/Puvj3nz5gl3d/cHjnvo0KEiODhYCCHE66+/Lt566y3RrFkzkZiYKIqLi4WJiYn4448/hBBC7N27VwAQt27d0ucAIM6dO6ff3rJly4StrW2tjvenn34SGo1GlJaWioSEBGFnZydee+018d///lcIIcSECRPEqFGjKh2jubm5CA0NrfC2ivZlRWJiYgQAkZubW2Zf7Ny5s8x6Vd3vAQEB1doHs2fPFm3atBHFxcUP3LYQQmi1WmFubi5+/vln/TIAYseOHffN6+DgID788MMy63h5eYlXXnlFCCFEcnKyACBWrVqlv/3kyZMCgEhMTKxSNqKa4hEkIon07dsXCQkJiIqKQkBAAIKCgjBs2DAAwLlz51BQUIBnnnlGP2/DzMwM69ev13/MAQDLli2Dp6cnrK2tYWZmhhUrViAlJQUAkJ2djdTUVPj4+OjXNzQ0RPfu3fXXz58/j5KSEvTq1Uu/zMjICN7e3khMTKz1Mf/76ExERASeeuop9O7dG/v27UNMTMw9WcozMTGBi4uL/rq9vb3+o6jaGu8TTzyB3NxcxMfHIyIiAk8++ST69OlTJvf9jnKFhIRgwoQJ8PPzw8cff1zm+apMbGwsBg4ciJYtW8Lc3BxPPvkkAOify7v+PZaaqso+SEhIwBNPPAEjI6MKt5Geno6JEyeibdu20Gg0UKvVyMvLuyfv/eTk5ODatWv3PN+9evW657XXpUsX/Z/t7e0BoMxHkER1gQWJSCKmpqZwdXWFu7s71qxZg6ioKKxevRoA9PNdfv31VyQkJOgvp06d0s9D2rJlC2bMmIHx48fjjz/+QEJCAoKCglBcXFyrOeVy+T3zeEpKSmq0rT59+uDUqVM4e/YsTp06hccff1xfPiIiItC9e3eYmJhUev/yb9gymeyebA/LwsIC7u7u+kx9+vRB7969ER8fjzNnzuDs2bP6AlOR9957DydPnsRzzz2Hv/76Cx06dLjnY75/y8/Ph7+/P9RqNTZu3IiYmBj9+uWfS1NT09oZ5AMYGxvf9/aAgAAkJCRgyZIlOHToEBISEtC8efNaf+3d9e/n/e7cN51OVyePRXQXCxJRPSCXy/H2229jzpw5uH37Njp06AClUomUlBS4urqWuTg5OQEADh48iJ49e+KVV15B165d4erqWuZohUajgb29PaKiovTLSktLERsbq7/u4uIChUKBgwcP6peVlJQgJiYGHTp0AABYW1sjNzcX+fn5+nUSEhLK5FcoFFX6VlXnzp3RrFkzfPDBB/Dw8ICZmRn69OmDiIgI7Nu3775HZh6ktsYL3DnStXfvXuzfvx99+vSBpaUlHnvsMXz44Yewt7dHu3bt7pulXbt2eOONN/DHH39g6NChWLt2LYCK91NSUhJu3ryJjz/+GE888QTc3NyqfHSkqvv936qyD7p06YK///670iJ88OBBvPrqqxgwYAA6duwIpVKJjIyMMusYGRndN5tarYaDg0OZHHe3/e/ngkgqLEhE9cRLL70EAwMDLFu2DObm5pgxYwbeeOMNrFu3DufPn0dcXBy++uorrFu3DgDQtm1bHDlyBLt378aZM2fw7rvv3jMZ9rXXXsPHH3+MnTt3IikpCa+88kqZEy+amppi6tSpeOutt7Br1y6cOnUKEydOREFBAcaPHw8A8PHxgYmJCd5++22cP38emzZtuufbUq1bt0ZycjISEhKQkZGBoqKiCscok8nQu3dvbNy4UV+GunTpgqKiIoSHh9/3yExV1MZ4gTtHunbv3g1DQ0O4ubnpl23cuPG+GW/fvo1p06Zh3759uHTpEg4ePIiYmBg89thj+v2Ul5eH8PBwZGRkoKCgAC1btoRCocBXX32FCxcu4KeffsKCBQuqNN6q7vd/q8o+mDZtGnJycjBixAgcOXIEZ8+eRVhYGE6fPg3gzmsvLCwMiYmJiIqKwujRo+856tS6dWuEh4cjLS0Nt27dqjDLW2+9hU8++QRbt27F6dOnMWvWLCQkJOC1116r0viJ6pTUk6CImqJ/T5r9t4ULFwpra2uRl5cndDqdWLx4sWjfvr0wMjIS1tbWwt/fX0RERAgh7kzkDgwMFBqNRlhYWIipU6eKWbNmlZkEW1JSIl577TWhVquFhYWFCAkJEWPHji3z2Ldv3xbTp08XVlZWQqlUil69eono6OgyuXbs2CFcXV2FsbGxeP7558WKFSvKTNIuLCwUw4YNExYWFgKAWLt2baVj/+KLLwQA8fvvv+uXDRo0SBgaGuonJQtR8STtB00Wr63x3rx5U8hkMjF8+PB7Hmv58uWVjq2oqEiMGDFCODk5CYVCIRwcHMS0adPE7du39etMmTJFNG/eXAAQ8+bNE0IIsWnTJtG6dWuhVCqFr6+v+OmnnwQAER8fX+G+uKuq+738660q++Do0aOiX79+wsTERJibm4snnnhCnD9/XgghRFxcnOjevbtQqVSibdu24vvvvxetWrUSX3zxhf7+P/30k3B1dRWGhoaiVatWQoh7J2lrtVrx3nvvCUdHR2FkZCTc3d3LvC7uTtK+ux+EEOLWrVsCgNi7d2+lzwNRbZAJUcsf4BMRERE1cPyIjYiIiKgcFiQiIiKicliQiIiIiMphQSIiIiIqhwWJiIiIqBwWJCIiIqJyWJCIiIiIymFBIiIiIiqHBYmIiIioHBYkIiIionJYkIiIiIjK+X8/NTu9wUeCtgAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sl_fidelity = 1 - (1 - np.array(sl_e_accuracy)) - (1 - np.array(sl_g_accuracy)) \n",
    "\n",
    "plt.figure()\n",
    "plt.plot(window_start_locations, sl_fidelity)\n",
    "plt.xlabel('Readout window start location')\n",
    "plt.ylabel('Fidelity')\n",
    "\n",
    "print('Accuracy', sl_accuracy)\n",
    "print('Fidelity', sl_fidelity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml4qick-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
