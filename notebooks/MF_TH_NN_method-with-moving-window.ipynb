{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from malab import *\n",
    "%pylab inline\n",
    "import numpy as np\n",
    "import hashlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-22 13:20:14.533738: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-08-22 13:20:14.630895: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2024-08-22 13:20:14.630912: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2024-08-22 13:20:15.110519: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2024-08-22 13:20:15.110577: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2024-08-22 13:20:15.110585: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "import hashlib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation, BatchNormalization, Dropout, Softmax\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, ModelCheckpoint\n",
    "from tensorflow.keras.losses import CategoricalCrossentropy\n",
    "from qkeras.utils import _add_supported_quantized_objects\n",
    "from tensorflow.keras.models import load_model\n",
    "from qkeras.utils import _add_supported_quantized_objects"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read training data\n",
    "\n",
    "#### Impoartant! \n",
    "Download the dataset locally from [OneDrive here](https://purdue0-my.sharepoint.com/personal/du245_purdue_edu/_layouts/15/onedrive.aspx?id=%2Fpersonal%2Fdu245%5Fpurdue%5Fedu%2FDocuments%2FShared%2FQSC%20ML%20for%20readout%2FFinal%5Fraw%5Fdata%5Ffor%5Fpaper%2Fdata%5F0528%5Fnpy). We are using QICK data with timestamp **0528**. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Data Set:\n",
      "\tX Path        : ../data/malab_05282024/npz/0528_X_train_0_770.npy\n",
      "\ty Path        : ../data/malab_05282024/npz/0528_y_train_0_770.npy\n",
      "\tSize          : 900000\n",
      "\tSample Shape  : (1540,)\n",
      "\tMean          : 57.37779754545455\n",
      "\tStd. Dev.     : 844.0956096913322\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Loadning training split\"\"\"\n",
    "start_window = 0\n",
    "end_window = 770\n",
    "data_dir = \"../data/malab_05282024/npz/\"\n",
    "assert os.path.exists(f\"{data_dir}/0528_X_train_{start_window}_{end_window}.npy\"), \"File does not exist \"\n",
    "\n",
    "x_train_path = os.path.join(data_dir, f'0528_X_train_{start_window}_{end_window}.npy')\n",
    "y_train_path = os.path.join(data_dir, f'0528_y_train_{start_window}_{end_window}.npy')\n",
    "\n",
    "data_X = np.load(x_train_path)\n",
    "data_Y = np.load(y_train_path)\n",
    "\n",
    "# Insure same dataset is loaded \n",
    "assert hashlib.md5(data_X).hexdigest() == 'b61226c86b7dee0201a9158455e08ffb',  \"Checksum failed. Wrong file was loaded or file may be corrupted.\"\n",
    "assert hashlib.md5(data_Y).hexdigest() == 'c59ce37dc7c73d2d546e7ea180fa8d31',  \"Checksum failed. Wrong file was loaded or file may be corrupted.\"\n",
    "\n",
    "print(\"Train Data Set:\")\n",
    "print(\"\\tX Path        :\", x_train_path)\n",
    "print(\"\\ty Path        :\", y_train_path)\n",
    "print(\"\\tSize          :\", len(data_X))\n",
    "print(\"\\tSample Shape  :\", data_X[0].shape)\n",
    "print(\"\\tMean          :\", data_X.mean())\n",
    "print(\"\\tStd. Dev.     :\", data_X.std())\n",
    "\n",
    "assert len(data_X[0]) == (end_window-start_window)*2, \"ERROR: Specified window does not match loaded dataset shape\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(900000, 1540)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(900000,)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [1., 1., 1., ..., 1., 1., 1.]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_Y.reshape(90,2,5000)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reshape training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# index = [file_index, state_index, shot_index, time_index, ADC_index]\n",
    "data_X_new = data_X.reshape(90, 2, 5000, 770, 2)\n",
    "data_Y_new = data_Y.reshape(90, 2, 5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_index = 0\n",
    "\n",
    "#### I part ###\n",
    "figure(figsize = (4,2), dpi = 150)\n",
    "\n",
    "\n",
    "test = data_X_new[file_index,0].mean(axis = 0)\n",
    "plot(test[:,0], label = 'g')\n",
    "test = data_X_new[file_index,1].mean(axis = 0)\n",
    "plot(test[:,0], label = 'e')\n",
    "legend()\n",
    "\n",
    "ylabel('I - ADC unit')\n",
    "xlabel('Time [clock cycle] ')\n",
    "xlim(0,770)\n",
    "legend()\n",
    "show()\n",
    "\n",
    "\n",
    "#### Q part ###\n",
    "figure(figsize = (4,2), dpi = 150)\n",
    "\n",
    "\n",
    "test = data_X_new[file_index,0].mean(axis = 0)\n",
    "plot(test[:,1], label = 'g')\n",
    "test = data_X_new[file_index,1].mean(axis = 0)\n",
    "plot(test[:,1], label = 'e')\n",
    "legend()\n",
    "\n",
    "ylabel('Q - ADC unit')\n",
    "xlabel('Time [clock cycle] ')\n",
    "xlim(0,770)\n",
    "legend()\n",
    "show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read test data\n",
    "\n",
    "#### Impoartant! \n",
    "Download the dataset locally from [OneDrive here](https://purdue0-my.sharepoint.com/personal/du245_purdue_edu/_layouts/15/onedrive.aspx?id=%2Fpersonal%2Fdu245%5Fpurdue%5Fedu%2FDocuments%2FShared%2FQSC%20ML%20for%20readout%2FFinal%5Fraw%5Fdata%5Ffor%5Fpaper%2Fdata%5F0528%5Fnpy). We are using QICK data with timestamp **0528**. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Data Set:\n",
      "\tX Path        : ../data/malab_05282024/npz/0528_X_test_0_770.npy\n",
      "\ty Path        : ../data/malab_05282024/npz/0528_y_test_0_770.npy\n",
      "\tSize         : 100000\n",
      "\tSample Shape : (1540,)\n",
      "\tSample Shape : 57.57549828571429\n",
      "\tStd. Dev.    : 845.6158899866076\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Loading testing split\"\"\"\n",
    "start_window = 0\n",
    "end_window = 770\n",
    "data_dir = \"../data/malab_05282024/npz/\"\n",
    "assert os.path.exists(f\"{data_dir}/X_test_{start_window}_{end_window}.npy\"), \"File does not exist \"\n",
    "\n",
    "x_test_path = os.path.join(data_dir, f'0528_X_test_{start_window}_{end_window}.npy')\n",
    "y_test_path = os.path.join(data_dir, f'0528_y_test_{start_window}_{end_window}.npy')\n",
    "\n",
    "test_X = np.load(x_test_path)\n",
    "test_Y = np.load(y_test_path)\n",
    "\n",
    "# Insure same dataset is loaded \n",
    "assert hashlib.md5(test_X).hexdigest() == 'b7d85f42522a0a57e877422bc5947cde', \"Checksum failed. Wrong file was loaded or file may be corrupted.\"\n",
    "assert hashlib.md5(test_Y).hexdigest() == '8c9cce1821372380371ade5f0ccfd4a2', \"Checksum failed. Wrong file was loaded or file may be corrupted.\"\n",
    "\n",
    "print(\"Test Data Set:\")\n",
    "print(\"\\tX Path        :\", x_test_path)\n",
    "print(\"\\ty Path        :\", y_test_path)\n",
    "print(\"\\tSize         :\", len(test_X))\n",
    "print(\"\\tSample Shape :\", test_X[0].shape)\n",
    "print(\"\\tSample Shape :\", test_X.mean())\n",
    "print(\"\\tStd. Dev.    :\", test_X.std())\n",
    "\n",
    "assert len(test_X[0]) == (end_window-start_window)*2, \"ERROR: Specified window does not match loaded dataset shape\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100000, 1540)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100000,)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_Y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reshape test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# index = [file_index, state_index, shot_index, time_index, ADC_index]\n",
    "test_X_new = test_X.reshape(10, 2, 5000, 770, 2)\n",
    "test_Y_new = test_Y.reshape(10, 2, 5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_index = 0\n",
    "\n",
    "#### I part ###\n",
    "figure(figsize = (4,2), dpi = 150)\n",
    "\n",
    "\n",
    "test = test_X_new[file_index,0].mean(axis = 0)\n",
    "plot(test[:,0], label = 'g')\n",
    "test = test_X_new[file_index,1].mean(axis = 0)\n",
    "plot(test[:,0], label = 'e')\n",
    "legend()\n",
    "\n",
    "ylabel('I - ADC unit')\n",
    "xlabel('Time [clock cycle] ')\n",
    "xlim(0,770)\n",
    "legend()\n",
    "show()\n",
    "\n",
    "\n",
    "#### Q part ###\n",
    "figure(figsize = (4,2), dpi = 150)\n",
    "\n",
    "\n",
    "test = test_X_new[file_index,0].mean(axis = 0)\n",
    "plot(test[:,1], label = 'g')\n",
    "test = test_X_new[file_index,1].mean(axis = 0)\n",
    "plot(test[:,1], label = 'e')\n",
    "legend()\n",
    "\n",
    "ylabel('Q - ADC unit')\n",
    "xlabel('Time [clock cycle] ')\n",
    "xlim(0,770)\n",
    "legend()\n",
    "show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TH model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "readout_loc_list = np.linspace(0,350, 8)\n",
    "all_fidelity = np.zeros(len(readout_loc_list))\n",
    "all_fidelity_train = np.zeros(len(readout_loc_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for m, readout_loc in enumerate(readout_loc_list):\n",
    "    #### training data #####\n",
    "    if True:\n",
    "        mean_Ig_train = data_X_new[:, 0, :, int(readout_loc): int(readout_loc + 400), 0].mean(axis = 2)\n",
    "        mean_Qg_train = data_X_new[:, 0, :, int(readout_loc): int(readout_loc + 400), 1].mean(axis = 2)\n",
    "        mean_Ie_train = data_X_new[:, 1, :, int(readout_loc): int(readout_loc + 400), 0].mean(axis = 2)\n",
    "        mean_Qe_train = data_X_new[:, 1, :, int(readout_loc): int(readout_loc + 400), 1].mean(axis = 2)\n",
    "\n",
    "        # IQ plot\n",
    "        I_g = mean_Ig_train.flatten()\n",
    "        Q_g = mean_Qg_train.flatten()\n",
    "        I_e = mean_Ie_train.flatten()\n",
    "        Q_e = mean_Qe_train.flatten()\n",
    "\n",
    "        plt.title('IQ Plot')\n",
    "        plt.plot(I_g, Q_g, '.',label = 'g',markersize = 0.05)\n",
    "        plt.plot(I_e, Q_e, '.',label = 'e',markersize = 0.05)\n",
    "        plt.xlabel('I')\n",
    "        plt.ylabel('Q')\n",
    "        plt.legend()\n",
    "        plt.axis('square')\n",
    "        show()\n",
    "\n",
    "        Ig = mean(I_g)\n",
    "        Ie = mean(I_e)\n",
    "        Qg = mean(Q_g)\n",
    "        Qe = mean(Q_e)\n",
    "        vec_I = Ie - Ig\n",
    "        vec_Q = Qe - Qg\n",
    "\n",
    "        gstate = (I_g - Ig)*vec_I + (Q_g - Qg)*vec_Q\n",
    "        estate = (I_e - Ig)*vec_I + (Q_e - Qg)*vec_Q\n",
    "        gstate = gstate / abs(vec_I+1j*vec_Q)**2\n",
    "        estate = estate / abs(vec_I+1j*vec_Q)**2\n",
    "        plt.hist(gstate,bins = 300,label = 'g',alpha = 0.5)\n",
    "        plt.hist(estate,bins = 300,label = 'e',alpha = 0.5)\n",
    "        plt.legend()\n",
    "        show()\n",
    "\n",
    "        th_min = min(gstate)\n",
    "        th_max = max(estate)\n",
    "        th_list = np.linspace(th_min,th_max,1000)\n",
    "\n",
    "        fidelity = [(sum(gstate<th)+sum(estate>th))/np.shape(gstate)[0]/2 for i,th in enumerate(th_list)]\n",
    "        print('max fidelity = ',max(fidelity)*2-1)\n",
    "        loc_opt = argmax(fidelity)\n",
    "\n",
    "        print('\\n rough estimation of n_th')\n",
    "        100*sum(gstate>th_list[argmax(fidelity)])/len(gstate)\n",
    "        \n",
    "        all_fidelity_train[m] = max(fidelity)*2-1\n",
    "    \n",
    "    #### testing data #####\n",
    "    if True:\n",
    "        mean_Ig_test = test_X_new[:, 0, :, int(readout_loc): int(readout_loc + 400), 0].mean(axis = 2)\n",
    "        mean_Qg_test = test_X_new[:, 0, :, int(readout_loc): int(readout_loc + 400), 1].mean(axis = 2)\n",
    "        mean_Ie_test = test_X_new[:, 1, :, int(readout_loc): int(readout_loc + 400), 0].mean(axis = 2)\n",
    "        mean_Qe_test = test_X_new[:, 1, :, int(readout_loc): int(readout_loc + 400), 1].mean(axis = 2)\n",
    "\n",
    "        # IQ plot\n",
    "        I_g = mean_Ig_test.flatten()\n",
    "        Q_g = mean_Qg_test.flatten()\n",
    "        I_e = mean_Ie_test.flatten()\n",
    "        Q_e = mean_Qe_test.flatten()\n",
    "        \n",
    "        gstate = (I_g - Ig)*vec_I + (Q_g - Qg)*vec_Q\n",
    "        estate = (I_e - Ig)*vec_I + (Q_e - Qg)*vec_Q\n",
    "        gstate = gstate / abs(vec_I+1j*vec_Q)**2\n",
    "        estate = estate / abs(vec_I+1j*vec_Q)**2\n",
    "        plt.hist(gstate,bins = 300,label = 'g',alpha = 0.5)\n",
    "        plt.hist(estate,bins = 300,label = 'e',alpha = 0.5)\n",
    "        plt.legend()\n",
    "        show()\n",
    "        \n",
    "        th = th_list[loc_opt]\n",
    "        test_fide = (sum(gstate<th)+sum(estate>th))/np.shape(gstate)[0]/2\n",
    "\n",
    "        all_fidelity[m] = test_fide*2-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_fidelity_NN = np.array([0.95445, 0.95579, 0.9573, 0.95642, 0.9545, 0.95276, 0.94966, 0.94661])\n",
    "\n",
    "figure(figsize = (4,3), dpi = 150)\n",
    "# errorbar(readout_loc_list, all_fidelity, xerr=0.0, yerr=all_fidelity_std,  label = 'TH method')\n",
    "plot(readout_loc_list, all_fidelity, '.-', label = 'TH method_Test')\n",
    "plot(readout_loc_list, all_fidelity_train, '.-', label = 'TH method_Train')\n",
    "plot(readout_loc_list, all_fidelity_NN*2-1, '.-', label = 'NN method')\n",
    "\n",
    "axvline(100, ls = '--', color = 'red')\n",
    "legend()\n",
    "ylim(0.88,0.94)\n",
    "xlabel('Readout window location')\n",
    "ylabel('Flidelity')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MF model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# index = [file_index, state_index, shot_index, time_index, ADC_index]\n",
    "data_X_new = data_X.reshape(90, 2, 5000, 770, 2)\n",
    "data_Y_new = data_Y.reshape(90, 2, 5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_Ig_trace = (data_X_new[:,0,:,:,0].mean(axis = 0)).mean(axis = 0)\n",
    "mean_Qg_trace = (data_X_new[:,0,:,:,1].mean(axis = 0)).mean(axis = 0)\n",
    "mean_Ie_trace = (data_X_new[:,1,:,:,0].mean(axis = 0)).mean(axis = 0)\n",
    "mean_Qe_trace = (data_X_new[:,1,:,:,1].mean(axis = 0)).mean(axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_I = abs(mean_Ig_trace - mean_Ie_trace)\n",
    "weight_Q = abs(mean_Qg_trace - mean_Qe_trace)\n",
    "\n",
    "figure(figsize = (4,2), dpi = 150)\n",
    "plot(weight_I, label = 'I', color = 'C0', ls = '-')\n",
    "plot(weight_Q, label = 'Q', color = 'C1', ls = '-')\n",
    "ylabel('ADC unit')\n",
    "xlabel('Time [clock cycle] ')\n",
    "xlim(0,770)\n",
    "legend()\n",
    "show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "readout_loc_list = np.linspace(0,350, 8)\n",
    "all_fidelity_MF_train = np.zeros(len(readout_loc_list))\n",
    "all_fidelity_MF_test = np.zeros(len(readout_loc_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for m, readout_loc in enumerate(readout_loc_list):\n",
    "    #### training data #####\n",
    "    if True:\n",
    "        mean_Ig_train = data_X_new[:, 0, :, int(readout_loc): int(readout_loc + 400), 0].dot(weight_I[int(readout_loc):int(readout_loc + 400)])\n",
    "        mean_Qg_train = data_X_new[:, 0, :, int(readout_loc): int(readout_loc + 400), 1].dot(weight_Q[int(readout_loc):int(readout_loc + 400)])\n",
    "        mean_Ie_train = data_X_new[:, 1, :, int(readout_loc): int(readout_loc + 400), 0].dot(weight_I[int(readout_loc):int(readout_loc + 400)])\n",
    "        mean_Qe_train = data_X_new[:, 1, :, int(readout_loc): int(readout_loc + 400), 1].dot(weight_Q[int(readout_loc):int(readout_loc + 400)])\n",
    "\n",
    "        # IQ plot  \n",
    "        ratio = 1.5\n",
    "        I_g = ratio*mean_Ig_train.flatten()/770/2048\n",
    "        Q_g = mean_Qg_train.flatten()/770/2048\n",
    "        I_e = ratio*mean_Ie_train.flatten()/770/2048\n",
    "        Q_e = mean_Qe_train.flatten()/770/2048\n",
    "\n",
    "        plt.title('IQ Plot')\n",
    "        plt.plot(I_g, Q_g, '.',label = 'g',markersize = 0.05)\n",
    "        plt.plot(I_e, Q_e, '.',label = 'e',markersize = 0.05)\n",
    "        plt.xlabel('I')\n",
    "        plt.ylabel('Q')\n",
    "        plt.legend()\n",
    "        plt.axis('square')\n",
    "        show()\n",
    "\n",
    "        Ig = mean(I_g)\n",
    "        Ie = mean(I_e)\n",
    "        Qg = mean(Q_g)\n",
    "        Qe = mean(Q_e)\n",
    "        vec_I = Ie - Ig\n",
    "        vec_Q = Qe - Qg\n",
    "\n",
    "        gstate = (I_g - Ig)*vec_I + (Q_g - Qg)*vec_Q\n",
    "        estate = (I_e - Ig)*vec_I + (Q_e - Qg)*vec_Q\n",
    "        gstate = gstate / abs(vec_I+1j*vec_Q)**2\n",
    "        estate = estate / abs(vec_I+1j*vec_Q)**2\n",
    "        plt.hist(gstate,bins = 300,label = 'g',alpha = 0.5)\n",
    "        plt.hist(estate,bins = 300,label = 'e',alpha = 0.5)\n",
    "        plt.legend()\n",
    "        show()\n",
    "\n",
    "        th_min = min(gstate)\n",
    "        th_max = max(estate)\n",
    "        th_list = np.linspace(th_min,th_max,1000)\n",
    "\n",
    "        fidelity = [(sum(gstate<th)+sum(estate>th))/np.shape(gstate)[0]/2 for i,th in enumerate(th_list)]\n",
    "        print('max fidelity = ',max(fidelity)*2-1)\n",
    "        loc_opt = argmax(fidelity)\n",
    "\n",
    "        print('\\n rough estimation of n_th')\n",
    "        100*sum(gstate>th_list[argmax(fidelity)])/len(gstate)\n",
    "        \n",
    "        all_fidelity_MF_train[m] = max(fidelity)*2-1\n",
    "    \n",
    "    #### testing data #####\n",
    "    if True:\n",
    "        mean_Ig_test = test_X_new[:, 0, :, int(readout_loc): int(readout_loc + 400), 0].dot(weight_I[int(readout_loc):int(readout_loc + 400)])\n",
    "        mean_Qg_test = test_X_new[:, 0, :, int(readout_loc): int(readout_loc + 400), 1].dot(weight_Q[int(readout_loc):int(readout_loc + 400)])\n",
    "        mean_Ie_test = test_X_new[:, 1, :, int(readout_loc): int(readout_loc + 400), 0].dot(weight_I[int(readout_loc):int(readout_loc + 400)])\n",
    "        mean_Qe_test = test_X_new[:, 1, :, int(readout_loc): int(readout_loc + 400), 1].dot(weight_Q[int(readout_loc):int(readout_loc + 400)])\n",
    "\n",
    "        # IQ plot\n",
    "        ratio = 1.5\n",
    "        I_g = ratio*mean_Ig_test.flatten()/770/2048\n",
    "        Q_g = mean_Qg_test.flatten()/770/2048\n",
    "        I_e = ratio*mean_Ie_test.flatten()/770/2048\n",
    "        Q_e = mean_Qe_test.flatten()/770/2048\n",
    "        \n",
    "        gstate = (I_g - Ig)*vec_I + (Q_g - Qg)*vec_Q\n",
    "        estate = (I_e - Ig)*vec_I + (Q_e - Qg)*vec_Q\n",
    "        gstate = gstate / abs(vec_I+1j*vec_Q)**2\n",
    "        estate = estate / abs(vec_I+1j*vec_Q)**2\n",
    "        plt.hist(gstate,bins = 300,label = 'g',alpha = 0.5)\n",
    "        plt.hist(estate,bins = 300,label = 'e',alpha = 0.5)\n",
    "        plt.legend()\n",
    "        show()\n",
    "        \n",
    "        th = th_list[loc_opt]\n",
    "        test_fide = (sum(gstate<th)+sum(estate>th))/np.shape(gstate)[0]/2\n",
    "\n",
    "        all_fidelity_MF_test[m] = test_fide*2-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_fidelity_NN = np.array([0.95445, 0.95579, 0.9573, 0.95642, 0.9545, 0.95276, 0.94966, 0.94661])\n",
    "\n",
    "figure(figsize = (4,3), dpi = 150)\n",
    "plot(readout_loc_list, all_fidelity, '--', color = 'C0', label = 'TH method_Test')\n",
    "plot(readout_loc_list, all_fidelity_train, 'o', color = 'C0',label = 'TH method_Train')\n",
    "plot(readout_loc_list, all_fidelity_MF_test, '--', color = 'C1', label = 'MF method_Test')\n",
    "plot(readout_loc_list, all_fidelity_MF_train, 'o', color = 'C1', label = 'MF method_Train')\n",
    "plot(readout_loc_list, all_fidelity_NN*2-1, 'o-', color = 'C2', label = 'NN method')\n",
    "\n",
    "axvline(100, ls = '--', color = 'red')\n",
    "legend(loc = (1.2,.3))\n",
    "ylim(0.88,0.94)\n",
    "xlabel('Readout window location')\n",
    "ylabel('Flidelity')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outfile = '_FIG_EXP_train_window_loc_MF_TH_NN.npz'\n",
    "note = 'Training data on 0528, readout fidelity with moving readout window, window size = 400'\n",
    "\n",
    "np.savez(outfile, \n",
    "         readout_loc_list=readout_loc_list, \n",
    "         fidelity_NN = all_fidelity_NN*2-1, \n",
    "         fidelity_TH_train = all_fidelity_train,\n",
    "         fidelity_TH_test = all_fidelity,\n",
    "         fidelity_MF_train = all_fidelity_MF_train,\n",
    "         fidelity_MF_test = all_fidelity_MF_test,\n",
    "         note=note)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NN model\n",
    "\n",
    "Results are with smaller readout window (400) and the start location of the readout window (0, 50, 100, ..., 350)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encode(data):\n",
    "    y_encoded = np.zeros([data.shape[0],2], dtype=np.int32)\n",
    "    for idx, x in enumerate(data):\n",
    "        if x == 1:\n",
    "            y_encoded[idx][1] = 1\n",
    "        else:\n",
    "            y_encoded[idx][0] = 1\n",
    "    return y_encoded\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_val = data_X\n",
    "y_train_val = data_Y\n",
    "y_train_val = one_hot_encode(y_train_val)\n",
    "\n",
    "del data_X\n",
    "del data_Y\n",
    "\n",
    "X_test = test_X\n",
    "y_test = test_Y\n",
    "y_test = one_hot_encode(y_test)\n",
    "\n",
    "del test_X\n",
    "del test_Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"hyperparameters\"\"\"\n",
    "init_learning_rate = 1e-4\n",
    "validation_split = 0\n",
    "batch_size = 8192\n",
    "epochs = 50\n",
    "checkpoint_filename = \"multi-layer.h5\"\n",
    "input_shape = (len(X_train_val[0]),)\n",
    "start_window = 0\n",
    "end_window = 770\n",
    "\n",
    "window_start_locations = list(range(0, 350+1, 50))\n",
    "window_size = 400"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scan_readout_window(model, window_start_locations, window_size, callbacks):\n",
    "    all_fidelity = list()\n",
    "    all_accuracy = list()\n",
    "    all_e_accuracy = list()\n",
    "    all_g_accuracy = list()\n",
    "\n",
    "    for start_window in window_start_locations:\n",
    "        end_window = start_window + window_size\n",
    "\n",
    "        #########################\n",
    "        # 1. get readout window \n",
    "        #########################\n",
    "        X_train_window = X_train_val[:,start_window*2:end_window*2]\n",
    "        X_test_window = X_test[:,start_window*2:end_window*2]\n",
    "\n",
    "        #########################\n",
    "        # 2. start training \n",
    "        #########################\n",
    "        opt = Adam(learning_rate=init_learning_rate)\n",
    "        model.compile(\n",
    "            optimizer=opt, \n",
    "            loss=CategoricalCrossentropy(from_logits=True), \n",
    "            metrics=['accuracy']\n",
    "        )\n",
    "\n",
    "        history = model.fit(\n",
    "            X_train_window, \n",
    "            y_train_val, \n",
    "            batch_size=batch_size,\n",
    "            epochs=50, \n",
    "            validation_split=0.05, \n",
    "            shuffle=True, \n",
    "            callbacks=callbacks,\n",
    "            verbose=2\n",
    "        )\n",
    "\n",
    "        #########################\n",
    "        # 3. load checkpoint \n",
    "        #########################\n",
    "        co = {}\n",
    "        _add_supported_quantized_objects(co)\n",
    "        model = load_model(checkpoint_filename, custom_objects=co, compile=False)\n",
    "\n",
    "        #########################\n",
    "        # 4. compute fidelity \n",
    "        #########################\n",
    "        y_pred = model.predict(X_test_window)\n",
    "        test_acc = accuracy_score(np.argmax(y_test, axis=1), np.argmax(y_pred, axis=1))\n",
    "        print(\"Keras  Accuracy: {}\".format(test_acc))\n",
    "        all_accuracy.append(test_acc)\n",
    "        \n",
    "        # get ground and excited indices \n",
    "        e_indices = np.where(np.argmax(y_test, axis=1) == 1)[0]\n",
    "        g_indices = np.where(np.argmax(y_test, axis=1) == 0)[0]\n",
    "\n",
    "        # separate ground and excited samples \n",
    "        Xe_test = X_test_window[e_indices]\n",
    "        ye_test = np.argmax(y_test, axis=1)[e_indices]\n",
    "\n",
    "        Xg_test = X_test_window[g_indices]\n",
    "        yg_test = np.argmax(y_test, axis=1)[g_indices]\n",
    "\n",
    "        # compute total correct for excited state \n",
    "        ye_pred = model.predict(Xe_test)\n",
    "        e_accuracy = accuracy_score(ye_test, np.argmax(ye_pred, axis=1))\n",
    "\n",
    "        total_correct = (ye_test==np.argmax(ye_pred, axis=1)).astype(np.int8).sum()\n",
    "        total_incorrect = (ye_test!=np.argmax(ye_pred, axis=1)).astype(np.int8).sum()\n",
    "\n",
    "        print(\"Total correct:\", total_correct)\n",
    "        print(\"Total incorrect:\", total_incorrect)\n",
    "        print(\"Total samples:\", len(Xe_test) )\n",
    "        print(\"Keras Excited Accuracy: {}\".format(e_accuracy))\n",
    "\n",
    "        # compute total correct for ground state \n",
    "        yg_pred = model.predict(Xg_test)\n",
    "        g_accuracy = accuracy_score(yg_test, np.argmax(yg_pred, axis=1))\n",
    "\n",
    "        total_correct = (yg_test==np.argmax(yg_pred, axis=1)).astype(np.int8).sum()\n",
    "        total_incorrect = (yg_test!=np.argmax(yg_pred, axis=1)).astype(np.int8).sum()\n",
    "\n",
    "        print(\"Total correct:\", total_correct)\n",
    "        print(\"Total incorrect:\", total_incorrect)\n",
    "        print(\"Total samples:\", len(Xg_test) )\n",
    "        print(\"Keras Ground Accuracy: {}\".format(g_accuracy))\n",
    "\n",
    "        all_e_accuracy.append(e_accuracy)\n",
    "        all_g_accuracy.append(g_accuracy)\n",
    "\n",
    "        # compute fidelity \n",
    "        fidelity = 0.5*(e_accuracy + g_accuracy)\n",
    "        all_fidelity.append(fidelity)\n",
    "        print('\\n===================================')\n",
    "        print('Fidelity', fidelity)\n",
    "        print('===================================')\n",
    "\n",
    "    return all_accuracy, all_e_accuracy, all_g_accuracy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Large version\n",
    "\n",
    "<img src=\"../images/multi_layer_model.png\" alt=\"alt text\" width=\"50%\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_6 (Dense)             (None, 385)               308385    \n",
      "                                                                 \n",
      " batch_normalization_3 (Batc  (None, 385)              1540      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 2)                 772       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 310,697\n",
      "Trainable params: 309,927\n",
      "Non-trainable params: 770\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/50\n",
      "105/105 - 3s - loss: 0.3671 - accuracy: 0.8805 - val_loss: 0.2651 - val_accuracy: 0.9466 - lr: 1.0000e-04 - 3s/epoch - 26ms/step\n",
      "Epoch 2/50\n",
      "105/105 - 2s - loss: 0.2452 - accuracy: 0.9525 - val_loss: 0.2440 - val_accuracy: 0.9511 - lr: 1.0000e-04 - 2s/epoch - 19ms/step\n",
      "Epoch 3/50\n",
      "105/105 - 2s - loss: 0.2343 - accuracy: 0.9548 - val_loss: 0.2349 - val_accuracy: 0.9523 - lr: 1.0000e-04 - 2s/epoch - 19ms/step\n",
      "Epoch 4/50\n",
      "105/105 - 2s - loss: 0.2267 - accuracy: 0.9556 - val_loss: 0.2285 - val_accuracy: 0.9532 - lr: 1.0000e-04 - 2s/epoch - 19ms/step\n",
      "Epoch 5/50\n",
      "105/105 - 2s - loss: 0.2201 - accuracy: 0.9560 - val_loss: 0.2235 - val_accuracy: 0.9532 - lr: 1.0000e-04 - 2s/epoch - 19ms/step\n",
      "Epoch 6/50\n",
      "105/105 - 2s - loss: 0.2145 - accuracy: 0.9565 - val_loss: 0.2196 - val_accuracy: 0.9536 - lr: 1.0000e-04 - 2s/epoch - 19ms/step\n",
      "Epoch 7/50\n",
      "105/105 - 2s - loss: 0.2099 - accuracy: 0.9568 - val_loss: 0.2161 - val_accuracy: 0.9539 - lr: 1.0000e-04 - 2s/epoch - 19ms/step\n",
      "Epoch 8/50\n",
      "105/105 - 2s - loss: 0.2059 - accuracy: 0.9573 - val_loss: 0.2141 - val_accuracy: 0.9539 - lr: 1.0000e-04 - 2s/epoch - 19ms/step\n",
      "Epoch 9/50\n",
      "105/105 - 2s - loss: 0.2024 - accuracy: 0.9577 - val_loss: 0.2120 - val_accuracy: 0.9540 - lr: 1.0000e-04 - 2s/epoch - 19ms/step\n",
      "Epoch 10/50\n",
      "105/105 - 2s - loss: 0.1993 - accuracy: 0.9580 - val_loss: 0.2107 - val_accuracy: 0.9542 - lr: 1.0000e-04 - 2s/epoch - 19ms/step\n",
      "Epoch 11/50\n",
      "105/105 - 2s - loss: 0.1965 - accuracy: 0.9583 - val_loss: 0.2091 - val_accuracy: 0.9544 - lr: 1.0000e-04 - 2s/epoch - 19ms/step\n",
      "Epoch 12/50\n",
      "105/105 - 2s - loss: 0.1937 - accuracy: 0.9587 - val_loss: 0.2090 - val_accuracy: 0.9544 - lr: 1.0000e-05 - 2s/epoch - 19ms/step\n",
      "Epoch 13/50\n",
      "105/105 - 2s - loss: 0.1934 - accuracy: 0.9587 - val_loss: 0.2088 - val_accuracy: 0.9543 - lr: 1.0000e-05 - 2s/epoch - 19ms/step\n",
      "Epoch 14/50\n",
      "105/105 - 2s - loss: 0.1931 - accuracy: 0.9588 - val_loss: 0.2087 - val_accuracy: 0.9543 - lr: 1.0000e-05 - 2s/epoch - 19ms/step\n",
      "Epoch 15/50\n",
      "105/105 - 2s - loss: 0.1928 - accuracy: 0.9588 - val_loss: 0.2086 - val_accuracy: 0.9543 - lr: 1.0000e-05 - 2s/epoch - 19ms/step\n",
      "Epoch 16/50\n",
      "105/105 - 2s - loss: 0.1925 - accuracy: 0.9588 - val_loss: 0.2084 - val_accuracy: 0.9543 - lr: 1.0000e-05 - 2s/epoch - 19ms/step\n",
      "Epoch 17/50\n",
      "105/105 - 2s - loss: 0.1922 - accuracy: 0.9589 - val_loss: 0.2083 - val_accuracy: 0.9543 - lr: 1.0000e-05 - 2s/epoch - 19ms/step\n",
      "Epoch 18/50\n",
      "105/105 - 2s - loss: 0.1919 - accuracy: 0.9589 - val_loss: 0.2082 - val_accuracy: 0.9543 - lr: 1.0000e-05 - 2s/epoch - 19ms/step\n",
      "Epoch 19/50\n",
      "105/105 - 2s - loss: 0.1916 - accuracy: 0.9589 - val_loss: 0.2080 - val_accuracy: 0.9544 - lr: 1.0000e-05 - 2s/epoch - 19ms/step\n",
      "Epoch 20/50\n",
      "105/105 - 2s - loss: 0.1913 - accuracy: 0.9590 - val_loss: 0.2079 - val_accuracy: 0.9544 - lr: 1.0000e-05 - 2s/epoch - 19ms/step\n",
      "Epoch 21/50\n",
      "105/105 - 2s - loss: 0.1910 - accuracy: 0.9590 - val_loss: 0.2078 - val_accuracy: 0.9543 - lr: 1.0000e-05 - 2s/epoch - 19ms/step\n",
      "Epoch 22/50\n",
      "105/105 - 2s - loss: 0.1907 - accuracy: 0.9590 - val_loss: 0.2078 - val_accuracy: 0.9543 - lr: 1.0000e-06 - 2s/epoch - 19ms/step\n",
      "Epoch 23/50\n",
      "105/105 - 2s - loss: 0.1907 - accuracy: 0.9590 - val_loss: 0.2078 - val_accuracy: 0.9543 - lr: 1.0000e-06 - 2s/epoch - 19ms/step\n",
      "Epoch 24/50\n",
      "105/105 - 2s - loss: 0.1906 - accuracy: 0.9590 - val_loss: 0.2078 - val_accuracy: 0.9543 - lr: 1.0000e-06 - 2s/epoch - 19ms/step\n",
      "Epoch 25/50\n",
      "105/105 - 2s - loss: 0.1906 - accuracy: 0.9591 - val_loss: 0.2077 - val_accuracy: 0.9543 - lr: 1.0000e-06 - 2s/epoch - 19ms/step\n",
      "Epoch 26/50\n",
      "105/105 - 2s - loss: 0.1906 - accuracy: 0.9590 - val_loss: 0.2077 - val_accuracy: 0.9543 - lr: 1.0000e-06 - 2s/epoch - 19ms/step\n",
      "Epoch 27/50\n",
      "105/105 - 2s - loss: 0.1905 - accuracy: 0.9591 - val_loss: 0.2077 - val_accuracy: 0.9543 - lr: 1.0000e-06 - 2s/epoch - 19ms/step\n",
      "Epoch 28/50\n",
      "105/105 - 2s - loss: 0.1905 - accuracy: 0.9590 - val_loss: 0.2077 - val_accuracy: 0.9543 - lr: 1.0000e-06 - 2s/epoch - 20ms/step\n",
      "Epoch 29/50\n",
      "105/105 - 2s - loss: 0.1905 - accuracy: 0.9591 - val_loss: 0.2077 - val_accuracy: 0.9543 - lr: 1.0000e-06 - 2s/epoch - 19ms/step\n",
      "Epoch 30/50\n",
      "105/105 - 2s - loss: 0.1904 - accuracy: 0.9590 - val_loss: 0.2077 - val_accuracy: 0.9543 - lr: 1.0000e-06 - 2s/epoch - 19ms/step\n",
      "Epoch 31/50\n",
      "105/105 - 2s - loss: 0.1904 - accuracy: 0.9590 - val_loss: 0.2077 - val_accuracy: 0.9543 - lr: 1.0000e-06 - 2s/epoch - 19ms/step\n",
      "Epoch 32/50\n",
      "105/105 - 2s - loss: 0.1904 - accuracy: 0.9591 - val_loss: 0.2077 - val_accuracy: 0.9543 - lr: 1.0000e-07 - 2s/epoch - 19ms/step\n",
      "Epoch 33/50\n",
      "105/105 - 2s - loss: 0.1904 - accuracy: 0.9591 - val_loss: 0.2077 - val_accuracy: 0.9543 - lr: 1.0000e-07 - 2s/epoch - 19ms/step\n",
      "Epoch 34/50\n",
      "105/105 - 2s - loss: 0.1904 - accuracy: 0.9591 - val_loss: 0.2077 - val_accuracy: 0.9543 - lr: 1.0000e-07 - 2s/epoch - 19ms/step\n",
      "Epoch 35/50\n",
      "105/105 - 2s - loss: 0.1904 - accuracy: 0.9590 - val_loss: 0.2077 - val_accuracy: 0.9543 - lr: 1.0000e-07 - 2s/epoch - 19ms/step\n",
      "Epoch 36/50\n",
      "105/105 - 2s - loss: 0.1904 - accuracy: 0.9591 - val_loss: 0.2077 - val_accuracy: 0.9543 - lr: 1.0000e-07 - 2s/epoch - 19ms/step\n",
      "Epoch 37/50\n",
      "105/105 - 2s - loss: 0.1904 - accuracy: 0.9591 - val_loss: 0.2077 - val_accuracy: 0.9543 - lr: 1.0000e-07 - 2s/epoch - 19ms/step\n",
      "Epoch 38/50\n",
      "105/105 - 2s - loss: 0.1903 - accuracy: 0.9591 - val_loss: 0.2077 - val_accuracy: 0.9543 - lr: 1.0000e-07 - 2s/epoch - 19ms/step\n",
      "Epoch 39/50\n",
      "105/105 - 2s - loss: 0.1904 - accuracy: 0.9590 - val_loss: 0.2077 - val_accuracy: 0.9543 - lr: 1.0000e-07 - 2s/epoch - 19ms/step\n",
      "Epoch 40/50\n",
      "105/105 - 2s - loss: 0.1904 - accuracy: 0.9591 - val_loss: 0.2076 - val_accuracy: 0.9543 - lr: 1.0000e-07 - 2s/epoch - 19ms/step\n",
      "Epoch 41/50\n",
      "105/105 - 2s - loss: 0.1903 - accuracy: 0.9590 - val_loss: 0.2076 - val_accuracy: 0.9544 - lr: 1.0000e-07 - 2s/epoch - 19ms/step\n",
      "Epoch 42/50\n",
      "105/105 - 2s - loss: 0.1903 - accuracy: 0.9591 - val_loss: 0.2076 - val_accuracy: 0.9543 - lr: 1.0000e-08 - 2s/epoch - 19ms/step\n",
      "Epoch 43/50\n",
      "105/105 - 2s - loss: 0.1903 - accuracy: 0.9590 - val_loss: 0.2076 - val_accuracy: 0.9543 - lr: 1.0000e-08 - 2s/epoch - 19ms/step\n",
      "Epoch 44/50\n",
      "105/105 - 2s - loss: 0.1904 - accuracy: 0.9591 - val_loss: 0.2077 - val_accuracy: 0.9543 - lr: 1.0000e-08 - 2s/epoch - 19ms/step\n",
      "Epoch 45/50\n",
      "105/105 - 2s - loss: 0.1903 - accuracy: 0.9590 - val_loss: 0.2076 - val_accuracy: 0.9543 - lr: 1.0000e-08 - 2s/epoch - 19ms/step\n",
      "Epoch 46/50\n",
      "105/105 - 2s - loss: 0.1903 - accuracy: 0.9591 - val_loss: 0.2076 - val_accuracy: 0.9543 - lr: 1.0000e-08 - 2s/epoch - 19ms/step\n",
      "Epoch 47/50\n",
      "105/105 - 2s - loss: 0.1904 - accuracy: 0.9590 - val_loss: 0.2076 - val_accuracy: 0.9543 - lr: 1.0000e-08 - 2s/epoch - 19ms/step\n",
      "Epoch 48/50\n",
      "105/105 - 2s - loss: 0.1904 - accuracy: 0.9591 - val_loss: 0.2076 - val_accuracy: 0.9543 - lr: 1.0000e-08 - 2s/epoch - 19ms/step\n",
      "Epoch 49/50\n",
      "105/105 - 2s - loss: 0.1903 - accuracy: 0.9591 - val_loss: 0.2077 - val_accuracy: 0.9543 - lr: 1.0000e-08 - 2s/epoch - 19ms/step\n",
      "Epoch 50/50\n",
      "105/105 - 2s - loss: 0.1903 - accuracy: 0.9590 - val_loss: 0.2076 - val_accuracy: 0.9543 - lr: 1.0000e-08 - 2s/epoch - 19ms/step\n",
      "3125/3125 [==============================] - 6s 2ms/step\n",
      "Keras  Accuracy: 0.95585\n",
      "1563/1563 [==============================] - 3s 2ms/step\n",
      "Total correct: 47286\n",
      "Total incorrect: 2714\n",
      "Total samples: 50000\n",
      "Keras Excited Accuracy: 0.94572\n",
      "1563/1563 [==============================] - 3s 2ms/step\n",
      "Total correct: 48299\n",
      "Total incorrect: 1701\n",
      "Total samples: 50000\n",
      "Keras Ground Accuracy: 0.96598\n",
      "\n",
      "===================================\n",
      "Fidelity 0.95585\n",
      "===================================\n",
      "Epoch 1/50\n",
      "105/105 - 3s - loss: 0.2009 - accuracy: 0.9588 - val_loss: 0.2019 - val_accuracy: 0.9572 - lr: 1.0000e-04 - 3s/epoch - 26ms/step\n",
      "Epoch 2/50\n",
      "105/105 - 2s - loss: 0.1955 - accuracy: 0.9596 - val_loss: 0.2003 - val_accuracy: 0.9572 - lr: 1.0000e-04 - 2s/epoch - 19ms/step\n",
      "Epoch 3/50\n",
      "105/105 - 2s - loss: 0.1917 - accuracy: 0.9600 - val_loss: 0.1987 - val_accuracy: 0.9572 - lr: 1.0000e-04 - 2s/epoch - 19ms/step\n",
      "Epoch 4/50\n",
      "105/105 - 2s - loss: 0.1884 - accuracy: 0.9604 - val_loss: 0.1971 - val_accuracy: 0.9575 - lr: 1.0000e-04 - 2s/epoch - 20ms/step\n",
      "Epoch 5/50\n",
      "105/105 - 2s - loss: 0.1854 - accuracy: 0.9607 - val_loss: 0.1959 - val_accuracy: 0.9573 - lr: 1.0000e-04 - 2s/epoch - 20ms/step\n",
      "Epoch 6/50\n",
      "105/105 - 2s - loss: 0.1825 - accuracy: 0.9610 - val_loss: 0.1944 - val_accuracy: 0.9575 - lr: 1.0000e-04 - 2s/epoch - 19ms/step\n",
      "Epoch 7/50\n",
      "105/105 - 2s - loss: 0.1798 - accuracy: 0.9612 - val_loss: 0.1931 - val_accuracy: 0.9574 - lr: 1.0000e-04 - 2s/epoch - 19ms/step\n",
      "Epoch 8/50\n",
      "105/105 - 2s - loss: 0.1772 - accuracy: 0.9615 - val_loss: 0.1927 - val_accuracy: 0.9574 - lr: 1.0000e-04 - 2s/epoch - 19ms/step\n",
      "Epoch 9/50\n",
      "105/105 - 2s - loss: 0.1745 - accuracy: 0.9617 - val_loss: 0.1918 - val_accuracy: 0.9576 - lr: 1.0000e-04 - 2s/epoch - 20ms/step\n",
      "Epoch 10/50\n",
      "105/105 - 2s - loss: 0.1719 - accuracy: 0.9620 - val_loss: 0.1911 - val_accuracy: 0.9575 - lr: 1.0000e-04 - 2s/epoch - 20ms/step\n",
      "Epoch 11/50\n",
      "105/105 - 2s - loss: 0.1693 - accuracy: 0.9622 - val_loss: 0.1905 - val_accuracy: 0.9574 - lr: 1.0000e-04 - 2s/epoch - 19ms/step\n",
      "Epoch 12/50\n",
      "105/105 - 2s - loss: 0.1662 - accuracy: 0.9626 - val_loss: 0.1904 - val_accuracy: 0.9574 - lr: 1.0000e-05 - 2s/epoch - 20ms/step\n",
      "Epoch 13/50\n",
      "105/105 - 2s - loss: 0.1659 - accuracy: 0.9626 - val_loss: 0.1903 - val_accuracy: 0.9574 - lr: 1.0000e-05 - 2s/epoch - 19ms/step\n",
      "Epoch 14/50\n",
      "105/105 - 2s - loss: 0.1656 - accuracy: 0.9627 - val_loss: 0.1903 - val_accuracy: 0.9574 - lr: 1.0000e-05 - 2s/epoch - 20ms/step\n",
      "Epoch 15/50\n",
      "105/105 - 2s - loss: 0.1653 - accuracy: 0.9627 - val_loss: 0.1902 - val_accuracy: 0.9574 - lr: 1.0000e-05 - 2s/epoch - 19ms/step\n",
      "Epoch 16/50\n",
      "105/105 - 2s - loss: 0.1650 - accuracy: 0.9627 - val_loss: 0.1901 - val_accuracy: 0.9574 - lr: 1.0000e-05 - 2s/epoch - 19ms/step\n",
      "Epoch 17/50\n",
      "105/105 - 2s - loss: 0.1647 - accuracy: 0.9628 - val_loss: 0.1901 - val_accuracy: 0.9574 - lr: 1.0000e-05 - 2s/epoch - 19ms/step\n",
      "Epoch 18/50\n",
      "105/105 - 2s - loss: 0.1644 - accuracy: 0.9628 - val_loss: 0.1901 - val_accuracy: 0.9574 - lr: 1.0000e-05 - 2s/epoch - 20ms/step\n",
      "Epoch 19/50\n",
      "105/105 - 2s - loss: 0.1642 - accuracy: 0.9628 - val_loss: 0.1901 - val_accuracy: 0.9574 - lr: 1.0000e-05 - 2s/epoch - 19ms/step\n",
      "Epoch 20/50\n",
      "105/105 - 2s - loss: 0.1639 - accuracy: 0.9628 - val_loss: 0.1900 - val_accuracy: 0.9574 - lr: 1.0000e-05 - 2s/epoch - 20ms/step\n",
      "Epoch 21/50\n",
      "105/105 - 2s - loss: 0.1636 - accuracy: 0.9629 - val_loss: 0.1900 - val_accuracy: 0.9573 - lr: 1.0000e-05 - 2s/epoch - 19ms/step\n",
      "Epoch 22/50\n",
      "105/105 - 2s - loss: 0.1633 - accuracy: 0.9629 - val_loss: 0.1900 - val_accuracy: 0.9574 - lr: 1.0000e-06 - 2s/epoch - 20ms/step\n",
      "Epoch 23/50\n",
      "105/105 - 2s - loss: 0.1632 - accuracy: 0.9629 - val_loss: 0.1900 - val_accuracy: 0.9573 - lr: 1.0000e-06 - 2s/epoch - 19ms/step\n",
      "Epoch 24/50\n",
      "105/105 - 2s - loss: 0.1632 - accuracy: 0.9629 - val_loss: 0.1900 - val_accuracy: 0.9573 - lr: 1.0000e-06 - 2s/epoch - 19ms/step\n",
      "Epoch 25/50\n",
      "105/105 - 2s - loss: 0.1632 - accuracy: 0.9629 - val_loss: 0.1900 - val_accuracy: 0.9573 - lr: 1.0000e-06 - 2s/epoch - 20ms/step\n",
      "Epoch 26/50\n",
      "105/105 - 2s - loss: 0.1632 - accuracy: 0.9629 - val_loss: 0.1900 - val_accuracy: 0.9573 - lr: 1.0000e-06 - 2s/epoch - 19ms/step\n",
      "Epoch 27/50\n",
      "105/105 - 2s - loss: 0.1631 - accuracy: 0.9629 - val_loss: 0.1900 - val_accuracy: 0.9573 - lr: 1.0000e-06 - 2s/epoch - 19ms/step\n",
      "Epoch 28/50\n",
      "105/105 - 2s - loss: 0.1631 - accuracy: 0.9629 - val_loss: 0.1900 - val_accuracy: 0.9573 - lr: 1.0000e-06 - 2s/epoch - 19ms/step\n",
      "Epoch 29/50\n",
      "105/105 - 2s - loss: 0.1631 - accuracy: 0.9629 - val_loss: 0.1900 - val_accuracy: 0.9573 - lr: 1.0000e-06 - 2s/epoch - 19ms/step\n",
      "Epoch 30/50\n",
      "105/105 - 2s - loss: 0.1631 - accuracy: 0.9629 - val_loss: 0.1900 - val_accuracy: 0.9573 - lr: 1.0000e-06 - 2s/epoch - 20ms/step\n",
      "Epoch 31/50\n",
      "105/105 - 2s - loss: 0.1630 - accuracy: 0.9629 - val_loss: 0.1900 - val_accuracy: 0.9573 - lr: 1.0000e-06 - 2s/epoch - 19ms/step\n",
      "Epoch 32/50\n",
      "105/105 - 2s - loss: 0.1630 - accuracy: 0.9629 - val_loss: 0.1900 - val_accuracy: 0.9573 - lr: 1.0000e-07 - 2s/epoch - 19ms/step\n",
      "Epoch 33/50\n",
      "105/105 - 2s - loss: 0.1630 - accuracy: 0.9629 - val_loss: 0.1900 - val_accuracy: 0.9573 - lr: 1.0000e-07 - 2s/epoch - 20ms/step\n",
      "Epoch 34/50\n",
      "105/105 - 2s - loss: 0.1630 - accuracy: 0.9630 - val_loss: 0.1900 - val_accuracy: 0.9573 - lr: 1.0000e-07 - 2s/epoch - 20ms/step\n",
      "Epoch 35/50\n",
      "105/105 - 2s - loss: 0.1630 - accuracy: 0.9629 - val_loss: 0.1900 - val_accuracy: 0.9573 - lr: 1.0000e-07 - 2s/epoch - 20ms/step\n",
      "Epoch 36/50\n",
      "105/105 - 2s - loss: 0.1630 - accuracy: 0.9629 - val_loss: 0.1900 - val_accuracy: 0.9573 - lr: 1.0000e-07 - 2s/epoch - 20ms/step\n",
      "Epoch 37/50\n",
      "105/105 - 2s - loss: 0.1630 - accuracy: 0.9630 - val_loss: 0.1900 - val_accuracy: 0.9573 - lr: 1.0000e-07 - 2s/epoch - 20ms/step\n",
      "Epoch 38/50\n",
      "105/105 - 2s - loss: 0.1630 - accuracy: 0.9629 - val_loss: 0.1900 - val_accuracy: 0.9573 - lr: 1.0000e-07 - 2s/epoch - 20ms/step\n",
      "Epoch 39/50\n",
      "105/105 - 2s - loss: 0.1630 - accuracy: 0.9629 - val_loss: 0.1900 - val_accuracy: 0.9573 - lr: 1.0000e-07 - 2s/epoch - 20ms/step\n",
      "Epoch 40/50\n",
      "105/105 - 2s - loss: 0.1630 - accuracy: 0.9630 - val_loss: 0.1900 - val_accuracy: 0.9573 - lr: 1.0000e-07 - 2s/epoch - 20ms/step\n",
      "Epoch 41/50\n",
      "105/105 - 2s - loss: 0.1630 - accuracy: 0.9629 - val_loss: 0.1900 - val_accuracy: 0.9573 - lr: 1.0000e-07 - 2s/epoch - 19ms/step\n",
      "Epoch 42/50\n",
      "105/105 - 2s - loss: 0.1630 - accuracy: 0.9629 - val_loss: 0.1900 - val_accuracy: 0.9573 - lr: 1.0000e-08 - 2s/epoch - 20ms/step\n",
      "Epoch 43/50\n",
      "105/105 - 2s - loss: 0.1630 - accuracy: 0.9629 - val_loss: 0.1899 - val_accuracy: 0.9573 - lr: 1.0000e-08 - 2s/epoch - 20ms/step\n",
      "Epoch 44/50\n",
      "105/105 - 2s - loss: 0.1630 - accuracy: 0.9629 - val_loss: 0.1900 - val_accuracy: 0.9573 - lr: 1.0000e-08 - 2s/epoch - 20ms/step\n",
      "Epoch 45/50\n",
      "105/105 - 2s - loss: 0.1630 - accuracy: 0.9630 - val_loss: 0.1900 - val_accuracy: 0.9573 - lr: 1.0000e-08 - 2s/epoch - 20ms/step\n",
      "Epoch 46/50\n",
      "105/105 - 2s - loss: 0.1630 - accuracy: 0.9629 - val_loss: 0.1900 - val_accuracy: 0.9573 - lr: 1.0000e-08 - 2s/epoch - 19ms/step\n",
      "Epoch 47/50\n",
      "105/105 - 2s - loss: 0.1630 - accuracy: 0.9629 - val_loss: 0.1900 - val_accuracy: 0.9573 - lr: 1.0000e-08 - 2s/epoch - 20ms/step\n",
      "Epoch 48/50\n",
      "105/105 - 2s - loss: 0.1630 - accuracy: 0.9629 - val_loss: 0.1900 - val_accuracy: 0.9573 - lr: 1.0000e-08 - 2s/epoch - 20ms/step\n",
      "Epoch 49/50\n",
      "105/105 - 2s - loss: 0.1630 - accuracy: 0.9629 - val_loss: 0.1900 - val_accuracy: 0.9573 - lr: 1.0000e-08 - 2s/epoch - 20ms/step\n",
      "Epoch 50/50\n",
      "105/105 - 2s - loss: 0.1630 - accuracy: 0.9629 - val_loss: 0.1900 - val_accuracy: 0.9573 - lr: 1.0000e-08 - 2s/epoch - 19ms/step\n",
      "3125/3125 [==============================] - 5s 2ms/step\n",
      "Keras  Accuracy: 0.95929\n",
      "1563/1563 [==============================] - 3s 2ms/step\n",
      "Total correct: 47382\n",
      "Total incorrect: 2618\n",
      "Total samples: 50000\n",
      "Keras Excited Accuracy: 0.94764\n",
      "1563/1563 [==============================] - 3s 2ms/step\n",
      "Total correct: 48547\n",
      "Total incorrect: 1453\n",
      "Total samples: 50000\n",
      "Keras Ground Accuracy: 0.97094\n",
      "\n",
      "===================================\n",
      "Fidelity 0.95929\n",
      "===================================\n",
      "Epoch 1/50\n",
      "105/105 - 3s - loss: 0.1864 - accuracy: 0.9600 - val_loss: 0.1875 - val_accuracy: 0.9583 - lr: 1.0000e-04 - 3s/epoch - 29ms/step\n",
      "Epoch 2/50\n",
      "105/105 - 2s - loss: 0.1816 - accuracy: 0.9606 - val_loss: 0.1864 - val_accuracy: 0.9584 - lr: 1.0000e-04 - 2s/epoch - 19ms/step\n",
      "Epoch 3/50\n",
      "105/105 - 2s - loss: 0.1783 - accuracy: 0.9609 - val_loss: 0.1857 - val_accuracy: 0.9583 - lr: 1.0000e-04 - 2s/epoch - 19ms/step\n",
      "Epoch 4/50\n",
      "105/105 - 2s - loss: 0.1753 - accuracy: 0.9613 - val_loss: 0.1846 - val_accuracy: 0.9586 - lr: 1.0000e-04 - 2s/epoch - 19ms/step\n",
      "Epoch 5/50\n",
      "105/105 - 2s - loss: 0.1726 - accuracy: 0.9615 - val_loss: 0.1838 - val_accuracy: 0.9586 - lr: 1.0000e-04 - 2s/epoch - 19ms/step\n",
      "Epoch 6/50\n",
      "105/105 - 2s - loss: 0.1700 - accuracy: 0.9618 - val_loss: 0.1832 - val_accuracy: 0.9584 - lr: 1.0000e-04 - 2s/epoch - 19ms/step\n",
      "Epoch 7/50\n",
      "105/105 - 2s - loss: 0.1675 - accuracy: 0.9620 - val_loss: 0.1823 - val_accuracy: 0.9585 - lr: 1.0000e-04 - 2s/epoch - 19ms/step\n",
      "Epoch 8/50\n",
      "105/105 - 2s - loss: 0.1650 - accuracy: 0.9624 - val_loss: 0.1821 - val_accuracy: 0.9584 - lr: 1.0000e-04 - 2s/epoch - 19ms/step\n",
      "Epoch 9/50\n",
      "105/105 - 2s - loss: 0.1626 - accuracy: 0.9626 - val_loss: 0.1811 - val_accuracy: 0.9584 - lr: 1.0000e-04 - 2s/epoch - 19ms/step\n",
      "Epoch 10/50\n",
      "105/105 - 2s - loss: 0.1601 - accuracy: 0.9628 - val_loss: 0.1813 - val_accuracy: 0.9585 - lr: 1.0000e-04 - 2s/epoch - 19ms/step\n",
      "Epoch 11/50\n",
      "105/105 - 2s - loss: 0.1577 - accuracy: 0.9631 - val_loss: 0.1809 - val_accuracy: 0.9584 - lr: 1.0000e-04 - 2s/epoch - 19ms/step\n",
      "Epoch 12/50\n",
      "105/105 - 2s - loss: 0.1544 - accuracy: 0.9635 - val_loss: 0.1808 - val_accuracy: 0.9584 - lr: 1.0000e-05 - 2s/epoch - 19ms/step\n",
      "Epoch 13/50\n",
      "105/105 - 2s - loss: 0.1540 - accuracy: 0.9636 - val_loss: 0.1807 - val_accuracy: 0.9585 - lr: 1.0000e-05 - 2s/epoch - 19ms/step\n",
      "Epoch 14/50\n",
      "105/105 - 2s - loss: 0.1537 - accuracy: 0.9636 - val_loss: 0.1807 - val_accuracy: 0.9585 - lr: 1.0000e-05 - 2s/epoch - 19ms/step\n",
      "Epoch 15/50\n",
      "105/105 - 2s - loss: 0.1534 - accuracy: 0.9636 - val_loss: 0.1806 - val_accuracy: 0.9585 - lr: 1.0000e-05 - 2s/epoch - 19ms/step\n",
      "Epoch 16/50\n",
      "105/105 - 2s - loss: 0.1531 - accuracy: 0.9637 - val_loss: 0.1807 - val_accuracy: 0.9585 - lr: 1.0000e-05 - 2s/epoch - 19ms/step\n",
      "Epoch 17/50\n",
      "105/105 - 2s - loss: 0.1528 - accuracy: 0.9637 - val_loss: 0.1807 - val_accuracy: 0.9585 - lr: 1.0000e-05 - 2s/epoch - 19ms/step\n",
      "Epoch 18/50\n",
      "105/105 - 2s - loss: 0.1526 - accuracy: 0.9637 - val_loss: 0.1806 - val_accuracy: 0.9585 - lr: 1.0000e-05 - 2s/epoch - 19ms/step\n",
      "Epoch 19/50\n",
      "105/105 - 2s - loss: 0.1523 - accuracy: 0.9637 - val_loss: 0.1807 - val_accuracy: 0.9584 - lr: 1.0000e-05 - 2s/epoch - 19ms/step\n",
      "Epoch 20/50\n",
      "105/105 - 2s - loss: 0.1520 - accuracy: 0.9638 - val_loss: 0.1807 - val_accuracy: 0.9585 - lr: 1.0000e-05 - 2s/epoch - 19ms/step\n",
      "Epoch 21/50\n",
      "105/105 - 2s - loss: 0.1518 - accuracy: 0.9638 - val_loss: 0.1807 - val_accuracy: 0.9584 - lr: 1.0000e-05 - 2s/epoch - 19ms/step\n",
      "Epoch 22/50\n",
      "105/105 - 2s - loss: 0.1514 - accuracy: 0.9639 - val_loss: 0.1807 - val_accuracy: 0.9584 - lr: 1.0000e-06 - 2s/epoch - 19ms/step\n",
      "Epoch 23/50\n",
      "105/105 - 2s - loss: 0.1514 - accuracy: 0.9638 - val_loss: 0.1807 - val_accuracy: 0.9584 - lr: 1.0000e-06 - 2s/epoch - 19ms/step\n",
      "Epoch 24/50\n",
      "105/105 - 2s - loss: 0.1513 - accuracy: 0.9639 - val_loss: 0.1807 - val_accuracy: 0.9584 - lr: 1.0000e-06 - 2s/epoch - 19ms/step\n",
      "Epoch 25/50\n",
      "105/105 - 2s - loss: 0.1513 - accuracy: 0.9639 - val_loss: 0.1807 - val_accuracy: 0.9584 - lr: 1.0000e-06 - 2s/epoch - 19ms/step\n",
      "Epoch 26/50\n",
      "105/105 - 2s - loss: 0.1513 - accuracy: 0.9639 - val_loss: 0.1807 - val_accuracy: 0.9584 - lr: 1.0000e-06 - 2s/epoch - 18ms/step\n",
      "Epoch 27/50\n",
      "105/105 - 2s - loss: 0.1513 - accuracy: 0.9639 - val_loss: 0.1807 - val_accuracy: 0.9584 - lr: 1.0000e-06 - 2s/epoch - 19ms/step\n",
      "Epoch 28/50\n",
      "105/105 - 2s - loss: 0.1512 - accuracy: 0.9639 - val_loss: 0.1807 - val_accuracy: 0.9585 - lr: 1.0000e-06 - 2s/epoch - 19ms/step\n",
      "Epoch 29/50\n",
      "105/105 - 2s - loss: 0.1512 - accuracy: 0.9639 - val_loss: 0.1807 - val_accuracy: 0.9584 - lr: 1.0000e-06 - 2s/epoch - 19ms/step\n",
      "Epoch 30/50\n",
      "105/105 - 2s - loss: 0.1512 - accuracy: 0.9639 - val_loss: 0.1807 - val_accuracy: 0.9585 - lr: 1.0000e-06 - 2s/epoch - 19ms/step\n",
      "Epoch 31/50\n",
      "105/105 - 2s - loss: 0.1512 - accuracy: 0.9639 - val_loss: 0.1807 - val_accuracy: 0.9584 - lr: 1.0000e-06 - 2s/epoch - 19ms/step\n",
      "Epoch 32/50\n",
      "105/105 - 2s - loss: 0.1511 - accuracy: 0.9639 - val_loss: 0.1807 - val_accuracy: 0.9585 - lr: 1.0000e-07 - 2s/epoch - 20ms/step\n",
      "Epoch 33/50\n",
      "105/105 - 2s - loss: 0.1511 - accuracy: 0.9639 - val_loss: 0.1807 - val_accuracy: 0.9585 - lr: 1.0000e-07 - 2s/epoch - 19ms/step\n",
      "Epoch 34/50\n",
      "105/105 - 2s - loss: 0.1511 - accuracy: 0.9639 - val_loss: 0.1807 - val_accuracy: 0.9584 - lr: 1.0000e-07 - 2s/epoch - 20ms/step\n",
      "Epoch 35/50\n",
      "105/105 - 2s - loss: 0.1511 - accuracy: 0.9639 - val_loss: 0.1807 - val_accuracy: 0.9585 - lr: 1.0000e-07 - 2s/epoch - 21ms/step\n",
      "Epoch 36/50\n",
      "105/105 - 2s - loss: 0.1511 - accuracy: 0.9639 - val_loss: 0.1807 - val_accuracy: 0.9585 - lr: 1.0000e-07 - 2s/epoch - 21ms/step\n",
      "Epoch 37/50\n",
      "105/105 - 2s - loss: 0.1511 - accuracy: 0.9639 - val_loss: 0.1807 - val_accuracy: 0.9585 - lr: 1.0000e-07 - 2s/epoch - 19ms/step\n",
      "Epoch 38/50\n",
      "105/105 - 2s - loss: 0.1511 - accuracy: 0.9639 - val_loss: 0.1807 - val_accuracy: 0.9585 - lr: 1.0000e-07 - 2s/epoch - 19ms/step\n",
      "Epoch 39/50\n",
      "105/105 - 2s - loss: 0.1511 - accuracy: 0.9639 - val_loss: 0.1807 - val_accuracy: 0.9585 - lr: 1.0000e-07 - 2s/epoch - 19ms/step\n",
      "Epoch 40/50\n",
      "105/105 - 2s - loss: 0.1511 - accuracy: 0.9639 - val_loss: 0.1807 - val_accuracy: 0.9585 - lr: 1.0000e-07 - 2s/epoch - 19ms/step\n",
      "Epoch 41/50\n",
      "105/105 - 2s - loss: 0.1511 - accuracy: 0.9639 - val_loss: 0.1807 - val_accuracy: 0.9585 - lr: 1.0000e-07 - 2s/epoch - 19ms/step\n",
      "Epoch 42/50\n",
      "105/105 - 2s - loss: 0.1511 - accuracy: 0.9639 - val_loss: 0.1807 - val_accuracy: 0.9585 - lr: 1.0000e-08 - 2s/epoch - 19ms/step\n",
      "Epoch 43/50\n",
      "105/105 - 2s - loss: 0.1511 - accuracy: 0.9639 - val_loss: 0.1807 - val_accuracy: 0.9584 - lr: 1.0000e-08 - 2s/epoch - 19ms/step\n",
      "Epoch 44/50\n",
      "105/105 - 2s - loss: 0.1511 - accuracy: 0.9639 - val_loss: 0.1807 - val_accuracy: 0.9584 - lr: 1.0000e-08 - 2s/epoch - 19ms/step\n",
      "Epoch 45/50\n",
      "105/105 - 2s - loss: 0.1511 - accuracy: 0.9639 - val_loss: 0.1807 - val_accuracy: 0.9584 - lr: 1.0000e-08 - 2s/epoch - 18ms/step\n",
      "Epoch 46/50\n",
      "105/105 - 2s - loss: 0.1511 - accuracy: 0.9639 - val_loss: 0.1807 - val_accuracy: 0.9585 - lr: 1.0000e-08 - 2s/epoch - 18ms/step\n",
      "Epoch 47/50\n",
      "105/105 - 2s - loss: 0.1511 - accuracy: 0.9639 - val_loss: 0.1807 - val_accuracy: 0.9584 - lr: 1.0000e-08 - 2s/epoch - 18ms/step\n",
      "Epoch 48/50\n",
      "105/105 - 2s - loss: 0.1511 - accuracy: 0.9639 - val_loss: 0.1807 - val_accuracy: 0.9585 - lr: 1.0000e-08 - 2s/epoch - 19ms/step\n",
      "Epoch 49/50\n",
      "105/105 - 2s - loss: 0.1511 - accuracy: 0.9639 - val_loss: 0.1807 - val_accuracy: 0.9585 - lr: 1.0000e-08 - 2s/epoch - 19ms/step\n",
      "Epoch 50/50\n",
      "105/105 - 2s - loss: 0.1511 - accuracy: 0.9639 - val_loss: 0.1807 - val_accuracy: 0.9584 - lr: 1.0000e-08 - 2s/epoch - 19ms/step\n",
      "3125/3125 [==============================] - 6s 2ms/step\n",
      "Keras  Accuracy: 0.96012\n",
      "1563/1563 [==============================] - 3s 2ms/step\n",
      "Total correct: 47369\n",
      "Total incorrect: 2631\n",
      "Total samples: 50000\n",
      "Keras Excited Accuracy: 0.94738\n",
      "1563/1563 [==============================] - 3s 2ms/step\n",
      "Total correct: 48643\n",
      "Total incorrect: 1357\n",
      "Total samples: 50000\n",
      "Keras Ground Accuracy: 0.97286\n",
      "\n",
      "===================================\n",
      "Fidelity 0.96012\n",
      "===================================\n",
      "Epoch 1/50\n",
      "105/105 - 3s - loss: 0.1821 - accuracy: 0.9594 - val_loss: 0.1835 - val_accuracy: 0.9578 - lr: 1.0000e-04 - 3s/epoch - 25ms/step\n",
      "Epoch 2/50\n",
      "105/105 - 2s - loss: 0.1774 - accuracy: 0.9599 - val_loss: 0.1831 - val_accuracy: 0.9579 - lr: 1.0000e-04 - 2s/epoch - 18ms/step\n",
      "Epoch 3/50\n",
      "105/105 - 2s - loss: 0.1740 - accuracy: 0.9603 - val_loss: 0.1822 - val_accuracy: 0.9578 - lr: 1.0000e-04 - 2s/epoch - 18ms/step\n",
      "Epoch 4/50\n",
      "105/105 - 2s - loss: 0.1711 - accuracy: 0.9606 - val_loss: 0.1817 - val_accuracy: 0.9579 - lr: 1.0000e-04 - 2s/epoch - 19ms/step\n",
      "Epoch 5/50\n",
      "105/105 - 2s - loss: 0.1684 - accuracy: 0.9609 - val_loss: 0.1814 - val_accuracy: 0.9580 - lr: 1.0000e-04 - 2s/epoch - 19ms/step\n",
      "Epoch 6/50\n",
      "105/105 - 2s - loss: 0.1658 - accuracy: 0.9612 - val_loss: 0.1813 - val_accuracy: 0.9580 - lr: 1.0000e-04 - 2s/epoch - 19ms/step\n",
      "Epoch 7/50\n",
      "105/105 - 2s - loss: 0.1634 - accuracy: 0.9615 - val_loss: 0.1809 - val_accuracy: 0.9580 - lr: 1.0000e-04 - 2s/epoch - 19ms/step\n",
      "Epoch 8/50\n",
      "105/105 - 2s - loss: 0.1609 - accuracy: 0.9617 - val_loss: 0.1807 - val_accuracy: 0.9580 - lr: 1.0000e-04 - 2s/epoch - 19ms/step\n",
      "Epoch 9/50\n",
      "105/105 - 2s - loss: 0.1584 - accuracy: 0.9619 - val_loss: 0.1807 - val_accuracy: 0.9581 - lr: 1.0000e-04 - 2s/epoch - 19ms/step\n",
      "Epoch 10/50\n",
      "105/105 - 2s - loss: 0.1560 - accuracy: 0.9622 - val_loss: 0.1807 - val_accuracy: 0.9579 - lr: 1.0000e-04 - 2s/epoch - 18ms/step\n",
      "Epoch 11/50\n",
      "105/105 - 2s - loss: 0.1536 - accuracy: 0.9624 - val_loss: 0.1810 - val_accuracy: 0.9578 - lr: 1.0000e-04 - 2s/epoch - 19ms/step\n",
      "Epoch 12/50\n",
      "105/105 - 2s - loss: 0.1500 - accuracy: 0.9628 - val_loss: 0.1809 - val_accuracy: 0.9578 - lr: 1.0000e-05 - 2s/epoch - 19ms/step\n",
      "Epoch 13/50\n",
      "105/105 - 2s - loss: 0.1496 - accuracy: 0.9628 - val_loss: 0.1810 - val_accuracy: 0.9578 - lr: 1.0000e-05 - 2s/epoch - 19ms/step\n",
      "Epoch 14/50\n",
      "105/105 - 2s - loss: 0.1493 - accuracy: 0.9629 - val_loss: 0.1810 - val_accuracy: 0.9578 - lr: 1.0000e-05 - 2s/epoch - 19ms/step\n",
      "Epoch 15/50\n",
      "105/105 - 2s - loss: 0.1490 - accuracy: 0.9629 - val_loss: 0.1811 - val_accuracy: 0.9578 - lr: 1.0000e-05 - 2s/epoch - 19ms/step\n",
      "Epoch 16/50\n",
      "105/105 - 2s - loss: 0.1487 - accuracy: 0.9629 - val_loss: 0.1810 - val_accuracy: 0.9578 - lr: 1.0000e-05 - 2s/epoch - 19ms/step\n",
      "Epoch 17/50\n",
      "105/105 - 2s - loss: 0.1484 - accuracy: 0.9630 - val_loss: 0.1812 - val_accuracy: 0.9578 - lr: 1.0000e-05 - 2s/epoch - 19ms/step\n",
      "Epoch 18/50\n",
      "105/105 - 2s - loss: 0.1481 - accuracy: 0.9630 - val_loss: 0.1812 - val_accuracy: 0.9578 - lr: 1.0000e-05 - 2s/epoch - 19ms/step\n",
      "Epoch 19/50\n",
      "105/105 - 2s - loss: 0.1479 - accuracy: 0.9630 - val_loss: 0.1812 - val_accuracy: 0.9578 - lr: 1.0000e-05 - 2s/epoch - 19ms/step\n",
      "Epoch 20/50\n",
      "105/105 - 2s - loss: 0.1476 - accuracy: 0.9630 - val_loss: 0.1813 - val_accuracy: 0.9577 - lr: 1.0000e-05 - 2s/epoch - 19ms/step\n",
      "Epoch 21/50\n",
      "105/105 - 2s - loss: 0.1473 - accuracy: 0.9631 - val_loss: 0.1813 - val_accuracy: 0.9577 - lr: 1.0000e-05 - 2s/epoch - 19ms/step\n",
      "Epoch 22/50\n",
      "105/105 - 2s - loss: 0.1469 - accuracy: 0.9631 - val_loss: 0.1813 - val_accuracy: 0.9577 - lr: 1.0000e-06 - 2s/epoch - 19ms/step\n",
      "Epoch 23/50\n",
      "105/105 - 2s - loss: 0.1469 - accuracy: 0.9631 - val_loss: 0.1813 - val_accuracy: 0.9577 - lr: 1.0000e-06 - 2s/epoch - 18ms/step\n",
      "Epoch 24/50\n",
      "105/105 - 2s - loss: 0.1469 - accuracy: 0.9631 - val_loss: 0.1813 - val_accuracy: 0.9577 - lr: 1.0000e-06 - 2s/epoch - 19ms/step\n",
      "Epoch 25/50\n",
      "105/105 - 2s - loss: 0.1468 - accuracy: 0.9631 - val_loss: 0.1813 - val_accuracy: 0.9577 - lr: 1.0000e-06 - 2s/epoch - 19ms/step\n",
      "Epoch 26/50\n",
      "105/105 - 2s - loss: 0.1468 - accuracy: 0.9631 - val_loss: 0.1813 - val_accuracy: 0.9577 - lr: 1.0000e-06 - 2s/epoch - 19ms/step\n",
      "Epoch 27/50\n",
      "105/105 - 2s - loss: 0.1468 - accuracy: 0.9631 - val_loss: 0.1813 - val_accuracy: 0.9577 - lr: 1.0000e-06 - 2s/epoch - 19ms/step\n",
      "Epoch 28/50\n",
      "105/105 - 2s - loss: 0.1467 - accuracy: 0.9631 - val_loss: 0.1813 - val_accuracy: 0.9577 - lr: 1.0000e-06 - 2s/epoch - 19ms/step\n",
      "Epoch 29/50\n",
      "105/105 - 2s - loss: 0.1467 - accuracy: 0.9631 - val_loss: 0.1814 - val_accuracy: 0.9577 - lr: 1.0000e-06 - 2s/epoch - 19ms/step\n",
      "Epoch 30/50\n",
      "105/105 - 2s - loss: 0.1467 - accuracy: 0.9631 - val_loss: 0.1814 - val_accuracy: 0.9577 - lr: 1.0000e-06 - 2s/epoch - 18ms/step\n",
      "Epoch 31/50\n",
      "105/105 - 2s - loss: 0.1467 - accuracy: 0.9631 - val_loss: 0.1814 - val_accuracy: 0.9577 - lr: 1.0000e-06 - 2s/epoch - 19ms/step\n",
      "Epoch 32/50\n",
      "105/105 - 2s - loss: 0.1466 - accuracy: 0.9631 - val_loss: 0.1814 - val_accuracy: 0.9577 - lr: 1.0000e-07 - 2s/epoch - 19ms/step\n",
      "Epoch 33/50\n",
      "105/105 - 2s - loss: 0.1466 - accuracy: 0.9631 - val_loss: 0.1814 - val_accuracy: 0.9577 - lr: 1.0000e-07 - 2s/epoch - 19ms/step\n",
      "Epoch 34/50\n",
      "105/105 - 2s - loss: 0.1466 - accuracy: 0.9632 - val_loss: 0.1814 - val_accuracy: 0.9577 - lr: 1.0000e-07 - 2s/epoch - 19ms/step\n",
      "Epoch 35/50\n",
      "105/105 - 2s - loss: 0.1466 - accuracy: 0.9631 - val_loss: 0.1814 - val_accuracy: 0.9577 - lr: 1.0000e-07 - 2s/epoch - 19ms/step\n",
      "Epoch 36/50\n",
      "105/105 - 2s - loss: 0.1466 - accuracy: 0.9631 - val_loss: 0.1814 - val_accuracy: 0.9577 - lr: 1.0000e-07 - 2s/epoch - 19ms/step\n",
      "Epoch 37/50\n",
      "105/105 - 2s - loss: 0.1466 - accuracy: 0.9631 - val_loss: 0.1814 - val_accuracy: 0.9577 - lr: 1.0000e-07 - 2s/epoch - 19ms/step\n",
      "Epoch 38/50\n",
      "105/105 - 2s - loss: 0.1466 - accuracy: 0.9631 - val_loss: 0.1814 - val_accuracy: 0.9577 - lr: 1.0000e-07 - 2s/epoch - 19ms/step\n",
      "Epoch 39/50\n",
      "105/105 - 2s - loss: 0.1466 - accuracy: 0.9631 - val_loss: 0.1814 - val_accuracy: 0.9577 - lr: 1.0000e-07 - 2s/epoch - 19ms/step\n",
      "Epoch 40/50\n",
      "105/105 - 2s - loss: 0.1466 - accuracy: 0.9632 - val_loss: 0.1814 - val_accuracy: 0.9577 - lr: 1.0000e-07 - 2s/epoch - 19ms/step\n",
      "Epoch 41/50\n",
      "105/105 - 2s - loss: 0.1466 - accuracy: 0.9631 - val_loss: 0.1814 - val_accuracy: 0.9577 - lr: 1.0000e-07 - 2s/epoch - 19ms/step\n",
      "Epoch 42/50\n",
      "105/105 - 2s - loss: 0.1466 - accuracy: 0.9631 - val_loss: 0.1814 - val_accuracy: 0.9577 - lr: 1.0000e-08 - 2s/epoch - 19ms/step\n",
      "Epoch 43/50\n",
      "105/105 - 2s - loss: 0.1466 - accuracy: 0.9631 - val_loss: 0.1814 - val_accuracy: 0.9577 - lr: 1.0000e-08 - 2s/epoch - 19ms/step\n",
      "Epoch 44/50\n",
      "105/105 - 2s - loss: 0.1466 - accuracy: 0.9631 - val_loss: 0.1814 - val_accuracy: 0.9577 - lr: 1.0000e-08 - 2s/epoch - 19ms/step\n",
      "Epoch 45/50\n",
      "105/105 - 2s - loss: 0.1466 - accuracy: 0.9631 - val_loss: 0.1814 - val_accuracy: 0.9577 - lr: 1.0000e-08 - 2s/epoch - 19ms/step\n",
      "Epoch 46/50\n",
      "105/105 - 2s - loss: 0.1466 - accuracy: 0.9631 - val_loss: 0.1814 - val_accuracy: 0.9577 - lr: 1.0000e-08 - 2s/epoch - 18ms/step\n",
      "Epoch 47/50\n",
      "105/105 - 2s - loss: 0.1466 - accuracy: 0.9631 - val_loss: 0.1814 - val_accuracy: 0.9577 - lr: 1.0000e-08 - 2s/epoch - 19ms/step\n",
      "Epoch 48/50\n",
      "105/105 - 2s - loss: 0.1466 - accuracy: 0.9632 - val_loss: 0.1814 - val_accuracy: 0.9577 - lr: 1.0000e-08 - 2s/epoch - 19ms/step\n",
      "Epoch 49/50\n",
      "105/105 - 2s - loss: 0.1466 - accuracy: 0.9631 - val_loss: 0.1814 - val_accuracy: 0.9577 - lr: 1.0000e-08 - 2s/epoch - 19ms/step\n",
      "Epoch 50/50\n",
      "105/105 - 2s - loss: 0.1466 - accuracy: 0.9631 - val_loss: 0.1814 - val_accuracy: 0.9577 - lr: 1.0000e-08 - 2s/epoch - 18ms/step\n",
      "3125/3125 [==============================] - 6s 2ms/step\n",
      "Keras  Accuracy: 0.95924\n",
      "1563/1563 [==============================] - 3s 2ms/step\n",
      "Total correct: 47214\n",
      "Total incorrect: 2786\n",
      "Total samples: 50000\n",
      "Keras Excited Accuracy: 0.94428\n",
      "1563/1563 [==============================] - 3s 2ms/step\n",
      "Total correct: 48710\n",
      "Total incorrect: 1290\n",
      "Total samples: 50000\n",
      "Keras Ground Accuracy: 0.9742\n",
      "\n",
      "===================================\n",
      "Fidelity 0.95924\n",
      "===================================\n",
      "Epoch 1/50\n",
      "105/105 - 3s - loss: 0.1885 - accuracy: 0.9575 - val_loss: 0.1907 - val_accuracy: 0.9554 - lr: 1.0000e-04 - 3s/epoch - 25ms/step\n",
      "Epoch 2/50\n",
      "105/105 - 2s - loss: 0.1836 - accuracy: 0.9581 - val_loss: 0.1901 - val_accuracy: 0.9556 - lr: 1.0000e-04 - 2s/epoch - 19ms/step\n",
      "Epoch 3/50\n",
      "105/105 - 2s - loss: 0.1802 - accuracy: 0.9584 - val_loss: 0.1891 - val_accuracy: 0.9556 - lr: 1.0000e-04 - 2s/epoch - 19ms/step\n",
      "Epoch 4/50\n",
      "105/105 - 2s - loss: 0.1772 - accuracy: 0.9587 - val_loss: 0.1890 - val_accuracy: 0.9556 - lr: 1.0000e-04 - 2s/epoch - 19ms/step\n",
      "Epoch 5/50\n",
      "105/105 - 2s - loss: 0.1744 - accuracy: 0.9590 - val_loss: 0.1884 - val_accuracy: 0.9555 - lr: 1.0000e-04 - 2s/epoch - 19ms/step\n",
      "Epoch 6/50\n",
      "105/105 - 2s - loss: 0.1719 - accuracy: 0.9592 - val_loss: 0.1877 - val_accuracy: 0.9557 - lr: 1.0000e-04 - 2s/epoch - 19ms/step\n",
      "Epoch 7/50\n",
      "105/105 - 2s - loss: 0.1694 - accuracy: 0.9594 - val_loss: 0.1880 - val_accuracy: 0.9556 - lr: 1.0000e-04 - 2s/epoch - 19ms/step\n",
      "Epoch 8/50\n",
      "105/105 - 2s - loss: 0.1669 - accuracy: 0.9598 - val_loss: 0.1876 - val_accuracy: 0.9557 - lr: 1.0000e-04 - 2s/epoch - 19ms/step\n",
      "Epoch 9/50\n",
      "105/105 - 2s - loss: 0.1645 - accuracy: 0.9599 - val_loss: 0.1874 - val_accuracy: 0.9557 - lr: 1.0000e-04 - 2s/epoch - 19ms/step\n",
      "Epoch 10/50\n",
      "105/105 - 2s - loss: 0.1620 - accuracy: 0.9602 - val_loss: 0.1883 - val_accuracy: 0.9557 - lr: 1.0000e-04 - 2s/epoch - 19ms/step\n",
      "Epoch 11/50\n",
      "105/105 - 2s - loss: 0.1595 - accuracy: 0.9604 - val_loss: 0.1874 - val_accuracy: 0.9556 - lr: 1.0000e-04 - 2s/epoch - 19ms/step\n",
      "Epoch 12/50\n",
      "105/105 - 2s - loss: 0.1560 - accuracy: 0.9608 - val_loss: 0.1877 - val_accuracy: 0.9556 - lr: 1.0000e-05 - 2s/epoch - 19ms/step\n",
      "Epoch 13/50\n",
      "105/105 - 2s - loss: 0.1555 - accuracy: 0.9608 - val_loss: 0.1876 - val_accuracy: 0.9556 - lr: 1.0000e-05 - 2s/epoch - 19ms/step\n",
      "Epoch 14/50\n",
      "105/105 - 2s - loss: 0.1552 - accuracy: 0.9609 - val_loss: 0.1878 - val_accuracy: 0.9555 - lr: 1.0000e-05 - 2s/epoch - 19ms/step\n",
      "Epoch 15/50\n",
      "105/105 - 2s - loss: 0.1549 - accuracy: 0.9608 - val_loss: 0.1878 - val_accuracy: 0.9556 - lr: 1.0000e-05 - 2s/epoch - 19ms/step\n",
      "Epoch 16/50\n",
      "105/105 - 2s - loss: 0.1546 - accuracy: 0.9609 - val_loss: 0.1878 - val_accuracy: 0.9557 - lr: 1.0000e-05 - 2s/epoch - 19ms/step\n",
      "Epoch 17/50\n",
      "105/105 - 2s - loss: 0.1543 - accuracy: 0.9609 - val_loss: 0.1878 - val_accuracy: 0.9557 - lr: 1.0000e-05 - 2s/epoch - 19ms/step\n",
      "Epoch 18/50\n",
      "105/105 - 2s - loss: 0.1541 - accuracy: 0.9610 - val_loss: 0.1879 - val_accuracy: 0.9557 - lr: 1.0000e-05 - 2s/epoch - 19ms/step\n",
      "Epoch 19/50\n",
      "105/105 - 2s - loss: 0.1538 - accuracy: 0.9610 - val_loss: 0.1879 - val_accuracy: 0.9556 - lr: 1.0000e-05 - 2s/epoch - 19ms/step\n",
      "Epoch 20/50\n",
      "105/105 - 2s - loss: 0.1535 - accuracy: 0.9610 - val_loss: 0.1879 - val_accuracy: 0.9557 - lr: 1.0000e-05 - 2s/epoch - 19ms/step\n",
      "Epoch 21/50\n",
      "105/105 - 2s - loss: 0.1533 - accuracy: 0.9610 - val_loss: 0.1880 - val_accuracy: 0.9556 - lr: 1.0000e-05 - 2s/epoch - 19ms/step\n",
      "Epoch 22/50\n",
      "105/105 - 2s - loss: 0.1528 - accuracy: 0.9611 - val_loss: 0.1880 - val_accuracy: 0.9556 - lr: 1.0000e-06 - 2s/epoch - 19ms/step\n",
      "Epoch 23/50\n",
      "105/105 - 2s - loss: 0.1528 - accuracy: 0.9611 - val_loss: 0.1880 - val_accuracy: 0.9557 - lr: 1.0000e-06 - 2s/epoch - 19ms/step\n",
      "Epoch 24/50\n",
      "105/105 - 2s - loss: 0.1528 - accuracy: 0.9611 - val_loss: 0.1880 - val_accuracy: 0.9556 - lr: 1.0000e-06 - 2s/epoch - 19ms/step\n",
      "Epoch 25/50\n",
      "105/105 - 2s - loss: 0.1527 - accuracy: 0.9611 - val_loss: 0.1880 - val_accuracy: 0.9556 - lr: 1.0000e-06 - 2s/epoch - 19ms/step\n",
      "Epoch 26/50\n",
      "105/105 - 2s - loss: 0.1527 - accuracy: 0.9611 - val_loss: 0.1880 - val_accuracy: 0.9557 - lr: 1.0000e-06 - 2s/epoch - 19ms/step\n",
      "Epoch 27/50\n",
      "105/105 - 2s - loss: 0.1527 - accuracy: 0.9611 - val_loss: 0.1880 - val_accuracy: 0.9557 - lr: 1.0000e-06 - 2s/epoch - 19ms/step\n",
      "Epoch 28/50\n",
      "105/105 - 2s - loss: 0.1527 - accuracy: 0.9611 - val_loss: 0.1880 - val_accuracy: 0.9557 - lr: 1.0000e-06 - 2s/epoch - 19ms/step\n",
      "Epoch 29/50\n",
      "105/105 - 2s - loss: 0.1526 - accuracy: 0.9611 - val_loss: 0.1880 - val_accuracy: 0.9557 - lr: 1.0000e-06 - 2s/epoch - 19ms/step\n",
      "Epoch 30/50\n",
      "105/105 - 2s - loss: 0.1526 - accuracy: 0.9611 - val_loss: 0.1880 - val_accuracy: 0.9557 - lr: 1.0000e-06 - 2s/epoch - 19ms/step\n",
      "Epoch 31/50\n",
      "105/105 - 2s - loss: 0.1526 - accuracy: 0.9611 - val_loss: 0.1880 - val_accuracy: 0.9557 - lr: 1.0000e-06 - 2s/epoch - 19ms/step\n",
      "Epoch 32/50\n",
      "105/105 - 2s - loss: 0.1525 - accuracy: 0.9611 - val_loss: 0.1880 - val_accuracy: 0.9557 - lr: 1.0000e-07 - 2s/epoch - 19ms/step\n",
      "Epoch 33/50\n",
      "105/105 - 2s - loss: 0.1526 - accuracy: 0.9611 - val_loss: 0.1880 - val_accuracy: 0.9557 - lr: 1.0000e-07 - 2s/epoch - 19ms/step\n",
      "Epoch 34/50\n",
      "105/105 - 2s - loss: 0.1526 - accuracy: 0.9611 - val_loss: 0.1880 - val_accuracy: 0.9557 - lr: 1.0000e-07 - 2s/epoch - 19ms/step\n",
      "Epoch 35/50\n",
      "105/105 - 2s - loss: 0.1525 - accuracy: 0.9611 - val_loss: 0.1880 - val_accuracy: 0.9557 - lr: 1.0000e-07 - 2s/epoch - 19ms/step\n",
      "Epoch 36/50\n",
      "105/105 - 2s - loss: 0.1525 - accuracy: 0.9611 - val_loss: 0.1880 - val_accuracy: 0.9557 - lr: 1.0000e-07 - 2s/epoch - 19ms/step\n",
      "Epoch 37/50\n",
      "105/105 - 2s - loss: 0.1525 - accuracy: 0.9611 - val_loss: 0.1880 - val_accuracy: 0.9557 - lr: 1.0000e-07 - 2s/epoch - 19ms/step\n",
      "Epoch 38/50\n",
      "105/105 - 2s - loss: 0.1525 - accuracy: 0.9611 - val_loss: 0.1880 - val_accuracy: 0.9557 - lr: 1.0000e-07 - 2s/epoch - 19ms/step\n",
      "Epoch 39/50\n",
      "105/105 - 2s - loss: 0.1525 - accuracy: 0.9611 - val_loss: 0.1880 - val_accuracy: 0.9557 - lr: 1.0000e-07 - 2s/epoch - 19ms/step\n",
      "Epoch 40/50\n",
      "105/105 - 2s - loss: 0.1525 - accuracy: 0.9611 - val_loss: 0.1880 - val_accuracy: 0.9557 - lr: 1.0000e-07 - 2s/epoch - 19ms/step\n",
      "Epoch 41/50\n",
      "105/105 - 2s - loss: 0.1525 - accuracy: 0.9611 - val_loss: 0.1880 - val_accuracy: 0.9557 - lr: 1.0000e-07 - 2s/epoch - 19ms/step\n",
      "Epoch 42/50\n",
      "105/105 - 2s - loss: 0.1525 - accuracy: 0.9611 - val_loss: 0.1880 - val_accuracy: 0.9557 - lr: 1.0000e-08 - 2s/epoch - 19ms/step\n",
      "Epoch 43/50\n",
      "105/105 - 2s - loss: 0.1525 - accuracy: 0.9611 - val_loss: 0.1880 - val_accuracy: 0.9557 - lr: 1.0000e-08 - 2s/epoch - 19ms/step\n",
      "Epoch 44/50\n",
      "105/105 - 2s - loss: 0.1525 - accuracy: 0.9611 - val_loss: 0.1881 - val_accuracy: 0.9557 - lr: 1.0000e-08 - 2s/epoch - 20ms/step\n",
      "Epoch 45/50\n",
      "105/105 - 2s - loss: 0.1525 - accuracy: 0.9611 - val_loss: 0.1880 - val_accuracy: 0.9557 - lr: 1.0000e-08 - 2s/epoch - 20ms/step\n",
      "Epoch 46/50\n",
      "105/105 - 2s - loss: 0.1525 - accuracy: 0.9611 - val_loss: 0.1880 - val_accuracy: 0.9557 - lr: 1.0000e-08 - 2s/epoch - 20ms/step\n",
      "Epoch 47/50\n",
      "105/105 - 2s - loss: 0.1525 - accuracy: 0.9611 - val_loss: 0.1880 - val_accuracy: 0.9557 - lr: 1.0000e-08 - 2s/epoch - 20ms/step\n",
      "Epoch 48/50\n",
      "105/105 - 2s - loss: 0.1525 - accuracy: 0.9611 - val_loss: 0.1880 - val_accuracy: 0.9557 - lr: 1.0000e-08 - 2s/epoch - 19ms/step\n",
      "Epoch 49/50\n",
      "105/105 - 2s - loss: 0.1525 - accuracy: 0.9611 - val_loss: 0.1880 - val_accuracy: 0.9557 - lr: 1.0000e-08 - 2s/epoch - 19ms/step\n",
      "Epoch 50/50\n",
      "105/105 - 2s - loss: 0.1525 - accuracy: 0.9611 - val_loss: 0.1880 - val_accuracy: 0.9557 - lr: 1.0000e-08 - 2s/epoch - 19ms/step\n",
      "3125/3125 [==============================] - 6s 2ms/step\n",
      "Keras  Accuracy: 0.95666\n",
      "1563/1563 [==============================] - 3s 2ms/step\n",
      "Total correct: 46960\n",
      "Total incorrect: 3040\n",
      "Total samples: 50000\n",
      "Keras Excited Accuracy: 0.9392\n",
      "1563/1563 [==============================] - 3s 2ms/step\n",
      "Total correct: 48706\n",
      "Total incorrect: 1294\n",
      "Total samples: 50000\n",
      "Keras Ground Accuracy: 0.97412\n",
      "\n",
      "===================================\n",
      "Fidelity 0.9566600000000001\n",
      "===================================\n",
      "Epoch 1/50\n",
      "105/105 - 3s - loss: 0.1969 - accuracy: 0.9548 - val_loss: 0.1980 - val_accuracy: 0.9528 - lr: 1.0000e-04 - 3s/epoch - 26ms/step\n",
      "Epoch 2/50\n",
      "105/105 - 2s - loss: 0.1916 - accuracy: 0.9555 - val_loss: 0.1973 - val_accuracy: 0.9529 - lr: 1.0000e-04 - 2s/epoch - 19ms/step\n",
      "Epoch 3/50\n",
      "105/105 - 2s - loss: 0.1880 - accuracy: 0.9558 - val_loss: 0.1964 - val_accuracy: 0.9530 - lr: 1.0000e-04 - 2s/epoch - 19ms/step\n",
      "Epoch 4/50\n",
      "105/105 - 2s - loss: 0.1850 - accuracy: 0.9561 - val_loss: 0.1961 - val_accuracy: 0.9529 - lr: 1.0000e-04 - 2s/epoch - 19ms/step\n",
      "Epoch 5/50\n",
      "105/105 - 2s - loss: 0.1823 - accuracy: 0.9564 - val_loss: 0.1961 - val_accuracy: 0.9529 - lr: 1.0000e-04 - 2s/epoch - 19ms/step\n",
      "Epoch 6/50\n",
      "105/105 - 2s - loss: 0.1796 - accuracy: 0.9567 - val_loss: 0.1952 - val_accuracy: 0.9530 - lr: 1.0000e-04 - 2s/epoch - 19ms/step\n",
      "Epoch 7/50\n",
      "105/105 - 2s - loss: 0.1770 - accuracy: 0.9569 - val_loss: 0.1949 - val_accuracy: 0.9529 - lr: 1.0000e-04 - 2s/epoch - 19ms/step\n",
      "Epoch 8/50\n",
      "105/105 - 2s - loss: 0.1746 - accuracy: 0.9571 - val_loss: 0.1948 - val_accuracy: 0.9527 - lr: 1.0000e-04 - 2s/epoch - 20ms/step\n",
      "Epoch 9/50\n",
      "105/105 - 2s - loss: 0.1721 - accuracy: 0.9573 - val_loss: 0.1947 - val_accuracy: 0.9530 - lr: 1.0000e-04 - 2s/epoch - 20ms/step\n",
      "Epoch 10/50\n",
      "105/105 - 2s - loss: 0.1696 - accuracy: 0.9576 - val_loss: 0.1949 - val_accuracy: 0.9528 - lr: 1.0000e-04 - 2s/epoch - 19ms/step\n",
      "Epoch 11/50\n",
      "105/105 - 2s - loss: 0.1672 - accuracy: 0.9578 - val_loss: 0.1947 - val_accuracy: 0.9526 - lr: 1.0000e-04 - 2s/epoch - 20ms/step\n",
      "Epoch 12/50\n",
      "105/105 - 2s - loss: 0.1636 - accuracy: 0.9581 - val_loss: 0.1947 - val_accuracy: 0.9526 - lr: 1.0000e-05 - 2s/epoch - 19ms/step\n",
      "Epoch 13/50\n",
      "105/105 - 2s - loss: 0.1632 - accuracy: 0.9582 - val_loss: 0.1947 - val_accuracy: 0.9526 - lr: 1.0000e-05 - 2s/epoch - 19ms/step\n",
      "Epoch 14/50\n",
      "105/105 - 2s - loss: 0.1629 - accuracy: 0.9582 - val_loss: 0.1947 - val_accuracy: 0.9526 - lr: 1.0000e-05 - 2s/epoch - 19ms/step\n",
      "Epoch 15/50\n",
      "105/105 - 2s - loss: 0.1625 - accuracy: 0.9582 - val_loss: 0.1948 - val_accuracy: 0.9526 - lr: 1.0000e-05 - 2s/epoch - 19ms/step\n",
      "Epoch 16/50\n",
      "105/105 - 2s - loss: 0.1622 - accuracy: 0.9583 - val_loss: 0.1947 - val_accuracy: 0.9526 - lr: 1.0000e-05 - 2s/epoch - 19ms/step\n",
      "Epoch 17/50\n",
      "105/105 - 2s - loss: 0.1620 - accuracy: 0.9583 - val_loss: 0.1948 - val_accuracy: 0.9526 - lr: 1.0000e-05 - 2s/epoch - 19ms/step\n",
      "Epoch 18/50\n",
      "105/105 - 2s - loss: 0.1617 - accuracy: 0.9583 - val_loss: 0.1948 - val_accuracy: 0.9526 - lr: 1.0000e-05 - 2s/epoch - 19ms/step\n",
      "Epoch 19/50\n",
      "105/105 - 2s - loss: 0.1614 - accuracy: 0.9583 - val_loss: 0.1948 - val_accuracy: 0.9526 - lr: 1.0000e-05 - 2s/epoch - 19ms/step\n",
      "Epoch 20/50\n",
      "105/105 - 2s - loss: 0.1612 - accuracy: 0.9584 - val_loss: 0.1949 - val_accuracy: 0.9526 - lr: 1.0000e-05 - 2s/epoch - 19ms/step\n",
      "Epoch 21/50\n",
      "105/105 - 2s - loss: 0.1609 - accuracy: 0.9584 - val_loss: 0.1949 - val_accuracy: 0.9526 - lr: 1.0000e-05 - 2s/epoch - 19ms/step\n",
      "Epoch 22/50\n",
      "105/105 - 2s - loss: 0.1605 - accuracy: 0.9584 - val_loss: 0.1949 - val_accuracy: 0.9526 - lr: 1.0000e-06 - 2s/epoch - 19ms/step\n",
      "Epoch 23/50\n",
      "105/105 - 2s - loss: 0.1604 - accuracy: 0.9584 - val_loss: 0.1949 - val_accuracy: 0.9526 - lr: 1.0000e-06 - 2s/epoch - 19ms/step\n",
      "Epoch 24/50\n",
      "105/105 - 2s - loss: 0.1604 - accuracy: 0.9584 - val_loss: 0.1949 - val_accuracy: 0.9526 - lr: 1.0000e-06 - 2s/epoch - 19ms/step\n",
      "Epoch 25/50\n",
      "105/105 - 2s - loss: 0.1604 - accuracy: 0.9584 - val_loss: 0.1949 - val_accuracy: 0.9526 - lr: 1.0000e-06 - 2s/epoch - 20ms/step\n",
      "Epoch 26/50\n",
      "105/105 - 2s - loss: 0.1604 - accuracy: 0.9584 - val_loss: 0.1950 - val_accuracy: 0.9526 - lr: 1.0000e-06 - 2s/epoch - 19ms/step\n",
      "Epoch 27/50\n",
      "105/105 - 2s - loss: 0.1603 - accuracy: 0.9584 - val_loss: 0.1949 - val_accuracy: 0.9526 - lr: 1.0000e-06 - 2s/epoch - 19ms/step\n",
      "Epoch 28/50\n",
      "105/105 - 2s - loss: 0.1603 - accuracy: 0.9585 - val_loss: 0.1950 - val_accuracy: 0.9526 - lr: 1.0000e-06 - 2s/epoch - 20ms/step\n",
      "Epoch 29/50\n",
      "105/105 - 2s - loss: 0.1603 - accuracy: 0.9584 - val_loss: 0.1949 - val_accuracy: 0.9526 - lr: 1.0000e-06 - 2s/epoch - 19ms/step\n",
      "Epoch 30/50\n",
      "105/105 - 2s - loss: 0.1602 - accuracy: 0.9584 - val_loss: 0.1950 - val_accuracy: 0.9526 - lr: 1.0000e-06 - 2s/epoch - 19ms/step\n",
      "Epoch 31/50\n",
      "105/105 - 2s - loss: 0.1602 - accuracy: 0.9585 - val_loss: 0.1949 - val_accuracy: 0.9526 - lr: 1.0000e-06 - 2s/epoch - 19ms/step\n",
      "Epoch 32/50\n",
      "105/105 - 2s - loss: 0.1602 - accuracy: 0.9584 - val_loss: 0.1950 - val_accuracy: 0.9526 - lr: 1.0000e-07 - 2s/epoch - 20ms/step\n",
      "Epoch 33/50\n",
      "105/105 - 2s - loss: 0.1602 - accuracy: 0.9584 - val_loss: 0.1950 - val_accuracy: 0.9525 - lr: 1.0000e-07 - 2s/epoch - 19ms/step\n",
      "Epoch 34/50\n",
      "105/105 - 2s - loss: 0.1602 - accuracy: 0.9584 - val_loss: 0.1950 - val_accuracy: 0.9526 - lr: 1.0000e-07 - 2s/epoch - 20ms/step\n",
      "Epoch 35/50\n",
      "105/105 - 2s - loss: 0.1602 - accuracy: 0.9584 - val_loss: 0.1950 - val_accuracy: 0.9526 - lr: 1.0000e-07 - 2s/epoch - 19ms/step\n",
      "Epoch 36/50\n",
      "105/105 - 2s - loss: 0.1602 - accuracy: 0.9584 - val_loss: 0.1950 - val_accuracy: 0.9525 - lr: 1.0000e-07 - 2s/epoch - 19ms/step\n",
      "Epoch 37/50\n",
      "105/105 - 2s - loss: 0.1602 - accuracy: 0.9585 - val_loss: 0.1950 - val_accuracy: 0.9526 - lr: 1.0000e-07 - 2s/epoch - 19ms/step\n",
      "Epoch 38/50\n",
      "105/105 - 2s - loss: 0.1601 - accuracy: 0.9585 - val_loss: 0.1950 - val_accuracy: 0.9526 - lr: 1.0000e-07 - 2s/epoch - 19ms/step\n",
      "Epoch 39/50\n",
      "105/105 - 2s - loss: 0.1602 - accuracy: 0.9584 - val_loss: 0.1950 - val_accuracy: 0.9526 - lr: 1.0000e-07 - 2s/epoch - 19ms/step\n",
      "Epoch 40/50\n",
      "105/105 - 2s - loss: 0.1602 - accuracy: 0.9585 - val_loss: 0.1950 - val_accuracy: 0.9526 - lr: 1.0000e-07 - 2s/epoch - 19ms/step\n",
      "Epoch 41/50\n",
      "105/105 - 2s - loss: 0.1602 - accuracy: 0.9585 - val_loss: 0.1950 - val_accuracy: 0.9526 - lr: 1.0000e-07 - 2s/epoch - 19ms/step\n",
      "Epoch 42/50\n",
      "105/105 - 2s - loss: 0.1601 - accuracy: 0.9584 - val_loss: 0.1950 - val_accuracy: 0.9526 - lr: 1.0000e-08 - 2s/epoch - 19ms/step\n",
      "Epoch 43/50\n",
      "105/105 - 2s - loss: 0.1602 - accuracy: 0.9585 - val_loss: 0.1950 - val_accuracy: 0.9526 - lr: 1.0000e-08 - 2s/epoch - 19ms/step\n",
      "Epoch 44/50\n",
      "105/105 - 2s - loss: 0.1601 - accuracy: 0.9584 - val_loss: 0.1950 - val_accuracy: 0.9525 - lr: 1.0000e-08 - 2s/epoch - 19ms/step\n",
      "Epoch 45/50\n",
      "105/105 - 2s - loss: 0.1601 - accuracy: 0.9585 - val_loss: 0.1950 - val_accuracy: 0.9526 - lr: 1.0000e-08 - 2s/epoch - 19ms/step\n",
      "Epoch 46/50\n",
      "105/105 - 2s - loss: 0.1602 - accuracy: 0.9584 - val_loss: 0.1950 - val_accuracy: 0.9526 - lr: 1.0000e-08 - 2s/epoch - 19ms/step\n",
      "Epoch 47/50\n",
      "105/105 - 2s - loss: 0.1602 - accuracy: 0.9584 - val_loss: 0.1950 - val_accuracy: 0.9525 - lr: 1.0000e-08 - 2s/epoch - 19ms/step\n",
      "Epoch 48/50\n",
      "105/105 - 2s - loss: 0.1601 - accuracy: 0.9584 - val_loss: 0.1950 - val_accuracy: 0.9525 - lr: 1.0000e-08 - 2s/epoch - 19ms/step\n",
      "Epoch 49/50\n",
      "105/105 - 2s - loss: 0.1601 - accuracy: 0.9584 - val_loss: 0.1950 - val_accuracy: 0.9525 - lr: 1.0000e-08 - 2s/epoch - 19ms/step\n",
      "Epoch 50/50\n",
      "105/105 - 2s - loss: 0.1602 - accuracy: 0.9584 - val_loss: 0.1949 - val_accuracy: 0.9526 - lr: 1.0000e-08 - 2s/epoch - 19ms/step\n",
      "3125/3125 [==============================] - 5s 2ms/step\n",
      "Keras  Accuracy: 0.95417\n",
      "1563/1563 [==============================] - 3s 2ms/step\n",
      "Total correct: 46684\n",
      "Total incorrect: 3316\n",
      "Total samples: 50000\n",
      "Keras Excited Accuracy: 0.93368\n",
      "1563/1563 [==============================] - 3s 2ms/step\n",
      "Total correct: 48733\n",
      "Total incorrect: 1267\n",
      "Total samples: 50000\n",
      "Keras Ground Accuracy: 0.97466\n",
      "\n",
      "===================================\n",
      "Fidelity 0.95417\n",
      "===================================\n",
      "Epoch 1/50\n",
      "105/105 - 3s - loss: 0.2054 - accuracy: 0.9521 - val_loss: 0.2070 - val_accuracy: 0.9501 - lr: 1.0000e-04 - 3s/epoch - 25ms/step\n",
      "Epoch 2/50\n",
      "105/105 - 2s - loss: 0.2000 - accuracy: 0.9527 - val_loss: 0.2060 - val_accuracy: 0.9501 - lr: 1.0000e-04 - 2s/epoch - 19ms/step\n",
      "Epoch 3/50\n",
      "105/105 - 2s - loss: 0.1964 - accuracy: 0.9531 - val_loss: 0.2050 - val_accuracy: 0.9501 - lr: 1.0000e-04 - 2s/epoch - 19ms/step\n",
      "Epoch 4/50\n",
      "105/105 - 2s - loss: 0.1933 - accuracy: 0.9534 - val_loss: 0.2038 - val_accuracy: 0.9502 - lr: 1.0000e-04 - 2s/epoch - 19ms/step\n",
      "Epoch 5/50\n",
      "105/105 - 2s - loss: 0.1905 - accuracy: 0.9537 - val_loss: 0.2035 - val_accuracy: 0.9501 - lr: 1.0000e-04 - 2s/epoch - 19ms/step\n",
      "Epoch 6/50\n",
      "105/105 - 2s - loss: 0.1878 - accuracy: 0.9539 - val_loss: 0.2033 - val_accuracy: 0.9499 - lr: 1.0000e-04 - 2s/epoch - 19ms/step\n",
      "Epoch 7/50\n",
      "105/105 - 2s - loss: 0.1852 - accuracy: 0.9542 - val_loss: 0.2026 - val_accuracy: 0.9502 - lr: 1.0000e-04 - 2s/epoch - 19ms/step\n",
      "Epoch 8/50\n",
      "105/105 - 2s - loss: 0.1828 - accuracy: 0.9544 - val_loss: 0.2029 - val_accuracy: 0.9500 - lr: 1.0000e-04 - 2s/epoch - 18ms/step\n",
      "Epoch 9/50\n",
      "105/105 - 2s - loss: 0.1803 - accuracy: 0.9545 - val_loss: 0.2030 - val_accuracy: 0.9499 - lr: 1.0000e-04 - 2s/epoch - 18ms/step\n",
      "Epoch 10/50\n",
      "105/105 - 2s - loss: 0.1778 - accuracy: 0.9547 - val_loss: 0.2026 - val_accuracy: 0.9499 - lr: 1.0000e-04 - 2s/epoch - 18ms/step\n",
      "Epoch 11/50\n",
      "105/105 - 2s - loss: 0.1753 - accuracy: 0.9550 - val_loss: 0.2026 - val_accuracy: 0.9498 - lr: 1.0000e-04 - 2s/epoch - 19ms/step\n",
      "Epoch 12/50\n",
      "105/105 - 2s - loss: 0.1717 - accuracy: 0.9553 - val_loss: 0.2026 - val_accuracy: 0.9498 - lr: 1.0000e-05 - 2s/epoch - 19ms/step\n",
      "Epoch 13/50\n",
      "105/105 - 2s - loss: 0.1712 - accuracy: 0.9553 - val_loss: 0.2026 - val_accuracy: 0.9498 - lr: 1.0000e-05 - 2s/epoch - 19ms/step\n",
      "Epoch 14/50\n",
      "105/105 - 2s - loss: 0.1709 - accuracy: 0.9554 - val_loss: 0.2025 - val_accuracy: 0.9498 - lr: 1.0000e-05 - 2s/epoch - 19ms/step\n",
      "Epoch 15/50\n",
      "105/105 - 2s - loss: 0.1706 - accuracy: 0.9554 - val_loss: 0.2025 - val_accuracy: 0.9497 - lr: 1.0000e-05 - 2s/epoch - 19ms/step\n",
      "Epoch 16/50\n",
      "105/105 - 2s - loss: 0.1703 - accuracy: 0.9555 - val_loss: 0.2025 - val_accuracy: 0.9497 - lr: 1.0000e-05 - 2s/epoch - 19ms/step\n",
      "Epoch 17/50\n",
      "105/105 - 2s - loss: 0.1700 - accuracy: 0.9555 - val_loss: 0.2026 - val_accuracy: 0.9497 - lr: 1.0000e-05 - 2s/epoch - 19ms/step\n",
      "Epoch 18/50\n",
      "105/105 - 2s - loss: 0.1697 - accuracy: 0.9555 - val_loss: 0.2026 - val_accuracy: 0.9497 - lr: 1.0000e-05 - 2s/epoch - 19ms/step\n",
      "Epoch 19/50\n",
      "105/105 - 2s - loss: 0.1694 - accuracy: 0.9555 - val_loss: 0.2026 - val_accuracy: 0.9498 - lr: 1.0000e-05 - 2s/epoch - 19ms/step\n",
      "Epoch 20/50\n",
      "105/105 - 2s - loss: 0.1692 - accuracy: 0.9555 - val_loss: 0.2027 - val_accuracy: 0.9498 - lr: 1.0000e-05 - 2s/epoch - 19ms/step\n",
      "Epoch 21/50\n",
      "105/105 - 2s - loss: 0.1689 - accuracy: 0.9556 - val_loss: 0.2027 - val_accuracy: 0.9498 - lr: 1.0000e-05 - 2s/epoch - 19ms/step\n",
      "Epoch 22/50\n",
      "105/105 - 2s - loss: 0.1685 - accuracy: 0.9556 - val_loss: 0.2027 - val_accuracy: 0.9498 - lr: 1.0000e-06 - 2s/epoch - 19ms/step\n",
      "Epoch 23/50\n",
      "105/105 - 2s - loss: 0.1684 - accuracy: 0.9556 - val_loss: 0.2027 - val_accuracy: 0.9498 - lr: 1.0000e-06 - 2s/epoch - 19ms/step\n",
      "Epoch 24/50\n",
      "105/105 - 2s - loss: 0.1684 - accuracy: 0.9556 - val_loss: 0.2027 - val_accuracy: 0.9498 - lr: 1.0000e-06 - 2s/epoch - 19ms/step\n",
      "Epoch 25/50\n",
      "105/105 - 2s - loss: 0.1684 - accuracy: 0.9556 - val_loss: 0.2027 - val_accuracy: 0.9498 - lr: 1.0000e-06 - 2s/epoch - 19ms/step\n",
      "Epoch 26/50\n",
      "105/105 - 2s - loss: 0.1684 - accuracy: 0.9556 - val_loss: 0.2027 - val_accuracy: 0.9498 - lr: 1.0000e-06 - 2s/epoch - 19ms/step\n",
      "Epoch 27/50\n",
      "105/105 - 2s - loss: 0.1683 - accuracy: 0.9556 - val_loss: 0.2027 - val_accuracy: 0.9498 - lr: 1.0000e-06 - 2s/epoch - 19ms/step\n",
      "Epoch 28/50\n",
      "105/105 - 2s - loss: 0.1683 - accuracy: 0.9556 - val_loss: 0.2027 - val_accuracy: 0.9498 - lr: 1.0000e-06 - 2s/epoch - 19ms/step\n",
      "Epoch 29/50\n",
      "105/105 - 2s - loss: 0.1683 - accuracy: 0.9556 - val_loss: 0.2027 - val_accuracy: 0.9498 - lr: 1.0000e-06 - 2s/epoch - 19ms/step\n",
      "Epoch 30/50\n",
      "105/105 - 2s - loss: 0.1683 - accuracy: 0.9556 - val_loss: 0.2027 - val_accuracy: 0.9498 - lr: 1.0000e-06 - 2s/epoch - 19ms/step\n",
      "Epoch 31/50\n",
      "105/105 - 2s - loss: 0.1682 - accuracy: 0.9556 - val_loss: 0.2028 - val_accuracy: 0.9498 - lr: 1.0000e-06 - 2s/epoch - 19ms/step\n",
      "Epoch 32/50\n",
      "105/105 - 2s - loss: 0.1682 - accuracy: 0.9556 - val_loss: 0.2028 - val_accuracy: 0.9498 - lr: 1.0000e-07 - 2s/epoch - 19ms/step\n",
      "Epoch 33/50\n",
      "105/105 - 2s - loss: 0.1682 - accuracy: 0.9556 - val_loss: 0.2028 - val_accuracy: 0.9498 - lr: 1.0000e-07 - 2s/epoch - 19ms/step\n",
      "Epoch 34/50\n",
      "105/105 - 2s - loss: 0.1682 - accuracy: 0.9556 - val_loss: 0.2027 - val_accuracy: 0.9498 - lr: 1.0000e-07 - 2s/epoch - 19ms/step\n",
      "Epoch 35/50\n",
      "105/105 - 2s - loss: 0.1682 - accuracy: 0.9556 - val_loss: 0.2028 - val_accuracy: 0.9498 - lr: 1.0000e-07 - 2s/epoch - 19ms/step\n",
      "Epoch 36/50\n",
      "105/105 - 2s - loss: 0.1682 - accuracy: 0.9556 - val_loss: 0.2027 - val_accuracy: 0.9498 - lr: 1.0000e-07 - 2s/epoch - 19ms/step\n",
      "Epoch 37/50\n",
      "105/105 - 2s - loss: 0.1682 - accuracy: 0.9556 - val_loss: 0.2028 - val_accuracy: 0.9498 - lr: 1.0000e-07 - 2s/epoch - 19ms/step\n",
      "Epoch 38/50\n",
      "105/105 - 2s - loss: 0.1682 - accuracy: 0.9557 - val_loss: 0.2027 - val_accuracy: 0.9498 - lr: 1.0000e-07 - 2s/epoch - 19ms/step\n",
      "Epoch 39/50\n",
      "105/105 - 2s - loss: 0.1682 - accuracy: 0.9556 - val_loss: 0.2028 - val_accuracy: 0.9498 - lr: 1.0000e-07 - 2s/epoch - 19ms/step\n",
      "Epoch 40/50\n",
      "105/105 - 2s - loss: 0.1682 - accuracy: 0.9557 - val_loss: 0.2027 - val_accuracy: 0.9498 - lr: 1.0000e-07 - 2s/epoch - 19ms/step\n",
      "Epoch 41/50\n",
      "105/105 - 2s - loss: 0.1682 - accuracy: 0.9556 - val_loss: 0.2027 - val_accuracy: 0.9498 - lr: 1.0000e-07 - 2s/epoch - 19ms/step\n",
      "Epoch 42/50\n",
      "105/105 - 2s - loss: 0.1681 - accuracy: 0.9556 - val_loss: 0.2028 - val_accuracy: 0.9498 - lr: 1.0000e-08 - 2s/epoch - 19ms/step\n",
      "Epoch 43/50\n",
      "105/105 - 2s - loss: 0.1681 - accuracy: 0.9556 - val_loss: 0.2027 - val_accuracy: 0.9498 - lr: 1.0000e-08 - 2s/epoch - 19ms/step\n",
      "Epoch 44/50\n",
      "105/105 - 2s - loss: 0.1681 - accuracy: 0.9556 - val_loss: 0.2028 - val_accuracy: 0.9498 - lr: 1.0000e-08 - 2s/epoch - 19ms/step\n",
      "Epoch 45/50\n",
      "105/105 - 2s - loss: 0.1681 - accuracy: 0.9556 - val_loss: 0.2027 - val_accuracy: 0.9498 - lr: 1.0000e-08 - 2s/epoch - 19ms/step\n",
      "Epoch 46/50\n",
      "105/105 - 2s - loss: 0.1681 - accuracy: 0.9556 - val_loss: 0.2027 - val_accuracy: 0.9498 - lr: 1.0000e-08 - 2s/epoch - 19ms/step\n",
      "Epoch 47/50\n",
      "105/105 - 2s - loss: 0.1681 - accuracy: 0.9556 - val_loss: 0.2027 - val_accuracy: 0.9498 - lr: 1.0000e-08 - 2s/epoch - 19ms/step\n",
      "Epoch 48/50\n",
      "105/105 - 2s - loss: 0.1681 - accuracy: 0.9557 - val_loss: 0.2028 - val_accuracy: 0.9498 - lr: 1.0000e-08 - 2s/epoch - 19ms/step\n",
      "Epoch 49/50\n",
      "105/105 - 2s - loss: 0.1682 - accuracy: 0.9556 - val_loss: 0.2028 - val_accuracy: 0.9498 - lr: 1.0000e-08 - 2s/epoch - 19ms/step\n",
      "Epoch 50/50\n",
      "105/105 - 2s - loss: 0.1682 - accuracy: 0.9556 - val_loss: 0.2027 - val_accuracy: 0.9498 - lr: 1.0000e-08 - 2s/epoch - 19ms/step\n",
      "3125/3125 [==============================] - 5s 2ms/step\n",
      "Keras  Accuracy: 0.95148\n",
      "1563/1563 [==============================] - 3s 2ms/step\n",
      "Total correct: 46427\n",
      "Total incorrect: 3573\n",
      "Total samples: 50000\n",
      "Keras Excited Accuracy: 0.92854\n",
      "1563/1563 [==============================] - 3s 2ms/step\n",
      "Total correct: 48721\n",
      "Total incorrect: 1279\n",
      "Total samples: 50000\n",
      "Keras Ground Accuracy: 0.97442\n",
      "\n",
      "===================================\n",
      "Fidelity 0.95148\n",
      "===================================\n",
      "Epoch 1/50\n",
      "105/105 - 3s - loss: 0.2137 - accuracy: 0.9494 - val_loss: 0.2157 - val_accuracy: 0.9464 - lr: 1.0000e-04 - 3s/epoch - 26ms/step\n",
      "Epoch 2/50\n",
      "105/105 - 2s - loss: 0.2081 - accuracy: 0.9500 - val_loss: 0.2150 - val_accuracy: 0.9467 - lr: 1.0000e-04 - 2s/epoch - 19ms/step\n",
      "Epoch 3/50\n",
      "105/105 - 2s - loss: 0.2044 - accuracy: 0.9504 - val_loss: 0.2143 - val_accuracy: 0.9466 - lr: 1.0000e-04 - 2s/epoch - 19ms/step\n",
      "Epoch 4/50\n",
      "105/105 - 2s - loss: 0.2012 - accuracy: 0.9507 - val_loss: 0.2129 - val_accuracy: 0.9468 - lr: 1.0000e-04 - 2s/epoch - 19ms/step\n",
      "Epoch 5/50\n",
      "105/105 - 2s - loss: 0.1983 - accuracy: 0.9510 - val_loss: 0.2125 - val_accuracy: 0.9468 - lr: 1.0000e-04 - 2s/epoch - 20ms/step\n",
      "Epoch 6/50\n",
      "105/105 - 2s - loss: 0.1957 - accuracy: 0.9512 - val_loss: 0.2124 - val_accuracy: 0.9469 - lr: 1.0000e-04 - 2s/epoch - 19ms/step\n",
      "Epoch 7/50\n",
      "105/105 - 2s - loss: 0.1931 - accuracy: 0.9514 - val_loss: 0.2119 - val_accuracy: 0.9468 - lr: 1.0000e-04 - 2s/epoch - 19ms/step\n",
      "Epoch 8/50\n",
      "105/105 - 2s - loss: 0.1906 - accuracy: 0.9517 - val_loss: 0.2114 - val_accuracy: 0.9469 - lr: 1.0000e-04 - 2s/epoch - 19ms/step\n",
      "Epoch 9/50\n",
      "105/105 - 2s - loss: 0.1881 - accuracy: 0.9518 - val_loss: 0.2118 - val_accuracy: 0.9466 - lr: 1.0000e-04 - 2s/epoch - 19ms/step\n",
      "Epoch 10/50\n",
      "105/105 - 2s - loss: 0.1856 - accuracy: 0.9521 - val_loss: 0.2116 - val_accuracy: 0.9466 - lr: 1.0000e-04 - 2s/epoch - 19ms/step\n",
      "Epoch 11/50\n",
      "105/105 - 2s - loss: 0.1831 - accuracy: 0.9523 - val_loss: 0.2118 - val_accuracy: 0.9465 - lr: 1.0000e-04 - 2s/epoch - 19ms/step\n",
      "Epoch 12/50\n",
      "105/105 - 2s - loss: 0.1795 - accuracy: 0.9526 - val_loss: 0.2118 - val_accuracy: 0.9466 - lr: 1.0000e-05 - 2s/epoch - 19ms/step\n",
      "Epoch 13/50\n",
      "105/105 - 2s - loss: 0.1790 - accuracy: 0.9527 - val_loss: 0.2118 - val_accuracy: 0.9466 - lr: 1.0000e-05 - 2s/epoch - 19ms/step\n",
      "Epoch 14/50\n",
      "105/105 - 2s - loss: 0.1787 - accuracy: 0.9527 - val_loss: 0.2117 - val_accuracy: 0.9466 - lr: 1.0000e-05 - 2s/epoch - 19ms/step\n",
      "Epoch 15/50\n",
      "105/105 - 2s - loss: 0.1784 - accuracy: 0.9527 - val_loss: 0.2118 - val_accuracy: 0.9466 - lr: 1.0000e-05 - 2s/epoch - 19ms/step\n",
      "Epoch 16/50\n",
      "105/105 - 2s - loss: 0.1781 - accuracy: 0.9527 - val_loss: 0.2118 - val_accuracy: 0.9466 - lr: 1.0000e-05 - 2s/epoch - 19ms/step\n",
      "Epoch 17/50\n",
      "105/105 - 2s - loss: 0.1778 - accuracy: 0.9528 - val_loss: 0.2118 - val_accuracy: 0.9466 - lr: 1.0000e-05 - 2s/epoch - 19ms/step\n",
      "Epoch 18/50\n",
      "105/105 - 2s - loss: 0.1775 - accuracy: 0.9528 - val_loss: 0.2118 - val_accuracy: 0.9466 - lr: 1.0000e-05 - 2s/epoch - 19ms/step\n",
      "Epoch 19/50\n",
      "105/105 - 2s - loss: 0.1773 - accuracy: 0.9528 - val_loss: 0.2119 - val_accuracy: 0.9466 - lr: 1.0000e-05 - 2s/epoch - 19ms/step\n",
      "Epoch 20/50\n",
      "105/105 - 2s - loss: 0.1770 - accuracy: 0.9529 - val_loss: 0.2119 - val_accuracy: 0.9466 - lr: 1.0000e-05 - 2s/epoch - 19ms/step\n",
      "Epoch 21/50\n",
      "105/105 - 2s - loss: 0.1767 - accuracy: 0.9528 - val_loss: 0.2120 - val_accuracy: 0.9466 - lr: 1.0000e-05 - 2s/epoch - 19ms/step\n",
      "Epoch 22/50\n",
      "105/105 - 2s - loss: 0.1763 - accuracy: 0.9529 - val_loss: 0.2120 - val_accuracy: 0.9466 - lr: 1.0000e-06 - 2s/epoch - 19ms/step\n",
      "Epoch 23/50\n",
      "105/105 - 2s - loss: 0.1763 - accuracy: 0.9529 - val_loss: 0.2120 - val_accuracy: 0.9466 - lr: 1.0000e-06 - 2s/epoch - 19ms/step\n",
      "Epoch 24/50\n",
      "105/105 - 2s - loss: 0.1762 - accuracy: 0.9529 - val_loss: 0.2120 - val_accuracy: 0.9466 - lr: 1.0000e-06 - 2s/epoch - 19ms/step\n",
      "Epoch 25/50\n",
      "105/105 - 2s - loss: 0.1762 - accuracy: 0.9529 - val_loss: 0.2120 - val_accuracy: 0.9466 - lr: 1.0000e-06 - 2s/epoch - 19ms/step\n",
      "Epoch 26/50\n",
      "105/105 - 2s - loss: 0.1762 - accuracy: 0.9529 - val_loss: 0.2120 - val_accuracy: 0.9466 - lr: 1.0000e-06 - 2s/epoch - 19ms/step\n",
      "Epoch 27/50\n",
      "105/105 - 2s - loss: 0.1761 - accuracy: 0.9529 - val_loss: 0.2120 - val_accuracy: 0.9466 - lr: 1.0000e-06 - 2s/epoch - 19ms/step\n",
      "Epoch 28/50\n",
      "105/105 - 2s - loss: 0.1761 - accuracy: 0.9529 - val_loss: 0.2120 - val_accuracy: 0.9466 - lr: 1.0000e-06 - 2s/epoch - 19ms/step\n",
      "Epoch 29/50\n",
      "105/105 - 2s - loss: 0.1761 - accuracy: 0.9529 - val_loss: 0.2120 - val_accuracy: 0.9466 - lr: 1.0000e-06 - 2s/epoch - 19ms/step\n",
      "Epoch 30/50\n",
      "105/105 - 2s - loss: 0.1761 - accuracy: 0.9529 - val_loss: 0.2120 - val_accuracy: 0.9466 - lr: 1.0000e-06 - 2s/epoch - 19ms/step\n",
      "Epoch 31/50\n",
      "105/105 - 2s - loss: 0.1761 - accuracy: 0.9529 - val_loss: 0.2120 - val_accuracy: 0.9466 - lr: 1.0000e-06 - 2s/epoch - 19ms/step\n",
      "Epoch 32/50\n",
      "105/105 - 2s - loss: 0.1760 - accuracy: 0.9529 - val_loss: 0.2120 - val_accuracy: 0.9466 - lr: 1.0000e-07 - 2s/epoch - 19ms/step\n",
      "Epoch 33/50\n",
      "105/105 - 2s - loss: 0.1760 - accuracy: 0.9529 - val_loss: 0.2120 - val_accuracy: 0.9466 - lr: 1.0000e-07 - 2s/epoch - 19ms/step\n",
      "Epoch 34/50\n",
      "105/105 - 2s - loss: 0.1760 - accuracy: 0.9529 - val_loss: 0.2120 - val_accuracy: 0.9466 - lr: 1.0000e-07 - 2s/epoch - 19ms/step\n",
      "Epoch 35/50\n",
      "105/105 - 2s - loss: 0.1760 - accuracy: 0.9529 - val_loss: 0.2120 - val_accuracy: 0.9466 - lr: 1.0000e-07 - 2s/epoch - 19ms/step\n",
      "Epoch 36/50\n",
      "105/105 - 2s - loss: 0.1760 - accuracy: 0.9529 - val_loss: 0.2120 - val_accuracy: 0.9466 - lr: 1.0000e-07 - 2s/epoch - 19ms/step\n",
      "Epoch 37/50\n",
      "105/105 - 2s - loss: 0.1760 - accuracy: 0.9529 - val_loss: 0.2120 - val_accuracy: 0.9466 - lr: 1.0000e-07 - 2s/epoch - 19ms/step\n",
      "Epoch 38/50\n",
      "105/105 - 2s - loss: 0.1760 - accuracy: 0.9529 - val_loss: 0.2120 - val_accuracy: 0.9466 - lr: 1.0000e-07 - 2s/epoch - 19ms/step\n",
      "Epoch 39/50\n",
      "105/105 - 2s - loss: 0.1760 - accuracy: 0.9529 - val_loss: 0.2120 - val_accuracy: 0.9466 - lr: 1.0000e-07 - 2s/epoch - 19ms/step\n",
      "Epoch 40/50\n",
      "105/105 - 2s - loss: 0.1759 - accuracy: 0.9529 - val_loss: 0.2120 - val_accuracy: 0.9466 - lr: 1.0000e-07 - 2s/epoch - 19ms/step\n",
      "Epoch 41/50\n",
      "105/105 - 2s - loss: 0.1760 - accuracy: 0.9529 - val_loss: 0.2120 - val_accuracy: 0.9466 - lr: 1.0000e-07 - 2s/epoch - 19ms/step\n",
      "Epoch 42/50\n",
      "105/105 - 2s - loss: 0.1760 - accuracy: 0.9529 - val_loss: 0.2120 - val_accuracy: 0.9466 - lr: 1.0000e-08 - 2s/epoch - 19ms/step\n",
      "Epoch 43/50\n",
      "105/105 - 2s - loss: 0.1759 - accuracy: 0.9529 - val_loss: 0.2120 - val_accuracy: 0.9466 - lr: 1.0000e-08 - 2s/epoch - 19ms/step\n",
      "Epoch 44/50\n",
      "105/105 - 2s - loss: 0.1760 - accuracy: 0.9529 - val_loss: 0.2120 - val_accuracy: 0.9466 - lr: 1.0000e-08 - 2s/epoch - 19ms/step\n",
      "Epoch 45/50\n",
      "105/105 - 2s - loss: 0.1760 - accuracy: 0.9529 - val_loss: 0.2120 - val_accuracy: 0.9466 - lr: 1.0000e-08 - 2s/epoch - 19ms/step\n",
      "Epoch 46/50\n",
      "105/105 - 2s - loss: 0.1760 - accuracy: 0.9529 - val_loss: 0.2120 - val_accuracy: 0.9466 - lr: 1.0000e-08 - 2s/epoch - 19ms/step\n",
      "Epoch 47/50\n",
      "105/105 - 2s - loss: 0.1760 - accuracy: 0.9529 - val_loss: 0.2120 - val_accuracy: 0.9466 - lr: 1.0000e-08 - 2s/epoch - 19ms/step\n",
      "Epoch 48/50\n",
      "105/105 - 2s - loss: 0.1760 - accuracy: 0.9529 - val_loss: 0.2120 - val_accuracy: 0.9466 - lr: 1.0000e-08 - 2s/epoch - 19ms/step\n",
      "Epoch 49/50\n",
      "105/105 - 2s - loss: 0.1760 - accuracy: 0.9529 - val_loss: 0.2120 - val_accuracy: 0.9466 - lr: 1.0000e-08 - 2s/epoch - 19ms/step\n",
      "Epoch 50/50\n",
      "105/105 - 2s - loss: 0.1760 - accuracy: 0.9529 - val_loss: 0.2120 - val_accuracy: 0.9466 - lr: 1.0000e-08 - 2s/epoch - 19ms/step\n",
      "3125/3125 [==============================] - 6s 2ms/step\n",
      "Keras  Accuracy: 0.94862\n",
      "1563/1563 [==============================] - 3s 2ms/step\n",
      "Total correct: 46164\n",
      "Total incorrect: 3836\n",
      "Total samples: 50000\n",
      "Keras Excited Accuracy: 0.92328\n",
      "1563/1563 [==============================] - 3s 2ms/step\n",
      "Total correct: 48698\n",
      "Total incorrect: 1302\n",
      "Total samples: 50000\n",
      "Keras Ground Accuracy: 0.97396\n",
      "\n",
      "===================================\n",
      "Fidelity 0.94862\n",
      "===================================\n"
     ]
    }
   ],
   "source": [
    "### calbacks \n",
    "checkpoint_filename = 'multi_layer_model_subwindow.h5'\n",
    "callbacks = [\n",
    "        ModelCheckpoint(\n",
    "        checkpoint_filename,\n",
    "        monitor=\"val_loss\",\n",
    "        verbose=0,\n",
    "        save_best_only=True,\n",
    "        save_weights_only=False,\n",
    "        save_freq=\"epoch\",\n",
    "    ),\n",
    "    ReduceLROnPlateau(patience=10, min_delta=1**-6),\n",
    "]\n",
    "\n",
    "\n",
    "### model \n",
    "sr = int((end_window-start_window)*2)\n",
    "hn = sr * 2\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(int(hn/8), activation='relu', input_shape=(800,), kernel_regularizer=tf.keras.regularizers.L2(l2=1e-4)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(2, activation='relu', kernel_regularizer=tf.keras.regularizers.L2(l2=1e-4),))\n",
    "print(model.summary())\n",
    "\n",
    "### scan readout window and train \n",
    "ml_accuracy, ml_e_accuracy, ml_g_accuracy  = scan_readout_window(model, window_start_locations, window_size, callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy [0.95585, 0.95929, 0.96012, 0.95924, 0.95666, 0.95417, 0.95148, 0.94862]\n",
      "Fidelity [0.9117  0.91858 0.92024 0.91848 0.91332 0.90834 0.90296 0.89724]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ml_fidelity = 1 - (1 - np.array(ml_e_accuracy)) - (1 - np.array(ml_g_accuracy)) \n",
    "\n",
    "plt.figure()\n",
    "plt.plot(window_start_locations, ml_fidelity)\n",
    "plt.xlabel('Readout window start location')\n",
    "plt.ylabel('Fidelity')\n",
    "\n",
    "print('Accuracy', ml_accuracy)\n",
    "print('Fidelity', ml_fidelity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Single-Layer Model\n",
    "\n",
    "<img src=\"../images/single_layer_model.png\" alt=\"alt text\" width=\"35%\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_11 (Dense)            (None, 2)                 1602      \n",
      "                                                                 \n",
      " batch_normalization_7 (Batc  (None, 2)                8         \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,610\n",
      "Trainable params: 1,606\n",
      "Non-trainable params: 4\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "Epoch 1/50\n",
      "105/105 - 1s - loss: 0.7299 - accuracy: 0.6190 - val_loss: 0.6105 - val_accuracy: 0.7248 - lr: 1.0000e-04 - 1s/epoch - 14ms/step\n",
      "Epoch 2/50\n",
      "105/105 - 1s - loss: 0.5084 - accuracy: 0.7694 - val_loss: 0.4317 - val_accuracy: 0.8266 - lr: 1.0000e-04 - 888ms/epoch - 8ms/step\n",
      "Epoch 3/50\n",
      "105/105 - 1s - loss: 0.4022 - accuracy: 0.8502 - val_loss: 0.3511 - val_accuracy: 0.8790 - lr: 1.0000e-04 - 863ms/epoch - 8ms/step\n",
      "Epoch 4/50\n",
      "105/105 - 1s - loss: 0.3454 - accuracy: 0.8919 - val_loss: 0.3101 - val_accuracy: 0.9083 - lr: 1.0000e-04 - 911ms/epoch - 9ms/step\n",
      "Epoch 5/50\n",
      "105/105 - 1s - loss: 0.3120 - accuracy: 0.9145 - val_loss: 0.2867 - val_accuracy: 0.9232 - lr: 1.0000e-04 - 908ms/epoch - 9ms/step\n",
      "Epoch 6/50\n",
      "105/105 - 1s - loss: 0.2903 - accuracy: 0.9280 - val_loss: 0.2716 - val_accuracy: 0.9316 - lr: 1.0000e-04 - 896ms/epoch - 9ms/step\n",
      "Epoch 7/50\n",
      "105/105 - 1s - loss: 0.2752 - accuracy: 0.9362 - val_loss: 0.2609 - val_accuracy: 0.9376 - lr: 1.0000e-04 - 902ms/epoch - 9ms/step\n",
      "Epoch 8/50\n",
      "105/105 - 1s - loss: 0.2640 - accuracy: 0.9416 - val_loss: 0.2528 - val_accuracy: 0.9416 - lr: 1.0000e-04 - 881ms/epoch - 8ms/step\n",
      "Epoch 9/50\n",
      "105/105 - 1s - loss: 0.2554 - accuracy: 0.9455 - val_loss: 0.2464 - val_accuracy: 0.9450 - lr: 1.0000e-04 - 911ms/epoch - 9ms/step\n",
      "Epoch 10/50\n",
      "105/105 - 1s - loss: 0.2484 - accuracy: 0.9482 - val_loss: 0.2411 - val_accuracy: 0.9471 - lr: 1.0000e-04 - 887ms/epoch - 8ms/step\n",
      "Epoch 11/50\n",
      "105/105 - 1s - loss: 0.2426 - accuracy: 0.9501 - val_loss: 0.2366 - val_accuracy: 0.9487 - lr: 1.0000e-04 - 913ms/epoch - 9ms/step\n",
      "Epoch 12/50\n",
      "105/105 - 1s - loss: 0.2377 - accuracy: 0.9517 - val_loss: 0.2327 - val_accuracy: 0.9503 - lr: 1.0000e-04 - 904ms/epoch - 9ms/step\n",
      "Epoch 13/50\n",
      "105/105 - 1s - loss: 0.2335 - accuracy: 0.9529 - val_loss: 0.2293 - val_accuracy: 0.9515 - lr: 1.0000e-04 - 889ms/epoch - 8ms/step\n",
      "Epoch 14/50\n",
      "105/105 - 1s - loss: 0.2298 - accuracy: 0.9538 - val_loss: 0.2262 - val_accuracy: 0.9522 - lr: 1.0000e-04 - 898ms/epoch - 9ms/step\n",
      "Epoch 15/50\n",
      "105/105 - 1s - loss: 0.2265 - accuracy: 0.9546 - val_loss: 0.2235 - val_accuracy: 0.9530 - lr: 1.0000e-04 - 889ms/epoch - 8ms/step\n",
      "Epoch 16/50\n",
      "105/105 - 1s - loss: 0.2236 - accuracy: 0.9552 - val_loss: 0.2210 - val_accuracy: 0.9534 - lr: 1.0000e-04 - 899ms/epoch - 9ms/step\n",
      "Epoch 17/50\n",
      "105/105 - 1s - loss: 0.2210 - accuracy: 0.9557 - val_loss: 0.2188 - val_accuracy: 0.9540 - lr: 1.0000e-04 - 903ms/epoch - 9ms/step\n",
      "Epoch 18/50\n",
      "105/105 - 1s - loss: 0.2186 - accuracy: 0.9561 - val_loss: 0.2167 - val_accuracy: 0.9543 - lr: 1.0000e-04 - 906ms/epoch - 9ms/step\n",
      "Epoch 19/50\n",
      "105/105 - 1s - loss: 0.2164 - accuracy: 0.9564 - val_loss: 0.2148 - val_accuracy: 0.9546 - lr: 1.0000e-04 - 900ms/epoch - 9ms/step\n",
      "Epoch 20/50\n",
      "105/105 - 1s - loss: 0.2144 - accuracy: 0.9567 - val_loss: 0.2131 - val_accuracy: 0.9548 - lr: 1.0000e-04 - 900ms/epoch - 9ms/step\n",
      "Epoch 21/50\n",
      "105/105 - 1s - loss: 0.2126 - accuracy: 0.9569 - val_loss: 0.2114 - val_accuracy: 0.9551 - lr: 1.0000e-04 - 878ms/epoch - 8ms/step\n",
      "Epoch 22/50\n",
      "105/105 - 1s - loss: 0.2108 - accuracy: 0.9571 - val_loss: 0.2099 - val_accuracy: 0.9554 - lr: 1.0000e-04 - 910ms/epoch - 9ms/step\n",
      "Epoch 23/50\n",
      "105/105 - 1s - loss: 0.2092 - accuracy: 0.9573 - val_loss: 0.2085 - val_accuracy: 0.9554 - lr: 1.0000e-04 - 910ms/epoch - 9ms/step\n",
      "Epoch 24/50\n",
      "105/105 - 1s - loss: 0.2077 - accuracy: 0.9575 - val_loss: 0.2071 - val_accuracy: 0.9554 - lr: 1.0000e-04 - 913ms/epoch - 9ms/step\n",
      "Epoch 25/50\n",
      "105/105 - 1s - loss: 0.2063 - accuracy: 0.9576 - val_loss: 0.2058 - val_accuracy: 0.9555 - lr: 1.0000e-04 - 885ms/epoch - 8ms/step\n",
      "Epoch 26/50\n",
      "105/105 - 1s - loss: 0.2049 - accuracy: 0.9577 - val_loss: 0.2046 - val_accuracy: 0.9555 - lr: 1.0000e-04 - 897ms/epoch - 9ms/step\n",
      "Epoch 27/50\n",
      "105/105 - 1s - loss: 0.2037 - accuracy: 0.9578 - val_loss: 0.2034 - val_accuracy: 0.9556 - lr: 1.0000e-04 - 912ms/epoch - 9ms/step\n",
      "Epoch 28/50\n",
      "105/105 - 1s - loss: 0.2025 - accuracy: 0.9579 - val_loss: 0.2023 - val_accuracy: 0.9558 - lr: 1.0000e-04 - 913ms/epoch - 9ms/step\n",
      "Epoch 29/50\n",
      "105/105 - 1s - loss: 0.2013 - accuracy: 0.9580 - val_loss: 0.2013 - val_accuracy: 0.9558 - lr: 1.0000e-04 - 913ms/epoch - 9ms/step\n",
      "Epoch 30/50\n",
      "105/105 - 1s - loss: 0.2002 - accuracy: 0.9580 - val_loss: 0.2002 - val_accuracy: 0.9557 - lr: 1.0000e-04 - 850ms/epoch - 8ms/step\n",
      "Epoch 31/50\n",
      "105/105 - 1s - loss: 0.1992 - accuracy: 0.9580 - val_loss: 0.1993 - val_accuracy: 0.9558 - lr: 1.0000e-04 - 915ms/epoch - 9ms/step\n",
      "Epoch 32/50\n",
      "105/105 - 1s - loss: 0.1982 - accuracy: 0.9581 - val_loss: 0.1984 - val_accuracy: 0.9558 - lr: 1.0000e-04 - 912ms/epoch - 9ms/step\n",
      "Epoch 33/50\n",
      "105/105 - 1s - loss: 0.1973 - accuracy: 0.9581 - val_loss: 0.1975 - val_accuracy: 0.9558 - lr: 1.0000e-04 - 923ms/epoch - 9ms/step\n",
      "Epoch 34/50\n",
      "105/105 - 1s - loss: 0.1963 - accuracy: 0.9581 - val_loss: 0.1966 - val_accuracy: 0.9558 - lr: 1.0000e-04 - 890ms/epoch - 8ms/step\n",
      "Epoch 35/50\n",
      "105/105 - 1s - loss: 0.1955 - accuracy: 0.9582 - val_loss: 0.1958 - val_accuracy: 0.9558 - lr: 1.0000e-04 - 902ms/epoch - 9ms/step\n",
      "Epoch 36/50\n",
      "105/105 - 1s - loss: 0.1946 - accuracy: 0.9582 - val_loss: 0.1950 - val_accuracy: 0.9558 - lr: 1.0000e-04 - 910ms/epoch - 9ms/step\n",
      "Epoch 37/50\n",
      "105/105 - 1s - loss: 0.1938 - accuracy: 0.9582 - val_loss: 0.1942 - val_accuracy: 0.9559 - lr: 1.0000e-04 - 915ms/epoch - 9ms/step\n",
      "Epoch 38/50\n",
      "105/105 - 1s - loss: 0.1930 - accuracy: 0.9582 - val_loss: 0.1935 - val_accuracy: 0.9560 - lr: 1.0000e-04 - 901ms/epoch - 9ms/step\n",
      "Epoch 39/50\n",
      "105/105 - 1s - loss: 0.1923 - accuracy: 0.9582 - val_loss: 0.1928 - val_accuracy: 0.9559 - lr: 1.0000e-04 - 906ms/epoch - 9ms/step\n",
      "Epoch 40/50\n",
      "105/105 - 1s - loss: 0.1916 - accuracy: 0.9583 - val_loss: 0.1920 - val_accuracy: 0.9559 - lr: 1.0000e-04 - 876ms/epoch - 8ms/step\n",
      "Epoch 41/50\n",
      "105/105 - 1s - loss: 0.1909 - accuracy: 0.9583 - val_loss: 0.1914 - val_accuracy: 0.9559 - lr: 1.0000e-04 - 921ms/epoch - 9ms/step\n",
      "Epoch 42/50\n",
      "105/105 - 1s - loss: 0.1902 - accuracy: 0.9583 - val_loss: 0.1908 - val_accuracy: 0.9559 - lr: 1.0000e-04 - 886ms/epoch - 8ms/step\n",
      "Epoch 43/50\n",
      "105/105 - 1s - loss: 0.1895 - accuracy: 0.9583 - val_loss: 0.1901 - val_accuracy: 0.9559 - lr: 1.0000e-04 - 870ms/epoch - 8ms/step\n",
      "Epoch 44/50\n",
      "105/105 - 1s - loss: 0.1889 - accuracy: 0.9583 - val_loss: 0.1895 - val_accuracy: 0.9560 - lr: 1.0000e-04 - 899ms/epoch - 9ms/step\n",
      "Epoch 45/50\n",
      "105/105 - 1s - loss: 0.1883 - accuracy: 0.9583 - val_loss: 0.1889 - val_accuracy: 0.9560 - lr: 1.0000e-04 - 902ms/epoch - 9ms/step\n",
      "Epoch 46/50\n",
      "105/105 - 1s - loss: 0.1877 - accuracy: 0.9583 - val_loss: 0.1884 - val_accuracy: 0.9560 - lr: 1.0000e-04 - 905ms/epoch - 9ms/step\n",
      "Epoch 47/50\n",
      "105/105 - 1s - loss: 0.1871 - accuracy: 0.9583 - val_loss: 0.1878 - val_accuracy: 0.9560 - lr: 1.0000e-04 - 917ms/epoch - 9ms/step\n",
      "Epoch 48/50\n",
      "105/105 - 1s - loss: 0.1865 - accuracy: 0.9583 - val_loss: 0.1872 - val_accuracy: 0.9560 - lr: 1.0000e-04 - 904ms/epoch - 9ms/step\n",
      "Epoch 49/50\n",
      "105/105 - 1s - loss: 0.1860 - accuracy: 0.9583 - val_loss: 0.1867 - val_accuracy: 0.9559 - lr: 1.0000e-04 - 888ms/epoch - 8ms/step\n",
      "Epoch 50/50\n",
      "105/105 - 1s - loss: 0.1854 - accuracy: 0.9583 - val_loss: 0.1862 - val_accuracy: 0.9560 - lr: 1.0000e-04 - 898ms/epoch - 9ms/step\n",
      "3125/3125 [==============================] - 3s 793us/step\n",
      "Keras  Accuracy: 0.95772\n",
      "1563/1563 [==============================] - 1s 876us/step\n",
      "Total correct: 47298\n",
      "Total incorrect: 2702\n",
      "Total samples: 50000\n",
      "Keras Excited Accuracy: 0.94596\n",
      "1563/1563 [==============================] - 2s 1ms/step\n",
      "Total correct: 48474\n",
      "Total incorrect: 1526\n",
      "Total samples: 50000\n",
      "Keras Ground Accuracy: 0.96948\n",
      "\n",
      "===================================\n",
      "Fidelity 0.95772\n",
      "===================================\n",
      "Epoch 1/50\n",
      "105/105 - 1s - loss: 0.1882 - accuracy: 0.9594 - val_loss: 0.1889 - val_accuracy: 0.9573 - lr: 1.0000e-04 - 1s/epoch - 14ms/step\n",
      "Epoch 2/50\n",
      "105/105 - 1s - loss: 0.1862 - accuracy: 0.9599 - val_loss: 0.1861 - val_accuracy: 0.9575 - lr: 1.0000e-04 - 922ms/epoch - 9ms/step\n",
      "Epoch 3/50\n",
      "105/105 - 1s - loss: 0.1848 - accuracy: 0.9601 - val_loss: 0.1847 - val_accuracy: 0.9579 - lr: 1.0000e-04 - 921ms/epoch - 9ms/step\n",
      "Epoch 4/50\n",
      "105/105 - 1s - loss: 0.1838 - accuracy: 0.9602 - val_loss: 0.1838 - val_accuracy: 0.9582 - lr: 1.0000e-04 - 917ms/epoch - 9ms/step\n",
      "Epoch 5/50\n",
      "105/105 - 1s - loss: 0.1830 - accuracy: 0.9603 - val_loss: 0.1831 - val_accuracy: 0.9583 - lr: 1.0000e-04 - 898ms/epoch - 9ms/step\n",
      "Epoch 6/50\n",
      "105/105 - 1s - loss: 0.1823 - accuracy: 0.9603 - val_loss: 0.1825 - val_accuracy: 0.9582 - lr: 1.0000e-04 - 893ms/epoch - 9ms/step\n",
      "Epoch 7/50\n",
      "105/105 - 1s - loss: 0.1817 - accuracy: 0.9604 - val_loss: 0.1820 - val_accuracy: 0.9582 - lr: 1.0000e-04 - 901ms/epoch - 9ms/step\n",
      "Epoch 8/50\n",
      "105/105 - 1s - loss: 0.1811 - accuracy: 0.9604 - val_loss: 0.1815 - val_accuracy: 0.9581 - lr: 1.0000e-04 - 897ms/epoch - 9ms/step\n",
      "Epoch 9/50\n",
      "105/105 - 1s - loss: 0.1806 - accuracy: 0.9604 - val_loss: 0.1810 - val_accuracy: 0.9582 - lr: 1.0000e-04 - 916ms/epoch - 9ms/step\n",
      "Epoch 10/50\n",
      "105/105 - 1s - loss: 0.1801 - accuracy: 0.9604 - val_loss: 0.1805 - val_accuracy: 0.9580 - lr: 1.0000e-04 - 905ms/epoch - 9ms/step\n",
      "Epoch 11/50\n",
      "105/105 - 1s - loss: 0.1797 - accuracy: 0.9604 - val_loss: 0.1801 - val_accuracy: 0.9580 - lr: 1.0000e-04 - 912ms/epoch - 9ms/step\n",
      "Epoch 12/50\n",
      "105/105 - 1s - loss: 0.1792 - accuracy: 0.9604 - val_loss: 0.1797 - val_accuracy: 0.9580 - lr: 1.0000e-04 - 910ms/epoch - 9ms/step\n",
      "Epoch 13/50\n",
      "105/105 - 1s - loss: 0.1788 - accuracy: 0.9604 - val_loss: 0.1793 - val_accuracy: 0.9581 - lr: 1.0000e-04 - 898ms/epoch - 9ms/step\n",
      "Epoch 14/50\n",
      "105/105 - 1s - loss: 0.1784 - accuracy: 0.9604 - val_loss: 0.1789 - val_accuracy: 0.9580 - lr: 1.0000e-04 - 900ms/epoch - 9ms/step\n",
      "Epoch 15/50\n",
      "105/105 - 1s - loss: 0.1780 - accuracy: 0.9604 - val_loss: 0.1786 - val_accuracy: 0.9580 - lr: 1.0000e-04 - 886ms/epoch - 8ms/step\n",
      "Epoch 16/50\n",
      "105/105 - 1s - loss: 0.1776 - accuracy: 0.9604 - val_loss: 0.1782 - val_accuracy: 0.9581 - lr: 1.0000e-04 - 926ms/epoch - 9ms/step\n",
      "Epoch 17/50\n",
      "105/105 - 1s - loss: 0.1773 - accuracy: 0.9604 - val_loss: 0.1779 - val_accuracy: 0.9581 - lr: 1.0000e-04 - 909ms/epoch - 9ms/step\n",
      "Epoch 18/50\n",
      "105/105 - 1s - loss: 0.1769 - accuracy: 0.9604 - val_loss: 0.1776 - val_accuracy: 0.9581 - lr: 1.0000e-04 - 900ms/epoch - 9ms/step\n",
      "Epoch 19/50\n",
      "105/105 - 1s - loss: 0.1766 - accuracy: 0.9604 - val_loss: 0.1773 - val_accuracy: 0.9581 - lr: 1.0000e-04 - 909ms/epoch - 9ms/step\n",
      "Epoch 20/50\n",
      "105/105 - 1s - loss: 0.1763 - accuracy: 0.9604 - val_loss: 0.1769 - val_accuracy: 0.9581 - lr: 1.0000e-04 - 898ms/epoch - 9ms/step\n",
      "Epoch 21/50\n",
      "105/105 - 1s - loss: 0.1760 - accuracy: 0.9604 - val_loss: 0.1767 - val_accuracy: 0.9581 - lr: 1.0000e-04 - 888ms/epoch - 8ms/step\n",
      "Epoch 22/50\n",
      "105/105 - 1s - loss: 0.1757 - accuracy: 0.9604 - val_loss: 0.1764 - val_accuracy: 0.9582 - lr: 1.0000e-04 - 900ms/epoch - 9ms/step\n",
      "Epoch 23/50\n",
      "105/105 - 1s - loss: 0.1754 - accuracy: 0.9605 - val_loss: 0.1761 - val_accuracy: 0.9582 - lr: 1.0000e-04 - 915ms/epoch - 9ms/step\n",
      "Epoch 24/50\n",
      "105/105 - 1s - loss: 0.1751 - accuracy: 0.9604 - val_loss: 0.1759 - val_accuracy: 0.9582 - lr: 1.0000e-04 - 894ms/epoch - 9ms/step\n",
      "Epoch 25/50\n",
      "105/105 - 1s - loss: 0.1749 - accuracy: 0.9604 - val_loss: 0.1757 - val_accuracy: 0.9582 - lr: 1.0000e-04 - 919ms/epoch - 9ms/step\n",
      "Epoch 26/50\n",
      "105/105 - 1s - loss: 0.1746 - accuracy: 0.9605 - val_loss: 0.1754 - val_accuracy: 0.9582 - lr: 1.0000e-04 - 897ms/epoch - 9ms/step\n",
      "Epoch 27/50\n",
      "105/105 - 1s - loss: 0.1744 - accuracy: 0.9605 - val_loss: 0.1752 - val_accuracy: 0.9582 - lr: 1.0000e-04 - 897ms/epoch - 9ms/step\n",
      "Epoch 28/50\n",
      "105/105 - 1s - loss: 0.1741 - accuracy: 0.9604 - val_loss: 0.1750 - val_accuracy: 0.9582 - lr: 1.0000e-04 - 921ms/epoch - 9ms/step\n",
      "Epoch 29/50\n",
      "105/105 - 1s - loss: 0.1739 - accuracy: 0.9604 - val_loss: 0.1748 - val_accuracy: 0.9582 - lr: 1.0000e-04 - 910ms/epoch - 9ms/step\n",
      "Epoch 30/50\n",
      "105/105 - 1s - loss: 0.1737 - accuracy: 0.9604 - val_loss: 0.1746 - val_accuracy: 0.9582 - lr: 1.0000e-04 - 915ms/epoch - 9ms/step\n",
      "Epoch 31/50\n",
      "105/105 - 1s - loss: 0.1735 - accuracy: 0.9605 - val_loss: 0.1744 - val_accuracy: 0.9582 - lr: 1.0000e-04 - 906ms/epoch - 9ms/step\n",
      "Epoch 32/50\n",
      "105/105 - 1s - loss: 0.1733 - accuracy: 0.9604 - val_loss: 0.1742 - val_accuracy: 0.9582 - lr: 1.0000e-04 - 904ms/epoch - 9ms/step\n",
      "Epoch 33/50\n",
      "105/105 - 1s - loss: 0.1731 - accuracy: 0.9605 - val_loss: 0.1740 - val_accuracy: 0.9582 - lr: 1.0000e-04 - 907ms/epoch - 9ms/step\n",
      "Epoch 34/50\n",
      "105/105 - 1s - loss: 0.1729 - accuracy: 0.9604 - val_loss: 0.1739 - val_accuracy: 0.9582 - lr: 1.0000e-04 - 907ms/epoch - 9ms/step\n",
      "Epoch 35/50\n",
      "105/105 - 1s - loss: 0.1728 - accuracy: 0.9604 - val_loss: 0.1737 - val_accuracy: 0.9582 - lr: 1.0000e-04 - 895ms/epoch - 9ms/step\n",
      "Epoch 36/50\n",
      "105/105 - 1s - loss: 0.1726 - accuracy: 0.9604 - val_loss: 0.1736 - val_accuracy: 0.9582 - lr: 1.0000e-04 - 910ms/epoch - 9ms/step\n",
      "Epoch 37/50\n",
      "105/105 - 1s - loss: 0.1724 - accuracy: 0.9604 - val_loss: 0.1734 - val_accuracy: 0.9582 - lr: 1.0000e-04 - 921ms/epoch - 9ms/step\n",
      "Epoch 38/50\n",
      "105/105 - 1s - loss: 0.1723 - accuracy: 0.9604 - val_loss: 0.1733 - val_accuracy: 0.9582 - lr: 1.0000e-04 - 912ms/epoch - 9ms/step\n",
      "Epoch 39/50\n",
      "105/105 - 1s - loss: 0.1721 - accuracy: 0.9604 - val_loss: 0.1732 - val_accuracy: 0.9582 - lr: 1.0000e-04 - 890ms/epoch - 8ms/step\n",
      "Epoch 40/50\n",
      "105/105 - 1s - loss: 0.1720 - accuracy: 0.9604 - val_loss: 0.1730 - val_accuracy: 0.9582 - lr: 1.0000e-04 - 907ms/epoch - 9ms/step\n",
      "Epoch 41/50\n",
      "105/105 - 1s - loss: 0.1719 - accuracy: 0.9604 - val_loss: 0.1729 - val_accuracy: 0.9582 - lr: 1.0000e-04 - 902ms/epoch - 9ms/step\n",
      "Epoch 42/50\n",
      "105/105 - 1s - loss: 0.1717 - accuracy: 0.9604 - val_loss: 0.1728 - val_accuracy: 0.9582 - lr: 1.0000e-04 - 927ms/epoch - 9ms/step\n",
      "Epoch 43/50\n",
      "105/105 - 1s - loss: 0.1716 - accuracy: 0.9604 - val_loss: 0.1727 - val_accuracy: 0.9582 - lr: 1.0000e-04 - 843ms/epoch - 8ms/step\n",
      "Epoch 44/50\n",
      "105/105 - 1s - loss: 0.1715 - accuracy: 0.9604 - val_loss: 0.1726 - val_accuracy: 0.9582 - lr: 1.0000e-04 - 817ms/epoch - 8ms/step\n",
      "Epoch 45/50\n",
      "105/105 - 1s - loss: 0.1714 - accuracy: 0.9604 - val_loss: 0.1725 - val_accuracy: 0.9582 - lr: 1.0000e-04 - 868ms/epoch - 8ms/step\n",
      "Epoch 46/50\n",
      "105/105 - 1s - loss: 0.1713 - accuracy: 0.9604 - val_loss: 0.1724 - val_accuracy: 0.9583 - lr: 1.0000e-04 - 897ms/epoch - 9ms/step\n",
      "Epoch 47/50\n",
      "105/105 - 1s - loss: 0.1712 - accuracy: 0.9605 - val_loss: 0.1723 - val_accuracy: 0.9583 - lr: 1.0000e-04 - 897ms/epoch - 9ms/step\n",
      "Epoch 48/50\n",
      "105/105 - 1s - loss: 0.1711 - accuracy: 0.9605 - val_loss: 0.1723 - val_accuracy: 0.9584 - lr: 1.0000e-04 - 917ms/epoch - 9ms/step\n",
      "Epoch 49/50\n",
      "105/105 - 1s - loss: 0.1710 - accuracy: 0.9604 - val_loss: 0.1722 - val_accuracy: 0.9583 - lr: 1.0000e-04 - 885ms/epoch - 8ms/step\n",
      "Epoch 50/50\n",
      "105/105 - 1s - loss: 0.1709 - accuracy: 0.9605 - val_loss: 0.1721 - val_accuracy: 0.9582 - lr: 1.0000e-04 - 895ms/epoch - 9ms/step\n",
      "3125/3125 [==============================] - 3s 832us/step\n",
      "Keras  Accuracy: 0.95985\n",
      "1563/1563 [==============================] - 1s 776us/step\n",
      "Total correct: 47409\n",
      "Total incorrect: 2591\n",
      "Total samples: 50000\n",
      "Keras Excited Accuracy: 0.94818\n",
      "1563/1563 [==============================] - 1s 760us/step\n",
      "Total correct: 48576\n",
      "Total incorrect: 1424\n",
      "Total samples: 50000\n",
      "Keras Ground Accuracy: 0.97152\n",
      "\n",
      "===================================\n",
      "Fidelity 0.9598500000000001\n",
      "===================================\n",
      "Epoch 1/50\n",
      "105/105 - 1s - loss: 0.1749 - accuracy: 0.9601 - val_loss: 0.1757 - val_accuracy: 0.9583 - lr: 1.0000e-04 - 1s/epoch - 14ms/step\n",
      "Epoch 2/50\n",
      "105/105 - 1s - loss: 0.1741 - accuracy: 0.9604 - val_loss: 0.1751 - val_accuracy: 0.9583 - lr: 1.0000e-04 - 880ms/epoch - 8ms/step\n",
      "Epoch 3/50\n",
      "105/105 - 1s - loss: 0.1735 - accuracy: 0.9605 - val_loss: 0.1748 - val_accuracy: 0.9586 - lr: 1.0000e-04 - 885ms/epoch - 8ms/step\n",
      "Epoch 4/50\n",
      "105/105 - 1s - loss: 0.1731 - accuracy: 0.9606 - val_loss: 0.1745 - val_accuracy: 0.9586 - lr: 1.0000e-04 - 892ms/epoch - 8ms/step\n",
      "Epoch 5/50\n",
      "105/105 - 1s - loss: 0.1728 - accuracy: 0.9607 - val_loss: 0.1743 - val_accuracy: 0.9587 - lr: 1.0000e-04 - 891ms/epoch - 8ms/step\n",
      "Epoch 6/50\n",
      "105/105 - 1s - loss: 0.1726 - accuracy: 0.9607 - val_loss: 0.1742 - val_accuracy: 0.9587 - lr: 1.0000e-04 - 895ms/epoch - 9ms/step\n",
      "Epoch 7/50\n",
      "105/105 - 1s - loss: 0.1724 - accuracy: 0.9608 - val_loss: 0.1741 - val_accuracy: 0.9587 - lr: 1.0000e-04 - 905ms/epoch - 9ms/step\n",
      "Epoch 8/50\n",
      "105/105 - 1s - loss: 0.1723 - accuracy: 0.9608 - val_loss: 0.1740 - val_accuracy: 0.9588 - lr: 1.0000e-04 - 898ms/epoch - 9ms/step\n",
      "Epoch 9/50\n",
      "105/105 - 1s - loss: 0.1722 - accuracy: 0.9608 - val_loss: 0.1740 - val_accuracy: 0.9588 - lr: 1.0000e-04 - 901ms/epoch - 9ms/step\n",
      "Epoch 10/50\n",
      "105/105 - 1s - loss: 0.1722 - accuracy: 0.9608 - val_loss: 0.1739 - val_accuracy: 0.9588 - lr: 1.0000e-04 - 904ms/epoch - 9ms/step\n",
      "Epoch 11/50\n",
      "105/105 - 1s - loss: 0.1721 - accuracy: 0.9608 - val_loss: 0.1739 - val_accuracy: 0.9588 - lr: 1.0000e-04 - 901ms/epoch - 9ms/step\n",
      "Epoch 12/50\n",
      "105/105 - 1s - loss: 0.1720 - accuracy: 0.9609 - val_loss: 0.1739 - val_accuracy: 0.9588 - lr: 1.0000e-04 - 903ms/epoch - 9ms/step\n",
      "Epoch 13/50\n",
      "105/105 - 1s - loss: 0.1720 - accuracy: 0.9609 - val_loss: 0.1739 - val_accuracy: 0.9589 - lr: 1.0000e-04 - 905ms/epoch - 9ms/step\n",
      "Epoch 14/50\n",
      "105/105 - 1s - loss: 0.1719 - accuracy: 0.9609 - val_loss: 0.1738 - val_accuracy: 0.9589 - lr: 1.0000e-04 - 884ms/epoch - 8ms/step\n",
      "Epoch 15/50\n",
      "105/105 - 1s - loss: 0.1719 - accuracy: 0.9609 - val_loss: 0.1738 - val_accuracy: 0.9589 - lr: 1.0000e-04 - 889ms/epoch - 8ms/step\n",
      "Epoch 16/50\n",
      "105/105 - 1s - loss: 0.1718 - accuracy: 0.9609 - val_loss: 0.1738 - val_accuracy: 0.9590 - lr: 1.0000e-04 - 891ms/epoch - 8ms/step\n",
      "Epoch 17/50\n",
      "105/105 - 1s - loss: 0.1718 - accuracy: 0.9609 - val_loss: 0.1737 - val_accuracy: 0.9589 - lr: 1.0000e-04 - 899ms/epoch - 9ms/step\n",
      "Epoch 18/50\n",
      "105/105 - 1s - loss: 0.1718 - accuracy: 0.9609 - val_loss: 0.1737 - val_accuracy: 0.9589 - lr: 1.0000e-04 - 914ms/epoch - 9ms/step\n",
      "Epoch 19/50\n",
      "105/105 - 1s - loss: 0.1718 - accuracy: 0.9609 - val_loss: 0.1737 - val_accuracy: 0.9590 - lr: 1.0000e-04 - 900ms/epoch - 9ms/step\n",
      "Epoch 20/50\n",
      "105/105 - 1s - loss: 0.1717 - accuracy: 0.9610 - val_loss: 0.1737 - val_accuracy: 0.9591 - lr: 1.0000e-04 - 876ms/epoch - 8ms/step\n",
      "Epoch 21/50\n",
      "105/105 - 1s - loss: 0.1717 - accuracy: 0.9610 - val_loss: 0.1736 - val_accuracy: 0.9590 - lr: 1.0000e-04 - 870ms/epoch - 8ms/step\n",
      "Epoch 22/50\n",
      "105/105 - 1s - loss: 0.1717 - accuracy: 0.9610 - val_loss: 0.1736 - val_accuracy: 0.9590 - lr: 1.0000e-04 - 875ms/epoch - 8ms/step\n",
      "Epoch 23/50\n",
      "105/105 - 1s - loss: 0.1717 - accuracy: 0.9609 - val_loss: 0.1736 - val_accuracy: 0.9590 - lr: 1.0000e-04 - 895ms/epoch - 9ms/step\n",
      "Epoch 24/50\n",
      "105/105 - 1s - loss: 0.1716 - accuracy: 0.9610 - val_loss: 0.1736 - val_accuracy: 0.9590 - lr: 1.0000e-04 - 896ms/epoch - 9ms/step\n",
      "Epoch 25/50\n",
      "105/105 - 1s - loss: 0.1716 - accuracy: 0.9610 - val_loss: 0.1735 - val_accuracy: 0.9590 - lr: 1.0000e-04 - 880ms/epoch - 8ms/step\n",
      "Epoch 26/50\n",
      "105/105 - 1s - loss: 0.1715 - accuracy: 0.9610 - val_loss: 0.1735 - val_accuracy: 0.9590 - lr: 1.0000e-04 - 881ms/epoch - 8ms/step\n",
      "Epoch 27/50\n",
      "105/105 - 1s - loss: 0.1716 - accuracy: 0.9610 - val_loss: 0.1735 - val_accuracy: 0.9589 - lr: 1.0000e-04 - 904ms/epoch - 9ms/step\n",
      "Epoch 28/50\n",
      "105/105 - 1s - loss: 0.1715 - accuracy: 0.9610 - val_loss: 0.1735 - val_accuracy: 0.9589 - lr: 1.0000e-04 - 906ms/epoch - 9ms/step\n",
      "Epoch 29/50\n",
      "105/105 - 1s - loss: 0.1715 - accuracy: 0.9610 - val_loss: 0.1735 - val_accuracy: 0.9589 - lr: 1.0000e-04 - 884ms/epoch - 8ms/step\n",
      "Epoch 30/50\n",
      "105/105 - 1s - loss: 0.1715 - accuracy: 0.9610 - val_loss: 0.1734 - val_accuracy: 0.9590 - lr: 1.0000e-04 - 887ms/epoch - 8ms/step\n",
      "Epoch 31/50\n",
      "105/105 - 1s - loss: 0.1715 - accuracy: 0.9611 - val_loss: 0.1734 - val_accuracy: 0.9590 - lr: 1.0000e-04 - 864ms/epoch - 8ms/step\n",
      "Epoch 32/50\n",
      "105/105 - 1s - loss: 0.1714 - accuracy: 0.9611 - val_loss: 0.1734 - val_accuracy: 0.9589 - lr: 1.0000e-04 - 872ms/epoch - 8ms/step\n",
      "Epoch 33/50\n",
      "105/105 - 1s - loss: 0.1714 - accuracy: 0.9611 - val_loss: 0.1733 - val_accuracy: 0.9589 - lr: 1.0000e-04 - 882ms/epoch - 8ms/step\n",
      "Epoch 34/50\n",
      "105/105 - 1s - loss: 0.1714 - accuracy: 0.9611 - val_loss: 0.1733 - val_accuracy: 0.9589 - lr: 1.0000e-04 - 884ms/epoch - 8ms/step\n",
      "Epoch 35/50\n",
      "105/105 - 1s - loss: 0.1714 - accuracy: 0.9610 - val_loss: 0.1733 - val_accuracy: 0.9589 - lr: 1.0000e-04 - 898ms/epoch - 9ms/step\n",
      "Epoch 36/50\n",
      "105/105 - 1s - loss: 0.1714 - accuracy: 0.9611 - val_loss: 0.1733 - val_accuracy: 0.9590 - lr: 1.0000e-04 - 890ms/epoch - 8ms/step\n",
      "Epoch 37/50\n",
      "105/105 - 1s - loss: 0.1713 - accuracy: 0.9611 - val_loss: 0.1733 - val_accuracy: 0.9590 - lr: 1.0000e-04 - 870ms/epoch - 8ms/step\n",
      "Epoch 38/50\n",
      "105/105 - 1s - loss: 0.1713 - accuracy: 0.9611 - val_loss: 0.1733 - val_accuracy: 0.9590 - lr: 1.0000e-04 - 887ms/epoch - 8ms/step\n",
      "Epoch 39/50\n",
      "105/105 - 1s - loss: 0.1713 - accuracy: 0.9611 - val_loss: 0.1732 - val_accuracy: 0.9590 - lr: 1.0000e-04 - 895ms/epoch - 9ms/step\n",
      "Epoch 40/50\n",
      "105/105 - 1s - loss: 0.1713 - accuracy: 0.9611 - val_loss: 0.1732 - val_accuracy: 0.9590 - lr: 1.0000e-04 - 882ms/epoch - 8ms/step\n",
      "Epoch 41/50\n",
      "105/105 - 1s - loss: 0.1713 - accuracy: 0.9611 - val_loss: 0.1732 - val_accuracy: 0.9590 - lr: 1.0000e-04 - 881ms/epoch - 8ms/step\n",
      "Epoch 42/50\n",
      "105/105 - 1s - loss: 0.1713 - accuracy: 0.9611 - val_loss: 0.1732 - val_accuracy: 0.9590 - lr: 1.0000e-04 - 890ms/epoch - 8ms/step\n",
      "Epoch 43/50\n",
      "105/105 - 1s - loss: 0.1713 - accuracy: 0.9611 - val_loss: 0.1732 - val_accuracy: 0.9591 - lr: 1.0000e-04 - 888ms/epoch - 8ms/step\n",
      "Epoch 44/50\n",
      "105/105 - 1s - loss: 0.1712 - accuracy: 0.9611 - val_loss: 0.1731 - val_accuracy: 0.9591 - lr: 1.0000e-04 - 873ms/epoch - 8ms/step\n",
      "Epoch 45/50\n",
      "105/105 - 1s - loss: 0.1712 - accuracy: 0.9611 - val_loss: 0.1731 - val_accuracy: 0.9591 - lr: 1.0000e-04 - 886ms/epoch - 8ms/step\n",
      "Epoch 46/50\n",
      "105/105 - 1s - loss: 0.1712 - accuracy: 0.9611 - val_loss: 0.1731 - val_accuracy: 0.9587 - lr: 1.0000e-04 - 895ms/epoch - 9ms/step\n",
      "Epoch 47/50\n",
      "105/105 - 1s - loss: 0.1712 - accuracy: 0.9611 - val_loss: 0.1731 - val_accuracy: 0.9587 - lr: 1.0000e-04 - 885ms/epoch - 8ms/step\n",
      "Epoch 48/50\n",
      "105/105 - 1s - loss: 0.1712 - accuracy: 0.9611 - val_loss: 0.1731 - val_accuracy: 0.9588 - lr: 1.0000e-04 - 898ms/epoch - 9ms/step\n",
      "Epoch 49/50\n",
      "105/105 - 1s - loss: 0.1712 - accuracy: 0.9611 - val_loss: 0.1730 - val_accuracy: 0.9588 - lr: 1.0000e-04 - 878ms/epoch - 8ms/step\n",
      "Epoch 50/50\n",
      "105/105 - 1s - loss: 0.1712 - accuracy: 0.9611 - val_loss: 0.1730 - val_accuracy: 0.9588 - lr: 1.0000e-04 - 887ms/epoch - 8ms/step\n",
      "3125/3125 [==============================] - 3s 799us/step\n",
      "Keras  Accuracy: 0.95973\n",
      "1563/1563 [==============================] - 1s 867us/step\n",
      "Total correct: 47338\n",
      "Total incorrect: 2662\n",
      "Total samples: 50000\n",
      "Keras Excited Accuracy: 0.94676\n",
      "1563/1563 [==============================] - 1s 825us/step\n",
      "Total correct: 48635\n",
      "Total incorrect: 1365\n",
      "Total samples: 50000\n",
      "Keras Ground Accuracy: 0.9727\n",
      "\n",
      "===================================\n",
      "Fidelity 0.95973\n",
      "===================================\n",
      "Epoch 1/50\n",
      "105/105 - 1s - loss: 0.1811 - accuracy: 0.9584 - val_loss: 0.1809 - val_accuracy: 0.9571 - lr: 1.0000e-04 - 1s/epoch - 14ms/step\n",
      "Epoch 2/50\n",
      "105/105 - 1s - loss: 0.1796 - accuracy: 0.9588 - val_loss: 0.1800 - val_accuracy: 0.9574 - lr: 1.0000e-04 - 875ms/epoch - 8ms/step\n",
      "Epoch 3/50\n",
      "105/105 - 1s - loss: 0.1787 - accuracy: 0.9591 - val_loss: 0.1793 - val_accuracy: 0.9578 - lr: 1.0000e-04 - 877ms/epoch - 8ms/step\n",
      "Epoch 4/50\n",
      "105/105 - 1s - loss: 0.1779 - accuracy: 0.9593 - val_loss: 0.1789 - val_accuracy: 0.9578 - lr: 1.0000e-04 - 882ms/epoch - 8ms/step\n",
      "Epoch 5/50\n",
      "105/105 - 1s - loss: 0.1774 - accuracy: 0.9594 - val_loss: 0.1786 - val_accuracy: 0.9580 - lr: 1.0000e-04 - 893ms/epoch - 9ms/step\n",
      "Epoch 6/50\n",
      "105/105 - 1s - loss: 0.1771 - accuracy: 0.9595 - val_loss: 0.1784 - val_accuracy: 0.9580 - lr: 1.0000e-04 - 893ms/epoch - 9ms/step\n",
      "Epoch 7/50\n",
      "105/105 - 1s - loss: 0.1768 - accuracy: 0.9595 - val_loss: 0.1782 - val_accuracy: 0.9580 - lr: 1.0000e-04 - 882ms/epoch - 8ms/step\n",
      "Epoch 8/50\n",
      "105/105 - 1s - loss: 0.1766 - accuracy: 0.9596 - val_loss: 0.1781 - val_accuracy: 0.9579 - lr: 1.0000e-04 - 898ms/epoch - 9ms/step\n",
      "Epoch 9/50\n",
      "105/105 - 1s - loss: 0.1764 - accuracy: 0.9596 - val_loss: 0.1781 - val_accuracy: 0.9578 - lr: 1.0000e-04 - 885ms/epoch - 8ms/step\n",
      "Epoch 10/50\n",
      "105/105 - 1s - loss: 0.1763 - accuracy: 0.9596 - val_loss: 0.1780 - val_accuracy: 0.9579 - lr: 1.0000e-04 - 909ms/epoch - 9ms/step\n",
      "Epoch 11/50\n",
      "105/105 - 1s - loss: 0.1762 - accuracy: 0.9597 - val_loss: 0.1780 - val_accuracy: 0.9579 - lr: 1.0000e-04 - 904ms/epoch - 9ms/step\n",
      "Epoch 12/50\n",
      "105/105 - 1s - loss: 0.1761 - accuracy: 0.9597 - val_loss: 0.1779 - val_accuracy: 0.9578 - lr: 1.0000e-04 - 876ms/epoch - 8ms/step\n",
      "Epoch 13/50\n",
      "105/105 - 1s - loss: 0.1761 - accuracy: 0.9597 - val_loss: 0.1779 - val_accuracy: 0.9579 - lr: 1.0000e-04 - 892ms/epoch - 8ms/step\n",
      "Epoch 14/50\n",
      "105/105 - 1s - loss: 0.1760 - accuracy: 0.9597 - val_loss: 0.1779 - val_accuracy: 0.9579 - lr: 1.0000e-04 - 889ms/epoch - 8ms/step\n",
      "Epoch 15/50\n",
      "105/105 - 1s - loss: 0.1759 - accuracy: 0.9598 - val_loss: 0.1779 - val_accuracy: 0.9579 - lr: 1.0000e-04 - 886ms/epoch - 8ms/step\n",
      "Epoch 16/50\n",
      "105/105 - 1s - loss: 0.1759 - accuracy: 0.9598 - val_loss: 0.1778 - val_accuracy: 0.9579 - lr: 1.0000e-04 - 887ms/epoch - 8ms/step\n",
      "Epoch 17/50\n",
      "105/105 - 1s - loss: 0.1759 - accuracy: 0.9598 - val_loss: 0.1778 - val_accuracy: 0.9579 - lr: 1.0000e-04 - 886ms/epoch - 8ms/step\n",
      "Epoch 18/50\n",
      "105/105 - 1s - loss: 0.1758 - accuracy: 0.9598 - val_loss: 0.1778 - val_accuracy: 0.9580 - lr: 1.0000e-04 - 887ms/epoch - 8ms/step\n",
      "Epoch 19/50\n",
      "105/105 - 1s - loss: 0.1758 - accuracy: 0.9598 - val_loss: 0.1778 - val_accuracy: 0.9579 - lr: 1.0000e-04 - 889ms/epoch - 8ms/step\n",
      "Epoch 20/50\n",
      "105/105 - 1s - loss: 0.1757 - accuracy: 0.9598 - val_loss: 0.1777 - val_accuracy: 0.9579 - lr: 1.0000e-04 - 889ms/epoch - 8ms/step\n",
      "Epoch 21/50\n",
      "105/105 - 1s - loss: 0.1757 - accuracy: 0.9598 - val_loss: 0.1777 - val_accuracy: 0.9579 - lr: 1.0000e-04 - 902ms/epoch - 9ms/step\n",
      "Epoch 22/50\n",
      "105/105 - 1s - loss: 0.1757 - accuracy: 0.9599 - val_loss: 0.1777 - val_accuracy: 0.9579 - lr: 1.0000e-04 - 888ms/epoch - 8ms/step\n",
      "Epoch 23/50\n",
      "105/105 - 1s - loss: 0.1756 - accuracy: 0.9598 - val_loss: 0.1776 - val_accuracy: 0.9579 - lr: 1.0000e-04 - 872ms/epoch - 8ms/step\n",
      "Epoch 24/50\n",
      "105/105 - 1s - loss: 0.1756 - accuracy: 0.9598 - val_loss: 0.1776 - val_accuracy: 0.9579 - lr: 1.0000e-04 - 855ms/epoch - 8ms/step\n",
      "Epoch 25/50\n",
      "105/105 - 1s - loss: 0.1756 - accuracy: 0.9599 - val_loss: 0.1776 - val_accuracy: 0.9578 - lr: 1.0000e-04 - 886ms/epoch - 8ms/step\n",
      "Epoch 26/50\n",
      "105/105 - 1s - loss: 0.1755 - accuracy: 0.9599 - val_loss: 0.1775 - val_accuracy: 0.9578 - lr: 1.0000e-04 - 892ms/epoch - 8ms/step\n",
      "Epoch 27/50\n",
      "105/105 - 1s - loss: 0.1755 - accuracy: 0.9599 - val_loss: 0.1775 - val_accuracy: 0.9578 - lr: 1.0000e-04 - 896ms/epoch - 9ms/step\n",
      "Epoch 28/50\n",
      "105/105 - 1s - loss: 0.1755 - accuracy: 0.9599 - val_loss: 0.1775 - val_accuracy: 0.9578 - lr: 1.0000e-04 - 902ms/epoch - 9ms/step\n",
      "Epoch 29/50\n",
      "105/105 - 1s - loss: 0.1754 - accuracy: 0.9599 - val_loss: 0.1774 - val_accuracy: 0.9578 - lr: 1.0000e-04 - 888ms/epoch - 8ms/step\n",
      "Epoch 30/50\n",
      "105/105 - 1s - loss: 0.1754 - accuracy: 0.9599 - val_loss: 0.1774 - val_accuracy: 0.9578 - lr: 1.0000e-04 - 865ms/epoch - 8ms/step\n",
      "Epoch 31/50\n",
      "105/105 - 1s - loss: 0.1754 - accuracy: 0.9599 - val_loss: 0.1774 - val_accuracy: 0.9578 - lr: 1.0000e-04 - 903ms/epoch - 9ms/step\n",
      "Epoch 32/50\n",
      "105/105 - 1s - loss: 0.1754 - accuracy: 0.9599 - val_loss: 0.1774 - val_accuracy: 0.9578 - lr: 1.0000e-04 - 908ms/epoch - 9ms/step\n",
      "Epoch 33/50\n",
      "105/105 - 1s - loss: 0.1753 - accuracy: 0.9599 - val_loss: 0.1773 - val_accuracy: 0.9578 - lr: 1.0000e-04 - 874ms/epoch - 8ms/step\n",
      "Epoch 34/50\n",
      "105/105 - 1s - loss: 0.1753 - accuracy: 0.9599 - val_loss: 0.1773 - val_accuracy: 0.9578 - lr: 1.0000e-04 - 875ms/epoch - 8ms/step\n",
      "Epoch 35/50\n",
      "105/105 - 1s - loss: 0.1753 - accuracy: 0.9599 - val_loss: 0.1773 - val_accuracy: 0.9576 - lr: 1.0000e-04 - 881ms/epoch - 8ms/step\n",
      "Epoch 36/50\n",
      "105/105 - 1s - loss: 0.1753 - accuracy: 0.9599 - val_loss: 0.1773 - val_accuracy: 0.9577 - lr: 1.0000e-04 - 897ms/epoch - 9ms/step\n",
      "Epoch 37/50\n",
      "105/105 - 1s - loss: 0.1752 - accuracy: 0.9599 - val_loss: 0.1772 - val_accuracy: 0.9576 - lr: 1.0000e-04 - 890ms/epoch - 8ms/step\n",
      "Epoch 38/50\n",
      "105/105 - 1s - loss: 0.1752 - accuracy: 0.9599 - val_loss: 0.1772 - val_accuracy: 0.9576 - lr: 1.0000e-04 - 886ms/epoch - 8ms/step\n",
      "Epoch 39/50\n",
      "105/105 - 1s - loss: 0.1752 - accuracy: 0.9599 - val_loss: 0.1772 - val_accuracy: 0.9577 - lr: 1.0000e-04 - 871ms/epoch - 8ms/step\n",
      "Epoch 40/50\n",
      "105/105 - 1s - loss: 0.1752 - accuracy: 0.9599 - val_loss: 0.1772 - val_accuracy: 0.9576 - lr: 1.0000e-04 - 879ms/epoch - 8ms/step\n",
      "Epoch 41/50\n",
      "105/105 - 1s - loss: 0.1752 - accuracy: 0.9599 - val_loss: 0.1771 - val_accuracy: 0.9576 - lr: 1.0000e-04 - 891ms/epoch - 8ms/step\n",
      "Epoch 42/50\n",
      "105/105 - 1s - loss: 0.1752 - accuracy: 0.9599 - val_loss: 0.1771 - val_accuracy: 0.9576 - lr: 1.0000e-04 - 865ms/epoch - 8ms/step\n",
      "Epoch 43/50\n",
      "105/105 - 1s - loss: 0.1751 - accuracy: 0.9599 - val_loss: 0.1771 - val_accuracy: 0.9576 - lr: 1.0000e-04 - 852ms/epoch - 8ms/step\n",
      "Epoch 44/50\n",
      "105/105 - 1s - loss: 0.1752 - accuracy: 0.9599 - val_loss: 0.1771 - val_accuracy: 0.9576 - lr: 1.0000e-04 - 899ms/epoch - 9ms/step\n",
      "Epoch 45/50\n",
      "105/105 - 1s - loss: 0.1751 - accuracy: 0.9599 - val_loss: 0.1771 - val_accuracy: 0.9577 - lr: 1.0000e-04 - 915ms/epoch - 9ms/step\n",
      "Epoch 46/50\n",
      "105/105 - 1s - loss: 0.1751 - accuracy: 0.9599 - val_loss: 0.1770 - val_accuracy: 0.9577 - lr: 1.0000e-04 - 894ms/epoch - 9ms/step\n",
      "Epoch 47/50\n",
      "105/105 - 1s - loss: 0.1751 - accuracy: 0.9599 - val_loss: 0.1770 - val_accuracy: 0.9576 - lr: 1.0000e-04 - 898ms/epoch - 9ms/step\n",
      "Epoch 48/50\n",
      "105/105 - 1s - loss: 0.1750 - accuracy: 0.9599 - val_loss: 0.1770 - val_accuracy: 0.9576 - lr: 1.0000e-04 - 908ms/epoch - 9ms/step\n",
      "Epoch 49/50\n",
      "105/105 - 1s - loss: 0.1751 - accuracy: 0.9599 - val_loss: 0.1770 - val_accuracy: 0.9576 - lr: 1.0000e-04 - 900ms/epoch - 9ms/step\n",
      "Epoch 50/50\n",
      "105/105 - 1s - loss: 0.1750 - accuracy: 0.9600 - val_loss: 0.1770 - val_accuracy: 0.9577 - lr: 1.0000e-04 - 888ms/epoch - 8ms/step\n",
      "3125/3125 [==============================] - 2s 735us/step\n",
      "Keras  Accuracy: 0.95769\n",
      "1563/1563 [==============================] - 1s 878us/step\n",
      "Total correct: 47128\n",
      "Total incorrect: 2872\n",
      "Total samples: 50000\n",
      "Keras Excited Accuracy: 0.94256\n",
      "1563/1563 [==============================] - 1s 749us/step\n",
      "Total correct: 48641\n",
      "Total incorrect: 1359\n",
      "Total samples: 50000\n",
      "Keras Ground Accuracy: 0.97282\n",
      "\n",
      "===================================\n",
      "Fidelity 0.9576899999999999\n",
      "===================================\n",
      "Epoch 1/50\n",
      "105/105 - 1s - loss: 0.1885 - accuracy: 0.9559 - val_loss: 0.1897 - val_accuracy: 0.9541 - lr: 1.0000e-04 - 1s/epoch - 14ms/step\n",
      "Epoch 2/50\n",
      "105/105 - 1s - loss: 0.1867 - accuracy: 0.9564 - val_loss: 0.1884 - val_accuracy: 0.9545 - lr: 1.0000e-04 - 885ms/epoch - 8ms/step\n",
      "Epoch 3/50\n",
      "105/105 - 1s - loss: 0.1854 - accuracy: 0.9568 - val_loss: 0.1874 - val_accuracy: 0.9548 - lr: 1.0000e-04 - 895ms/epoch - 9ms/step\n",
      "Epoch 4/50\n",
      "105/105 - 1s - loss: 0.1845 - accuracy: 0.9571 - val_loss: 0.1866 - val_accuracy: 0.9551 - lr: 1.0000e-04 - 891ms/epoch - 8ms/step\n",
      "Epoch 5/50\n",
      "105/105 - 1s - loss: 0.1838 - accuracy: 0.9573 - val_loss: 0.1861 - val_accuracy: 0.9554 - lr: 1.0000e-04 - 909ms/epoch - 9ms/step\n",
      "Epoch 6/50\n",
      "105/105 - 1s - loss: 0.1834 - accuracy: 0.9574 - val_loss: 0.1858 - val_accuracy: 0.9556 - lr: 1.0000e-04 - 894ms/epoch - 9ms/step\n",
      "Epoch 7/50\n",
      "105/105 - 1s - loss: 0.1830 - accuracy: 0.9575 - val_loss: 0.1855 - val_accuracy: 0.9556 - lr: 1.0000e-04 - 863ms/epoch - 8ms/step\n",
      "Epoch 8/50\n",
      "105/105 - 1s - loss: 0.1827 - accuracy: 0.9576 - val_loss: 0.1853 - val_accuracy: 0.9558 - lr: 1.0000e-04 - 887ms/epoch - 8ms/step\n",
      "Epoch 9/50\n",
      "105/105 - 1s - loss: 0.1825 - accuracy: 0.9576 - val_loss: 0.1852 - val_accuracy: 0.9560 - lr: 1.0000e-04 - 889ms/epoch - 8ms/step\n",
      "Epoch 10/50\n",
      "105/105 - 1s - loss: 0.1823 - accuracy: 0.9577 - val_loss: 0.1851 - val_accuracy: 0.9560 - lr: 1.0000e-04 - 884ms/epoch - 8ms/step\n",
      "Epoch 11/50\n",
      "105/105 - 1s - loss: 0.1822 - accuracy: 0.9577 - val_loss: 0.1850 - val_accuracy: 0.9560 - lr: 1.0000e-04 - 879ms/epoch - 8ms/step\n",
      "Epoch 12/50\n",
      "105/105 - 1s - loss: 0.1820 - accuracy: 0.9578 - val_loss: 0.1849 - val_accuracy: 0.9561 - lr: 1.0000e-04 - 883ms/epoch - 8ms/step\n",
      "Epoch 13/50\n",
      "105/105 - 1s - loss: 0.1819 - accuracy: 0.9578 - val_loss: 0.1848 - val_accuracy: 0.9561 - lr: 1.0000e-04 - 883ms/epoch - 8ms/step\n",
      "Epoch 14/50\n",
      "105/105 - 1s - loss: 0.1819 - accuracy: 0.9578 - val_loss: 0.1848 - val_accuracy: 0.9560 - lr: 1.0000e-04 - 886ms/epoch - 8ms/step\n",
      "Epoch 15/50\n",
      "105/105 - 1s - loss: 0.1818 - accuracy: 0.9579 - val_loss: 0.1847 - val_accuracy: 0.9561 - lr: 1.0000e-04 - 889ms/epoch - 8ms/step\n",
      "Epoch 16/50\n",
      "105/105 - 1s - loss: 0.1818 - accuracy: 0.9578 - val_loss: 0.1847 - val_accuracy: 0.9561 - lr: 1.0000e-04 - 899ms/epoch - 9ms/step\n",
      "Epoch 17/50\n",
      "105/105 - 1s - loss: 0.1817 - accuracy: 0.9578 - val_loss: 0.1846 - val_accuracy: 0.9561 - lr: 1.0000e-04 - 877ms/epoch - 8ms/step\n",
      "Epoch 18/50\n",
      "105/105 - 1s - loss: 0.1816 - accuracy: 0.9579 - val_loss: 0.1845 - val_accuracy: 0.9561 - lr: 1.0000e-04 - 893ms/epoch - 9ms/step\n",
      "Epoch 19/50\n",
      "105/105 - 1s - loss: 0.1816 - accuracy: 0.9579 - val_loss: 0.1845 - val_accuracy: 0.9562 - lr: 1.0000e-04 - 887ms/epoch - 8ms/step\n",
      "Epoch 20/50\n",
      "105/105 - 1s - loss: 0.1815 - accuracy: 0.9579 - val_loss: 0.1845 - val_accuracy: 0.9561 - lr: 1.0000e-04 - 901ms/epoch - 9ms/step\n",
      "Epoch 21/50\n",
      "105/105 - 1s - loss: 0.1815 - accuracy: 0.9580 - val_loss: 0.1845 - val_accuracy: 0.9561 - lr: 1.0000e-04 - 883ms/epoch - 8ms/step\n",
      "Epoch 22/50\n",
      "105/105 - 1s - loss: 0.1815 - accuracy: 0.9579 - val_loss: 0.1844 - val_accuracy: 0.9561 - lr: 1.0000e-04 - 894ms/epoch - 9ms/step\n",
      "Epoch 23/50\n",
      "105/105 - 1s - loss: 0.1814 - accuracy: 0.9580 - val_loss: 0.1844 - val_accuracy: 0.9561 - lr: 1.0000e-04 - 901ms/epoch - 9ms/step\n",
      "Epoch 24/50\n",
      "105/105 - 1s - loss: 0.1814 - accuracy: 0.9580 - val_loss: 0.1843 - val_accuracy: 0.9561 - lr: 1.0000e-04 - 887ms/epoch - 8ms/step\n",
      "Epoch 25/50\n",
      "105/105 - 1s - loss: 0.1813 - accuracy: 0.9580 - val_loss: 0.1843 - val_accuracy: 0.9561 - lr: 1.0000e-04 - 878ms/epoch - 8ms/step\n",
      "Epoch 26/50\n",
      "105/105 - 1s - loss: 0.1813 - accuracy: 0.9580 - val_loss: 0.1843 - val_accuracy: 0.9561 - lr: 1.0000e-04 - 882ms/epoch - 8ms/step\n",
      "Epoch 27/50\n",
      "105/105 - 1s - loss: 0.1813 - accuracy: 0.9580 - val_loss: 0.1842 - val_accuracy: 0.9561 - lr: 1.0000e-04 - 866ms/epoch - 8ms/step\n",
      "Epoch 28/50\n",
      "105/105 - 1s - loss: 0.1812 - accuracy: 0.9580 - val_loss: 0.1842 - val_accuracy: 0.9561 - lr: 1.0000e-04 - 889ms/epoch - 8ms/step\n",
      "Epoch 29/50\n",
      "105/105 - 1s - loss: 0.1812 - accuracy: 0.9581 - val_loss: 0.1841 - val_accuracy: 0.9561 - lr: 1.0000e-04 - 873ms/epoch - 8ms/step\n",
      "Epoch 30/50\n",
      "105/105 - 1s - loss: 0.1812 - accuracy: 0.9581 - val_loss: 0.1841 - val_accuracy: 0.9561 - lr: 1.0000e-04 - 905ms/epoch - 9ms/step\n",
      "Epoch 31/50\n",
      "105/105 - 1s - loss: 0.1812 - accuracy: 0.9581 - val_loss: 0.1841 - val_accuracy: 0.9560 - lr: 1.0000e-04 - 939ms/epoch - 9ms/step\n",
      "Epoch 32/50\n",
      "105/105 - 1s - loss: 0.1811 - accuracy: 0.9581 - val_loss: 0.1840 - val_accuracy: 0.9561 - lr: 1.0000e-04 - 898ms/epoch - 9ms/step\n",
      "Epoch 33/50\n",
      "105/105 - 1s - loss: 0.1811 - accuracy: 0.9581 - val_loss: 0.1840 - val_accuracy: 0.9560 - lr: 1.0000e-04 - 999ms/epoch - 10ms/step\n",
      "Epoch 34/50\n",
      "105/105 - 1s - loss: 0.1811 - accuracy: 0.9581 - val_loss: 0.1840 - val_accuracy: 0.9560 - lr: 1.0000e-04 - 890ms/epoch - 8ms/step\n",
      "Epoch 35/50\n",
      "105/105 - 1s - loss: 0.1810 - accuracy: 0.9581 - val_loss: 0.1839 - val_accuracy: 0.9560 - lr: 1.0000e-04 - 897ms/epoch - 9ms/step\n",
      "Epoch 36/50\n",
      "105/105 - 1s - loss: 0.1810 - accuracy: 0.9581 - val_loss: 0.1839 - val_accuracy: 0.9560 - lr: 1.0000e-04 - 897ms/epoch - 9ms/step\n",
      "Epoch 37/50\n",
      "105/105 - 1s - loss: 0.1810 - accuracy: 0.9581 - val_loss: 0.1839 - val_accuracy: 0.9560 - lr: 1.0000e-04 - 941ms/epoch - 9ms/step\n",
      "Epoch 38/50\n",
      "105/105 - 1s - loss: 0.1810 - accuracy: 0.9581 - val_loss: 0.1838 - val_accuracy: 0.9560 - lr: 1.0000e-04 - 881ms/epoch - 8ms/step\n",
      "Epoch 39/50\n",
      "105/105 - 1s - loss: 0.1809 - accuracy: 0.9581 - val_loss: 0.1838 - val_accuracy: 0.9560 - lr: 1.0000e-04 - 886ms/epoch - 8ms/step\n",
      "Epoch 40/50\n",
      "105/105 - 1s - loss: 0.1809 - accuracy: 0.9581 - val_loss: 0.1838 - val_accuracy: 0.9560 - lr: 1.0000e-04 - 865ms/epoch - 8ms/step\n",
      "Epoch 41/50\n",
      "105/105 - 1s - loss: 0.1809 - accuracy: 0.9581 - val_loss: 0.1838 - val_accuracy: 0.9560 - lr: 1.0000e-04 - 986ms/epoch - 9ms/step\n",
      "Epoch 42/50\n",
      "105/105 - 1s - loss: 0.1809 - accuracy: 0.9581 - val_loss: 0.1837 - val_accuracy: 0.9560 - lr: 1.0000e-04 - 880ms/epoch - 8ms/step\n",
      "Epoch 43/50\n",
      "105/105 - 1s - loss: 0.1809 - accuracy: 0.9581 - val_loss: 0.1837 - val_accuracy: 0.9559 - lr: 1.0000e-04 - 875ms/epoch - 8ms/step\n",
      "Epoch 44/50\n",
      "105/105 - 1s - loss: 0.1808 - accuracy: 0.9581 - val_loss: 0.1837 - val_accuracy: 0.9559 - lr: 1.0000e-04 - 870ms/epoch - 8ms/step\n",
      "Epoch 45/50\n",
      "105/105 - 1s - loss: 0.1808 - accuracy: 0.9581 - val_loss: 0.1837 - val_accuracy: 0.9559 - lr: 1.0000e-04 - 883ms/epoch - 8ms/step\n",
      "Epoch 46/50\n",
      "105/105 - 1s - loss: 0.1808 - accuracy: 0.9581 - val_loss: 0.1836 - val_accuracy: 0.9559 - lr: 1.0000e-04 - 879ms/epoch - 8ms/step\n",
      "Epoch 47/50\n",
      "105/105 - 1s - loss: 0.1808 - accuracy: 0.9581 - val_loss: 0.1836 - val_accuracy: 0.9559 - lr: 1.0000e-04 - 891ms/epoch - 8ms/step\n",
      "Epoch 48/50\n",
      "105/105 - 1s - loss: 0.1808 - accuracy: 0.9581 - val_loss: 0.1836 - val_accuracy: 0.9559 - lr: 1.0000e-04 - 848ms/epoch - 8ms/step\n",
      "Epoch 49/50\n",
      "105/105 - 1s - loss: 0.1808 - accuracy: 0.9581 - val_loss: 0.1836 - val_accuracy: 0.9559 - lr: 1.0000e-04 - 954ms/epoch - 9ms/step\n",
      "Epoch 50/50\n",
      "105/105 - 1s - loss: 0.1808 - accuracy: 0.9581 - val_loss: 0.1836 - val_accuracy: 0.9558 - lr: 1.0000e-04 - 889ms/epoch - 8ms/step\n",
      "3125/3125 [==============================] - 2s 725us/step\n",
      "Keras  Accuracy: 0.95521\n",
      "1563/1563 [==============================] - 1s 868us/step\n",
      "Total correct: 46872\n",
      "Total incorrect: 3128\n",
      "Total samples: 50000\n",
      "Keras Excited Accuracy: 0.93744\n",
      "1563/1563 [==============================] - 1s 901us/step\n",
      "Total correct: 48649\n",
      "Total incorrect: 1351\n",
      "Total samples: 50000\n",
      "Keras Ground Accuracy: 0.97298\n",
      "\n",
      "===================================\n",
      "Fidelity 0.95521\n",
      "===================================\n",
      "Epoch 1/50\n",
      "105/105 - 1s - loss: 0.1967 - accuracy: 0.9532 - val_loss: 0.1988 - val_accuracy: 0.9514 - lr: 1.0000e-04 - 1s/epoch - 14ms/step\n",
      "Epoch 2/50\n",
      "105/105 - 1s - loss: 0.1947 - accuracy: 0.9537 - val_loss: 0.1973 - val_accuracy: 0.9520 - lr: 1.0000e-04 - 902ms/epoch - 9ms/step\n",
      "Epoch 3/50\n",
      "105/105 - 1s - loss: 0.1933 - accuracy: 0.9541 - val_loss: 0.1961 - val_accuracy: 0.9524 - lr: 1.0000e-04 - 881ms/epoch - 8ms/step\n",
      "Epoch 4/50\n",
      "105/105 - 1s - loss: 0.1924 - accuracy: 0.9544 - val_loss: 0.1952 - val_accuracy: 0.9525 - lr: 1.0000e-04 - 886ms/epoch - 8ms/step\n",
      "Epoch 5/50\n",
      "105/105 - 1s - loss: 0.1916 - accuracy: 0.9546 - val_loss: 0.1946 - val_accuracy: 0.9528 - lr: 1.0000e-04 - 898ms/epoch - 9ms/step\n",
      "Epoch 6/50\n",
      "105/105 - 1s - loss: 0.1910 - accuracy: 0.9547 - val_loss: 0.1941 - val_accuracy: 0.9529 - lr: 1.0000e-04 - 879ms/epoch - 8ms/step\n",
      "Epoch 7/50\n",
      "105/105 - 1s - loss: 0.1906 - accuracy: 0.9549 - val_loss: 0.1938 - val_accuracy: 0.9530 - lr: 1.0000e-04 - 862ms/epoch - 8ms/step\n",
      "Epoch 8/50\n",
      "105/105 - 1s - loss: 0.1903 - accuracy: 0.9549 - val_loss: 0.1935 - val_accuracy: 0.9531 - lr: 1.0000e-04 - 879ms/epoch - 8ms/step\n",
      "Epoch 9/50\n",
      "105/105 - 1s - loss: 0.1900 - accuracy: 0.9550 - val_loss: 0.1933 - val_accuracy: 0.9533 - lr: 1.0000e-04 - 873ms/epoch - 8ms/step\n",
      "Epoch 10/50\n",
      "105/105 - 1s - loss: 0.1898 - accuracy: 0.9551 - val_loss: 0.1932 - val_accuracy: 0.9533 - lr: 1.0000e-04 - 887ms/epoch - 8ms/step\n",
      "Epoch 11/50\n",
      "105/105 - 1s - loss: 0.1896 - accuracy: 0.9552 - val_loss: 0.1931 - val_accuracy: 0.9534 - lr: 1.0000e-04 - 879ms/epoch - 8ms/step\n",
      "Epoch 12/50\n",
      "105/105 - 1s - loss: 0.1895 - accuracy: 0.9552 - val_loss: 0.1930 - val_accuracy: 0.9535 - lr: 1.0000e-04 - 873ms/epoch - 8ms/step\n",
      "Epoch 13/50\n",
      "105/105 - 1s - loss: 0.1894 - accuracy: 0.9552 - val_loss: 0.1929 - val_accuracy: 0.9535 - lr: 1.0000e-04 - 873ms/epoch - 8ms/step\n",
      "Epoch 14/50\n",
      "105/105 - 1s - loss: 0.1893 - accuracy: 0.9553 - val_loss: 0.1928 - val_accuracy: 0.9535 - lr: 1.0000e-04 - 888ms/epoch - 8ms/step\n",
      "Epoch 15/50\n",
      "105/105 - 1s - loss: 0.1892 - accuracy: 0.9553 - val_loss: 0.1927 - val_accuracy: 0.9535 - lr: 1.0000e-04 - 886ms/epoch - 8ms/step\n",
      "Epoch 16/50\n",
      "105/105 - 1s - loss: 0.1891 - accuracy: 0.9553 - val_loss: 0.1927 - val_accuracy: 0.9535 - lr: 1.0000e-04 - 890ms/epoch - 8ms/step\n",
      "Epoch 17/50\n",
      "105/105 - 1s - loss: 0.1891 - accuracy: 0.9553 - val_loss: 0.1926 - val_accuracy: 0.9535 - lr: 1.0000e-04 - 893ms/epoch - 9ms/step\n",
      "Epoch 18/50\n",
      "105/105 - 1s - loss: 0.1890 - accuracy: 0.9553 - val_loss: 0.1925 - val_accuracy: 0.9535 - lr: 1.0000e-04 - 879ms/epoch - 8ms/step\n",
      "Epoch 19/50\n",
      "105/105 - 1s - loss: 0.1889 - accuracy: 0.9554 - val_loss: 0.1925 - val_accuracy: 0.9535 - lr: 1.0000e-04 - 889ms/epoch - 8ms/step\n",
      "Epoch 20/50\n",
      "105/105 - 1s - loss: 0.1889 - accuracy: 0.9554 - val_loss: 0.1924 - val_accuracy: 0.9535 - lr: 1.0000e-04 - 882ms/epoch - 8ms/step\n",
      "Epoch 21/50\n",
      "105/105 - 1s - loss: 0.1888 - accuracy: 0.9554 - val_loss: 0.1924 - val_accuracy: 0.9534 - lr: 1.0000e-04 - 902ms/epoch - 9ms/step\n",
      "Epoch 22/50\n",
      "105/105 - 1s - loss: 0.1888 - accuracy: 0.9554 - val_loss: 0.1924 - val_accuracy: 0.9535 - lr: 1.0000e-04 - 908ms/epoch - 9ms/step\n",
      "Epoch 23/50\n",
      "105/105 - 1s - loss: 0.1887 - accuracy: 0.9554 - val_loss: 0.1923 - val_accuracy: 0.9534 - lr: 1.0000e-04 - 871ms/epoch - 8ms/step\n",
      "Epoch 24/50\n",
      "105/105 - 1s - loss: 0.1887 - accuracy: 0.9554 - val_loss: 0.1923 - val_accuracy: 0.9534 - lr: 1.0000e-04 - 903ms/epoch - 9ms/step\n",
      "Epoch 25/50\n",
      "105/105 - 1s - loss: 0.1887 - accuracy: 0.9555 - val_loss: 0.1922 - val_accuracy: 0.9534 - lr: 1.0000e-04 - 876ms/epoch - 8ms/step\n",
      "Epoch 26/50\n",
      "105/105 - 1s - loss: 0.1886 - accuracy: 0.9555 - val_loss: 0.1922 - val_accuracy: 0.9534 - lr: 1.0000e-04 - 904ms/epoch - 9ms/step\n",
      "Epoch 27/50\n",
      "105/105 - 1s - loss: 0.1886 - accuracy: 0.9555 - val_loss: 0.1921 - val_accuracy: 0.9532 - lr: 1.0000e-04 - 913ms/epoch - 9ms/step\n",
      "Epoch 28/50\n",
      "105/105 - 1s - loss: 0.1885 - accuracy: 0.9555 - val_loss: 0.1921 - val_accuracy: 0.9532 - lr: 1.0000e-04 - 891ms/epoch - 8ms/step\n",
      "Epoch 29/50\n",
      "105/105 - 1s - loss: 0.1885 - accuracy: 0.9555 - val_loss: 0.1920 - val_accuracy: 0.9532 - lr: 1.0000e-04 - 889ms/epoch - 8ms/step\n",
      "Epoch 30/50\n",
      "105/105 - 1s - loss: 0.1884 - accuracy: 0.9556 - val_loss: 0.1920 - val_accuracy: 0.9532 - lr: 1.0000e-04 - 865ms/epoch - 8ms/step\n",
      "Epoch 31/50\n",
      "105/105 - 1s - loss: 0.1884 - accuracy: 0.9555 - val_loss: 0.1919 - val_accuracy: 0.9532 - lr: 1.0000e-04 - 878ms/epoch - 8ms/step\n",
      "Epoch 32/50\n",
      "105/105 - 1s - loss: 0.1884 - accuracy: 0.9556 - val_loss: 0.1919 - val_accuracy: 0.9532 - lr: 1.0000e-04 - 865ms/epoch - 8ms/step\n",
      "Epoch 33/50\n",
      "105/105 - 1s - loss: 0.1884 - accuracy: 0.9556 - val_loss: 0.1919 - val_accuracy: 0.9531 - lr: 1.0000e-04 - 874ms/epoch - 8ms/step\n",
      "Epoch 34/50\n",
      "105/105 - 1s - loss: 0.1883 - accuracy: 0.9556 - val_loss: 0.1918 - val_accuracy: 0.9531 - lr: 1.0000e-04 - 895ms/epoch - 9ms/step\n",
      "Epoch 35/50\n",
      "105/105 - 1s - loss: 0.1883 - accuracy: 0.9556 - val_loss: 0.1918 - val_accuracy: 0.9531 - lr: 1.0000e-04 - 891ms/epoch - 8ms/step\n",
      "Epoch 36/50\n",
      "105/105 - 1s - loss: 0.1883 - accuracy: 0.9556 - val_loss: 0.1918 - val_accuracy: 0.9531 - lr: 1.0000e-04 - 917ms/epoch - 9ms/step\n",
      "Epoch 37/50\n",
      "105/105 - 1s - loss: 0.1883 - accuracy: 0.9556 - val_loss: 0.1917 - val_accuracy: 0.9531 - lr: 1.0000e-04 - 878ms/epoch - 8ms/step\n",
      "Epoch 38/50\n",
      "105/105 - 1s - loss: 0.1882 - accuracy: 0.9556 - val_loss: 0.1917 - val_accuracy: 0.9531 - lr: 1.0000e-04 - 897ms/epoch - 9ms/step\n",
      "Epoch 39/50\n",
      "105/105 - 1s - loss: 0.1882 - accuracy: 0.9556 - val_loss: 0.1917 - val_accuracy: 0.9531 - lr: 1.0000e-04 - 886ms/epoch - 8ms/step\n",
      "Epoch 40/50\n",
      "105/105 - 1s - loss: 0.1882 - accuracy: 0.9556 - val_loss: 0.1917 - val_accuracy: 0.9531 - lr: 1.0000e-04 - 894ms/epoch - 9ms/step\n",
      "Epoch 41/50\n",
      "105/105 - 1s - loss: 0.1882 - accuracy: 0.9556 - val_loss: 0.1916 - val_accuracy: 0.9531 - lr: 1.0000e-04 - 877ms/epoch - 8ms/step\n",
      "Epoch 42/50\n",
      "105/105 - 1s - loss: 0.1881 - accuracy: 0.9556 - val_loss: 0.1916 - val_accuracy: 0.9531 - lr: 1.0000e-04 - 889ms/epoch - 8ms/step\n",
      "Epoch 43/50\n",
      "105/105 - 1s - loss: 0.1881 - accuracy: 0.9556 - val_loss: 0.1916 - val_accuracy: 0.9531 - lr: 1.0000e-04 - 899ms/epoch - 9ms/step\n",
      "Epoch 44/50\n",
      "105/105 - 1s - loss: 0.1881 - accuracy: 0.9556 - val_loss: 0.1915 - val_accuracy: 0.9532 - lr: 1.0000e-04 - 879ms/epoch - 8ms/step\n",
      "Epoch 45/50\n",
      "105/105 - 1s - loss: 0.1881 - accuracy: 0.9556 - val_loss: 0.1915 - val_accuracy: 0.9531 - lr: 1.0000e-04 - 895ms/epoch - 9ms/step\n",
      "Epoch 46/50\n",
      "105/105 - 1s - loss: 0.1881 - accuracy: 0.9556 - val_loss: 0.1915 - val_accuracy: 0.9531 - lr: 1.0000e-04 - 880ms/epoch - 8ms/step\n",
      "Epoch 47/50\n",
      "105/105 - 1s - loss: 0.1880 - accuracy: 0.9556 - val_loss: 0.1915 - val_accuracy: 0.9531 - lr: 1.0000e-04 - 896ms/epoch - 9ms/step\n",
      "Epoch 48/50\n",
      "105/105 - 1s - loss: 0.1880 - accuracy: 0.9556 - val_loss: 0.1915 - val_accuracy: 0.9532 - lr: 1.0000e-04 - 884ms/epoch - 8ms/step\n",
      "Epoch 49/50\n",
      "105/105 - 1s - loss: 0.1880 - accuracy: 0.9556 - val_loss: 0.1914 - val_accuracy: 0.9531 - lr: 1.0000e-04 - 897ms/epoch - 9ms/step\n",
      "Epoch 50/50\n",
      "105/105 - 1s - loss: 0.1880 - accuracy: 0.9556 - val_loss: 0.1914 - val_accuracy: 0.9531 - lr: 1.0000e-04 - 863ms/epoch - 8ms/step\n",
      "3125/3125 [==============================] - 2s 757us/step\n",
      "Keras  Accuracy: 0.95261\n",
      "1563/1563 [==============================] - 1s 811us/step\n",
      "Total correct: 46620\n",
      "Total incorrect: 3380\n",
      "Total samples: 50000\n",
      "Keras Excited Accuracy: 0.9324\n",
      "1563/1563 [==============================] - 2s 964us/step\n",
      "Total correct: 48641\n",
      "Total incorrect: 1359\n",
      "Total samples: 50000\n",
      "Keras Ground Accuracy: 0.97282\n",
      "\n",
      "===================================\n",
      "Fidelity 0.95261\n",
      "===================================\n",
      "Epoch 1/50\n",
      "105/105 - 1s - loss: 0.2053 - accuracy: 0.9503 - val_loss: 0.2081 - val_accuracy: 0.9482 - lr: 1.0000e-04 - 1s/epoch - 14ms/step\n",
      "Epoch 2/50\n",
      "105/105 - 1s - loss: 0.2032 - accuracy: 0.9509 - val_loss: 0.2065 - val_accuracy: 0.9487 - lr: 1.0000e-04 - 868ms/epoch - 8ms/step\n",
      "Epoch 3/50\n",
      "105/105 - 1s - loss: 0.2018 - accuracy: 0.9513 - val_loss: 0.2052 - val_accuracy: 0.9490 - lr: 1.0000e-04 - 886ms/epoch - 8ms/step\n",
      "Epoch 4/50\n",
      "105/105 - 1s - loss: 0.2008 - accuracy: 0.9516 - val_loss: 0.2043 - val_accuracy: 0.9493 - lr: 1.0000e-04 - 878ms/epoch - 8ms/step\n",
      "Epoch 5/50\n",
      "105/105 - 1s - loss: 0.2000 - accuracy: 0.9518 - val_loss: 0.2036 - val_accuracy: 0.9494 - lr: 1.0000e-04 - 891ms/epoch - 8ms/step\n",
      "Epoch 6/50\n",
      "105/105 - 1s - loss: 0.1994 - accuracy: 0.9519 - val_loss: 0.2031 - val_accuracy: 0.9496 - lr: 1.0000e-04 - 879ms/epoch - 8ms/step\n",
      "Epoch 7/50\n",
      "105/105 - 1s - loss: 0.1990 - accuracy: 0.9521 - val_loss: 0.2027 - val_accuracy: 0.9498 - lr: 1.0000e-04 - 888ms/epoch - 8ms/step\n",
      "Epoch 8/50\n",
      "105/105 - 1s - loss: 0.1986 - accuracy: 0.9522 - val_loss: 0.2024 - val_accuracy: 0.9498 - lr: 1.0000e-04 - 882ms/epoch - 8ms/step\n",
      "Epoch 9/50\n",
      "105/105 - 1s - loss: 0.1983 - accuracy: 0.9522 - val_loss: 0.2022 - val_accuracy: 0.9499 - lr: 1.0000e-04 - 881ms/epoch - 8ms/step\n",
      "Epoch 10/50\n",
      "105/105 - 1s - loss: 0.1981 - accuracy: 0.9523 - val_loss: 0.2020 - val_accuracy: 0.9500 - lr: 1.0000e-04 - 885ms/epoch - 8ms/step\n",
      "Epoch 11/50\n",
      "105/105 - 1s - loss: 0.1979 - accuracy: 0.9523 - val_loss: 0.2018 - val_accuracy: 0.9501 - lr: 1.0000e-04 - 901ms/epoch - 9ms/step\n",
      "Epoch 12/50\n",
      "105/105 - 1s - loss: 0.1977 - accuracy: 0.9524 - val_loss: 0.2017 - val_accuracy: 0.9503 - lr: 1.0000e-04 - 884ms/epoch - 8ms/step\n",
      "Epoch 13/50\n",
      "105/105 - 1s - loss: 0.1976 - accuracy: 0.9524 - val_loss: 0.2016 - val_accuracy: 0.9503 - lr: 1.0000e-04 - 884ms/epoch - 8ms/step\n",
      "Epoch 14/50\n",
      "105/105 - 1s - loss: 0.1975 - accuracy: 0.9525 - val_loss: 0.2014 - val_accuracy: 0.9504 - lr: 1.0000e-04 - 891ms/epoch - 8ms/step\n",
      "Epoch 15/50\n",
      "105/105 - 1s - loss: 0.1974 - accuracy: 0.9525 - val_loss: 0.2014 - val_accuracy: 0.9504 - lr: 1.0000e-04 - 888ms/epoch - 8ms/step\n",
      "Epoch 16/50\n",
      "105/105 - 1s - loss: 0.1973 - accuracy: 0.9525 - val_loss: 0.2012 - val_accuracy: 0.9504 - lr: 1.0000e-04 - 864ms/epoch - 8ms/step\n",
      "Epoch 17/50\n",
      "105/105 - 1s - loss: 0.1972 - accuracy: 0.9526 - val_loss: 0.2012 - val_accuracy: 0.9504 - lr: 1.0000e-04 - 857ms/epoch - 8ms/step\n",
      "Epoch 18/50\n",
      "105/105 - 1s - loss: 0.1972 - accuracy: 0.9526 - val_loss: 0.2011 - val_accuracy: 0.9504 - lr: 1.0000e-04 - 880ms/epoch - 8ms/step\n",
      "Epoch 19/50\n",
      "105/105 - 1s - loss: 0.1971 - accuracy: 0.9526 - val_loss: 0.2010 - val_accuracy: 0.9505 - lr: 1.0000e-04 - 871ms/epoch - 8ms/step\n",
      "Epoch 20/50\n",
      "105/105 - 1s - loss: 0.1970 - accuracy: 0.9527 - val_loss: 0.2010 - val_accuracy: 0.9505 - lr: 1.0000e-04 - 892ms/epoch - 8ms/step\n",
      "Epoch 21/50\n",
      "105/105 - 1s - loss: 0.1970 - accuracy: 0.9527 - val_loss: 0.2009 - val_accuracy: 0.9505 - lr: 1.0000e-04 - 880ms/epoch - 8ms/step\n",
      "Epoch 22/50\n",
      "105/105 - 1s - loss: 0.1969 - accuracy: 0.9527 - val_loss: 0.2008 - val_accuracy: 0.9505 - lr: 1.0000e-04 - 886ms/epoch - 8ms/step\n",
      "Epoch 23/50\n",
      "105/105 - 1s - loss: 0.1968 - accuracy: 0.9527 - val_loss: 0.2007 - val_accuracy: 0.9505 - lr: 1.0000e-04 - 870ms/epoch - 8ms/step\n",
      "Epoch 24/50\n",
      "105/105 - 1s - loss: 0.1968 - accuracy: 0.9527 - val_loss: 0.2007 - val_accuracy: 0.9506 - lr: 1.0000e-04 - 881ms/epoch - 8ms/step\n",
      "Epoch 25/50\n",
      "105/105 - 1s - loss: 0.1967 - accuracy: 0.9527 - val_loss: 0.2006 - val_accuracy: 0.9505 - lr: 1.0000e-04 - 876ms/epoch - 8ms/step\n",
      "Epoch 26/50\n",
      "105/105 - 1s - loss: 0.1967 - accuracy: 0.9527 - val_loss: 0.2006 - val_accuracy: 0.9506 - lr: 1.0000e-04 - 888ms/epoch - 8ms/step\n",
      "Epoch 27/50\n",
      "105/105 - 1s - loss: 0.1966 - accuracy: 0.9528 - val_loss: 0.2005 - val_accuracy: 0.9505 - lr: 1.0000e-04 - 866ms/epoch - 8ms/step\n",
      "Epoch 28/50\n",
      "105/105 - 1s - loss: 0.1966 - accuracy: 0.9528 - val_loss: 0.2005 - val_accuracy: 0.9506 - lr: 1.0000e-04 - 878ms/epoch - 8ms/step\n",
      "Epoch 29/50\n",
      "105/105 - 1s - loss: 0.1965 - accuracy: 0.9528 - val_loss: 0.2004 - val_accuracy: 0.9503 - lr: 1.0000e-04 - 887ms/epoch - 8ms/step\n",
      "Epoch 30/50\n",
      "105/105 - 1s - loss: 0.1965 - accuracy: 0.9528 - val_loss: 0.2003 - val_accuracy: 0.9502 - lr: 1.0000e-04 - 885ms/epoch - 8ms/step\n",
      "Epoch 31/50\n",
      "105/105 - 1s - loss: 0.1965 - accuracy: 0.9528 - val_loss: 0.2003 - val_accuracy: 0.9502 - lr: 1.0000e-04 - 883ms/epoch - 8ms/step\n",
      "Epoch 32/50\n",
      "105/105 - 1s - loss: 0.1964 - accuracy: 0.9528 - val_loss: 0.2002 - val_accuracy: 0.9503 - lr: 1.0000e-04 - 886ms/epoch - 8ms/step\n",
      "Epoch 33/50\n",
      "105/105 - 1s - loss: 0.1964 - accuracy: 0.9529 - val_loss: 0.2002 - val_accuracy: 0.9503 - lr: 1.0000e-04 - 880ms/epoch - 8ms/step\n",
      "Epoch 34/50\n",
      "105/105 - 1s - loss: 0.1963 - accuracy: 0.9529 - val_loss: 0.2001 - val_accuracy: 0.9503 - lr: 1.0000e-04 - 890ms/epoch - 8ms/step\n",
      "Epoch 35/50\n",
      "105/105 - 1s - loss: 0.1963 - accuracy: 0.9529 - val_loss: 0.2001 - val_accuracy: 0.9503 - lr: 1.0000e-04 - 889ms/epoch - 8ms/step\n",
      "Epoch 36/50\n",
      "105/105 - 1s - loss: 0.1963 - accuracy: 0.9529 - val_loss: 0.2000 - val_accuracy: 0.9502 - lr: 1.0000e-04 - 886ms/epoch - 8ms/step\n",
      "Epoch 37/50\n",
      "105/105 - 1s - loss: 0.1962 - accuracy: 0.9529 - val_loss: 0.2000 - val_accuracy: 0.9502 - lr: 1.0000e-04 - 875ms/epoch - 8ms/step\n",
      "Epoch 38/50\n",
      "105/105 - 1s - loss: 0.1962 - accuracy: 0.9529 - val_loss: 0.1999 - val_accuracy: 0.9501 - lr: 1.0000e-04 - 873ms/epoch - 8ms/step\n",
      "Epoch 39/50\n",
      "105/105 - 1s - loss: 0.1961 - accuracy: 0.9529 - val_loss: 0.1999 - val_accuracy: 0.9501 - lr: 1.0000e-04 - 891ms/epoch - 8ms/step\n",
      "Epoch 40/50\n",
      "105/105 - 1s - loss: 0.1961 - accuracy: 0.9529 - val_loss: 0.1999 - val_accuracy: 0.9501 - lr: 1.0000e-04 - 889ms/epoch - 8ms/step\n",
      "Epoch 41/50\n",
      "105/105 - 1s - loss: 0.1961 - accuracy: 0.9529 - val_loss: 0.1999 - val_accuracy: 0.9501 - lr: 1.0000e-04 - 887ms/epoch - 8ms/step\n",
      "Epoch 42/50\n",
      "105/105 - 1s - loss: 0.1961 - accuracy: 0.9529 - val_loss: 0.1998 - val_accuracy: 0.9501 - lr: 1.0000e-04 - 858ms/epoch - 8ms/step\n",
      "Epoch 43/50\n",
      "105/105 - 1s - loss: 0.1960 - accuracy: 0.9529 - val_loss: 0.1998 - val_accuracy: 0.9501 - lr: 1.0000e-04 - 878ms/epoch - 8ms/step\n",
      "Epoch 44/50\n",
      "105/105 - 1s - loss: 0.1960 - accuracy: 0.9529 - val_loss: 0.1997 - val_accuracy: 0.9500 - lr: 1.0000e-04 - 877ms/epoch - 8ms/step\n",
      "Epoch 45/50\n",
      "105/105 - 1s - loss: 0.1960 - accuracy: 0.9529 - val_loss: 0.1997 - val_accuracy: 0.9500 - lr: 1.0000e-04 - 873ms/epoch - 8ms/step\n",
      "Epoch 46/50\n",
      "105/105 - 1s - loss: 0.1960 - accuracy: 0.9529 - val_loss: 0.1997 - val_accuracy: 0.9500 - lr: 1.0000e-04 - 886ms/epoch - 8ms/step\n",
      "Epoch 47/50\n",
      "105/105 - 1s - loss: 0.1959 - accuracy: 0.9529 - val_loss: 0.1996 - val_accuracy: 0.9500 - lr: 1.0000e-04 - 886ms/epoch - 8ms/step\n",
      "Epoch 48/50\n",
      "105/105 - 1s - loss: 0.1959 - accuracy: 0.9529 - val_loss: 0.1996 - val_accuracy: 0.9500 - lr: 1.0000e-04 - 887ms/epoch - 8ms/step\n",
      "Epoch 49/50\n",
      "105/105 - 1s - loss: 0.1959 - accuracy: 0.9529 - val_loss: 0.1996 - val_accuracy: 0.9499 - lr: 1.0000e-04 - 888ms/epoch - 8ms/step\n",
      "Epoch 50/50\n",
      "105/105 - 1s - loss: 0.1959 - accuracy: 0.9529 - val_loss: 0.1996 - val_accuracy: 0.9499 - lr: 1.0000e-04 - 879ms/epoch - 8ms/step\n",
      "3125/3125 [==============================] - 2s 731us/step\n",
      "Keras  Accuracy: 0.94944\n",
      "1563/1563 [==============================] - 1s 743us/step\n",
      "Total correct: 46339\n",
      "Total incorrect: 3661\n",
      "Total samples: 50000\n",
      "Keras Excited Accuracy: 0.92678\n",
      "1563/1563 [==============================] - 1s 709us/step\n",
      "Total correct: 48605\n",
      "Total incorrect: 1395\n",
      "Total samples: 50000\n",
      "Keras Ground Accuracy: 0.9721\n",
      "\n",
      "===================================\n",
      "Fidelity 0.9494400000000001\n",
      "===================================\n",
      "Epoch 1/50\n",
      "105/105 - 1s - loss: 0.2138 - accuracy: 0.9474 - val_loss: 0.2166 - val_accuracy: 0.9444 - lr: 1.0000e-04 - 1s/epoch - 14ms/step\n",
      "Epoch 2/50\n",
      "105/105 - 1s - loss: 0.2118 - accuracy: 0.9480 - val_loss: 0.2148 - val_accuracy: 0.9450 - lr: 1.0000e-04 - 868ms/epoch - 8ms/step\n",
      "Epoch 3/50\n",
      "105/105 - 1s - loss: 0.2103 - accuracy: 0.9484 - val_loss: 0.2134 - val_accuracy: 0.9454 - lr: 1.0000e-04 - 881ms/epoch - 8ms/step\n",
      "Epoch 4/50\n",
      "105/105 - 1s - loss: 0.2092 - accuracy: 0.9487 - val_loss: 0.2123 - val_accuracy: 0.9457 - lr: 1.0000e-04 - 899ms/epoch - 9ms/step\n",
      "Epoch 5/50\n",
      "105/105 - 1s - loss: 0.2084 - accuracy: 0.9489 - val_loss: 0.2115 - val_accuracy: 0.9458 - lr: 1.0000e-04 - 868ms/epoch - 8ms/step\n",
      "Epoch 6/50\n",
      "105/105 - 1s - loss: 0.2078 - accuracy: 0.9491 - val_loss: 0.2110 - val_accuracy: 0.9460 - lr: 1.0000e-04 - 869ms/epoch - 8ms/step\n",
      "Epoch 7/50\n",
      "105/105 - 1s - loss: 0.2073 - accuracy: 0.9492 - val_loss: 0.2105 - val_accuracy: 0.9462 - lr: 1.0000e-04 - 869ms/epoch - 8ms/step\n",
      "Epoch 8/50\n",
      "105/105 - 1s - loss: 0.2070 - accuracy: 0.9493 - val_loss: 0.2102 - val_accuracy: 0.9463 - lr: 1.0000e-04 - 886ms/epoch - 8ms/step\n",
      "Epoch 9/50\n",
      "105/105 - 1s - loss: 0.2067 - accuracy: 0.9494 - val_loss: 0.2099 - val_accuracy: 0.9463 - lr: 1.0000e-04 - 878ms/epoch - 8ms/step\n",
      "Epoch 10/50\n",
      "105/105 - 1s - loss: 0.2064 - accuracy: 0.9494 - val_loss: 0.2097 - val_accuracy: 0.9464 - lr: 1.0000e-04 - 890ms/epoch - 8ms/step\n",
      "Epoch 11/50\n",
      "105/105 - 1s - loss: 0.2062 - accuracy: 0.9495 - val_loss: 0.2095 - val_accuracy: 0.9464 - lr: 1.0000e-04 - 886ms/epoch - 8ms/step\n",
      "Epoch 12/50\n",
      "105/105 - 1s - loss: 0.2061 - accuracy: 0.9495 - val_loss: 0.2094 - val_accuracy: 0.9465 - lr: 1.0000e-04 - 888ms/epoch - 8ms/step\n",
      "Epoch 13/50\n",
      "105/105 - 1s - loss: 0.2059 - accuracy: 0.9496 - val_loss: 0.2092 - val_accuracy: 0.9465 - lr: 1.0000e-04 - 874ms/epoch - 8ms/step\n",
      "Epoch 14/50\n",
      "105/105 - 1s - loss: 0.2058 - accuracy: 0.9496 - val_loss: 0.2091 - val_accuracy: 0.9466 - lr: 1.0000e-04 - 887ms/epoch - 8ms/step\n",
      "Epoch 15/50\n",
      "105/105 - 1s - loss: 0.2057 - accuracy: 0.9497 - val_loss: 0.2090 - val_accuracy: 0.9466 - lr: 1.0000e-04 - 876ms/epoch - 8ms/step\n",
      "Epoch 16/50\n",
      "105/105 - 1s - loss: 0.2056 - accuracy: 0.9497 - val_loss: 0.2089 - val_accuracy: 0.9467 - lr: 1.0000e-04 - 887ms/epoch - 8ms/step\n",
      "Epoch 17/50\n",
      "105/105 - 1s - loss: 0.2055 - accuracy: 0.9498 - val_loss: 0.2088 - val_accuracy: 0.9467 - lr: 1.0000e-04 - 889ms/epoch - 8ms/step\n",
      "Epoch 18/50\n",
      "105/105 - 1s - loss: 0.2054 - accuracy: 0.9498 - val_loss: 0.2086 - val_accuracy: 0.9467 - lr: 1.0000e-04 - 881ms/epoch - 8ms/step\n",
      "Epoch 19/50\n",
      "105/105 - 1s - loss: 0.2053 - accuracy: 0.9498 - val_loss: 0.2086 - val_accuracy: 0.9467 - lr: 1.0000e-04 - 893ms/epoch - 9ms/step\n",
      "Epoch 20/50\n",
      "105/105 - 1s - loss: 0.2053 - accuracy: 0.9498 - val_loss: 0.2085 - val_accuracy: 0.9468 - lr: 1.0000e-04 - 856ms/epoch - 8ms/step\n",
      "Epoch 21/50\n",
      "105/105 - 1s - loss: 0.2052 - accuracy: 0.9499 - val_loss: 0.2084 - val_accuracy: 0.9467 - lr: 1.0000e-04 - 888ms/epoch - 8ms/step\n",
      "Epoch 22/50\n",
      "105/105 - 1s - loss: 0.2051 - accuracy: 0.9499 - val_loss: 0.2084 - val_accuracy: 0.9468 - lr: 1.0000e-04 - 873ms/epoch - 8ms/step\n",
      "Epoch 23/50\n",
      "105/105 - 1s - loss: 0.2051 - accuracy: 0.9499 - val_loss: 0.2083 - val_accuracy: 0.9468 - lr: 1.0000e-04 - 871ms/epoch - 8ms/step\n",
      "Epoch 24/50\n",
      "105/105 - 1s - loss: 0.2050 - accuracy: 0.9499 - val_loss: 0.2082 - val_accuracy: 0.9468 - lr: 1.0000e-04 - 880ms/epoch - 8ms/step\n",
      "Epoch 25/50\n",
      "105/105 - 1s - loss: 0.2049 - accuracy: 0.9500 - val_loss: 0.2081 - val_accuracy: 0.9468 - lr: 1.0000e-04 - 891ms/epoch - 8ms/step\n",
      "Epoch 26/50\n",
      "105/105 - 1s - loss: 0.2048 - accuracy: 0.9500 - val_loss: 0.2080 - val_accuracy: 0.9469 - lr: 1.0000e-04 - 892ms/epoch - 8ms/step\n",
      "Epoch 27/50\n",
      "105/105 - 1s - loss: 0.2048 - accuracy: 0.9500 - val_loss: 0.2080 - val_accuracy: 0.9469 - lr: 1.0000e-04 - 897ms/epoch - 9ms/step\n",
      "Epoch 28/50\n",
      "105/105 - 1s - loss: 0.2047 - accuracy: 0.9500 - val_loss: 0.2079 - val_accuracy: 0.9469 - lr: 1.0000e-04 - 888ms/epoch - 8ms/step\n",
      "Epoch 29/50\n",
      "105/105 - 1s - loss: 0.2047 - accuracy: 0.9500 - val_loss: 0.2079 - val_accuracy: 0.9469 - lr: 1.0000e-04 - 890ms/epoch - 8ms/step\n",
      "Epoch 30/50\n",
      "105/105 - 1s - loss: 0.2046 - accuracy: 0.9500 - val_loss: 0.2078 - val_accuracy: 0.9469 - lr: 1.0000e-04 - 885ms/epoch - 8ms/step\n",
      "Epoch 31/50\n",
      "105/105 - 1s - loss: 0.2046 - accuracy: 0.9501 - val_loss: 0.2077 - val_accuracy: 0.9469 - lr: 1.0000e-04 - 892ms/epoch - 8ms/step\n",
      "Epoch 32/50\n",
      "105/105 - 1s - loss: 0.2045 - accuracy: 0.9501 - val_loss: 0.2076 - val_accuracy: 0.9469 - lr: 1.0000e-04 - 874ms/epoch - 8ms/step\n",
      "Epoch 33/50\n",
      "105/105 - 1s - loss: 0.2045 - accuracy: 0.9501 - val_loss: 0.2076 - val_accuracy: 0.9469 - lr: 1.0000e-04 - 881ms/epoch - 8ms/step\n",
      "Epoch 34/50\n",
      "105/105 - 1s - loss: 0.2044 - accuracy: 0.9501 - val_loss: 0.2075 - val_accuracy: 0.9469 - lr: 1.0000e-04 - 884ms/epoch - 8ms/step\n",
      "Epoch 35/50\n",
      "105/105 - 1s - loss: 0.2044 - accuracy: 0.9502 - val_loss: 0.2075 - val_accuracy: 0.9468 - lr: 1.0000e-04 - 893ms/epoch - 9ms/step\n",
      "Epoch 36/50\n",
      "105/105 - 1s - loss: 0.2043 - accuracy: 0.9502 - val_loss: 0.2074 - val_accuracy: 0.9468 - lr: 1.0000e-04 - 892ms/epoch - 8ms/step\n",
      "Epoch 37/50\n",
      "105/105 - 1s - loss: 0.2043 - accuracy: 0.9502 - val_loss: 0.2074 - val_accuracy: 0.9468 - lr: 1.0000e-04 - 890ms/epoch - 8ms/step\n",
      "Epoch 38/50\n",
      "105/105 - 1s - loss: 0.2042 - accuracy: 0.9502 - val_loss: 0.2073 - val_accuracy: 0.9468 - lr: 1.0000e-04 - 872ms/epoch - 8ms/step\n",
      "Epoch 39/50\n",
      "105/105 - 1s - loss: 0.2042 - accuracy: 0.9502 - val_loss: 0.2073 - val_accuracy: 0.9468 - lr: 1.0000e-04 - 867ms/epoch - 8ms/step\n",
      "Epoch 40/50\n",
      "105/105 - 1s - loss: 0.2042 - accuracy: 0.9502 - val_loss: 0.2072 - val_accuracy: 0.9467 - lr: 1.0000e-04 - 879ms/epoch - 8ms/step\n",
      "Epoch 41/50\n",
      "105/105 - 1s - loss: 0.2041 - accuracy: 0.9502 - val_loss: 0.2072 - val_accuracy: 0.9467 - lr: 1.0000e-04 - 878ms/epoch - 8ms/step\n",
      "Epoch 42/50\n",
      "105/105 - 1s - loss: 0.2041 - accuracy: 0.9502 - val_loss: 0.2071 - val_accuracy: 0.9467 - lr: 1.0000e-04 - 881ms/epoch - 8ms/step\n",
      "Epoch 43/50\n",
      "105/105 - 1s - loss: 0.2040 - accuracy: 0.9502 - val_loss: 0.2071 - val_accuracy: 0.9467 - lr: 1.0000e-04 - 887ms/epoch - 8ms/step\n",
      "Epoch 44/50\n",
      "105/105 - 1s - loss: 0.2040 - accuracy: 0.9502 - val_loss: 0.2070 - val_accuracy: 0.9467 - lr: 1.0000e-04 - 883ms/epoch - 8ms/step\n",
      "Epoch 45/50\n",
      "105/105 - 1s - loss: 0.2040 - accuracy: 0.9502 - val_loss: 0.2070 - val_accuracy: 0.9467 - lr: 1.0000e-04 - 890ms/epoch - 8ms/step\n",
      "Epoch 46/50\n",
      "105/105 - 1s - loss: 0.2039 - accuracy: 0.9502 - val_loss: 0.2069 - val_accuracy: 0.9467 - lr: 1.0000e-04 - 892ms/epoch - 8ms/step\n",
      "Epoch 47/50\n",
      "105/105 - 1s - loss: 0.2039 - accuracy: 0.9502 - val_loss: 0.2069 - val_accuracy: 0.9466 - lr: 1.0000e-04 - 904ms/epoch - 9ms/step\n",
      "Epoch 48/50\n",
      "105/105 - 1s - loss: 0.2039 - accuracy: 0.9502 - val_loss: 0.2069 - val_accuracy: 0.9466 - lr: 1.0000e-04 - 883ms/epoch - 8ms/step\n",
      "Epoch 49/50\n",
      "105/105 - 1s - loss: 0.2039 - accuracy: 0.9502 - val_loss: 0.2068 - val_accuracy: 0.9466 - lr: 1.0000e-04 - 880ms/epoch - 8ms/step\n",
      "Epoch 50/50\n",
      "105/105 - 1s - loss: 0.2038 - accuracy: 0.9502 - val_loss: 0.2068 - val_accuracy: 0.9466 - lr: 1.0000e-04 - 868ms/epoch - 8ms/step\n",
      "3125/3125 [==============================] - 2s 715us/step\n",
      "Keras  Accuracy: 0.94659\n",
      "1563/1563 [==============================] - 1s 920us/step\n",
      "Total correct: 46084\n",
      "Total incorrect: 3916\n",
      "Total samples: 50000\n",
      "Keras Excited Accuracy: 0.92168\n",
      "1563/1563 [==============================] - 1s 687us/step\n",
      "Total correct: 48575\n",
      "Total incorrect: 1425\n",
      "Total samples: 50000\n",
      "Keras Ground Accuracy: 0.9715\n",
      "\n",
      "===================================\n",
      "Fidelity 0.94659\n",
      "===================================\n"
     ]
    }
   ],
   "source": [
    "checkpoint_filename = 'single_layer_model_subwindow.h5'\n",
    "callbacks = [\n",
    "        ModelCheckpoint(\n",
    "        checkpoint_filename,\n",
    "        monitor=\"val_loss\",\n",
    "        verbose=0,\n",
    "        save_best_only=True,\n",
    "        save_weights_only=False,\n",
    "        save_freq=\"epoch\",\n",
    "    ),\n",
    "    ReduceLROnPlateau(patience=75, min_delta=1**-6),\n",
    "]\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(2, activation='relu', input_shape=(800,)))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "print(model.summary())\n",
    "\n",
    "sl_accuracy, sl_e_accuracy, sl_g_accuracy = scan_readout_window(model, window_start_locations, window_size, callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy [0.95772, 0.95985, 0.95973, 0.95769, 0.95521, 0.95261, 0.94944, 0.94659]\n",
      "Fidelity [0.91544 0.9197  0.91946 0.91538 0.91042 0.90522 0.89888 0.89318]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sl_fidelity = 1 - (1 - np.array(sl_e_accuracy)) - (1 - np.array(sl_g_accuracy)) \n",
    "\n",
    "plt.figure()\n",
    "plt.plot(window_start_locations, sl_fidelity)\n",
    "plt.xlabel('Readout window start location')\n",
    "plt.ylabel('Fidelity')\n",
    "\n",
    "print('Accuracy', sl_accuracy)\n",
    "print('Fidelity', sl_fidelity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "374.391px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
